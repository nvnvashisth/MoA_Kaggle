{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-20T23:25:04.324054Z",
     "iopub.status.busy": "2020-11-20T23:25:04.323157Z",
     "iopub.status.idle": "2020-11-20T23:25:05.371472Z",
     "shell.execute_reply": "2020-11-20T23:25:05.370155Z"
    },
    "papermill": {
     "duration": 1.083758,
     "end_time": "2020-11-20T23:25:05.371616",
     "exception": false,
     "start_time": "2020-11-20T23:25:04.287858",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('../input/iterativestratification')\n",
    "from iterstrat.ml_stratifiers import MultilabelStratifiedKFold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-20T23:25:05.441678Z",
     "iopub.status.busy": "2020-11-20T23:25:05.440924Z",
     "iopub.status.idle": "2020-11-20T23:25:07.606758Z",
     "shell.execute_reply": "2020-11-20T23:25:07.607965Z"
    },
    "papermill": {
     "duration": 2.202954,
     "end_time": "2020-11-20T23:25:07.608146",
     "exception": false,
     "start_time": "2020-11-20T23:25:05.405192",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import random\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import copy\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn import preprocessing\n",
    "from sklearn.metrics import log_loss\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import QuantileTransformer\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-20T23:25:07.691677Z",
     "iopub.status.busy": "2020-11-20T23:25:07.690834Z",
     "iopub.status.idle": "2020-11-20T23:25:13.952921Z",
     "shell.execute_reply": "2020-11-20T23:25:13.951608Z"
    },
    "papermill": {
     "duration": 6.310891,
     "end_time": "2020-11-20T23:25:13.953074",
     "exception": false,
     "start_time": "2020-11-20T23:25:07.642183",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_features = pd.read_csv('../input/lish-moa/train_features.csv')\n",
    "# aug = pd.read_csv('../input/moa-ctgan/ctgan_aug.csv')\n",
    "# train_targets_scored = pd.read_csv('../input/lish-moa/train_targets_scored.csv')\n",
    "train_targets_scored = pd.read_csv('../input/lish-moa/train_targets_nonscored.csv')\n",
    "test_features = pd.read_csv('../input/lish-moa/test_features.csv')\n",
    "sample_submission = pd.read_csv('../input/lish-moa/sample_submission.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-20T23:25:14.017351Z",
     "iopub.status.busy": "2020-11-20T23:25:14.015442Z",
     "iopub.status.idle": "2020-11-20T23:25:14.018059Z",
     "shell.execute_reply": "2020-11-20T23:25:14.018561Z"
    },
    "papermill": {
     "duration": 0.036202,
     "end_time": "2020-11-20T23:25:14.018694",
     "exception": false,
     "start_time": "2020-11-20T23:25:13.982492",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# aug['cp_dose'] = aug['cp_dose'].map({0: 'D1', 1: 'D2'})\n",
    "# aug['cp_time'] = aug['cp_time'].map({24.0: 24, 48.0: 48, 72.0: 72})\n",
    "# aug['cp_type'] = 'trt_cp'\n",
    "# aug.insert(1, 'sig_id', range(1, 1 + len(aug)))\n",
    "# aug['sig_id'] = \"id_\" + aug.sig_id.map(str)\n",
    "# aug_features = aug[train_features.columns]\n",
    "# aug_targets = aug[train_targets_scored.columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-20T23:25:14.084324Z",
     "iopub.status.busy": "2020-11-20T23:25:14.083563Z",
     "iopub.status.idle": "2020-11-20T23:25:14.088499Z",
     "shell.execute_reply": "2020-11-20T23:25:14.087824Z"
    },
    "papermill": {
     "duration": 0.040573,
     "end_time": "2020-11-20T23:25:14.088616",
     "exception": false,
     "start_time": "2020-11-20T23:25:14.048043",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# train_features = pd.concat([train_features, aug_features]).reset_index(drop=True)\n",
    "# train_targets_scored = pd.concat([train_targets_scored, aug_targets]).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-20T23:25:14.160097Z",
     "iopub.status.busy": "2020-11-20T23:25:14.157966Z",
     "iopub.status.idle": "2020-11-20T23:25:14.160797Z",
     "shell.execute_reply": "2020-11-20T23:25:14.161313Z"
    },
    "papermill": {
     "duration": 0.040918,
     "end_time": "2020-11-20T23:25:14.161428",
     "exception": false,
     "start_time": "2020-11-20T23:25:14.120510",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "GENES = [col for col in train_features.columns if col.startswith('g-')]\n",
    "CELLS = [col for col in train_features.columns if col.startswith('c-')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-20T23:25:14.233162Z",
     "iopub.status.busy": "2020-11-20T23:25:14.232432Z",
     "iopub.status.idle": "2020-11-20T23:25:24.484951Z",
     "shell.execute_reply": "2020-11-20T23:25:24.484293Z"
    },
    "papermill": {
     "duration": 10.293968,
     "end_time": "2020-11-20T23:25:24.485089",
     "exception": false,
     "start_time": "2020-11-20T23:25:14.191121",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "for col in (GENES + CELLS):\n",
    "    transformer = QuantileTransformer(n_quantiles=100,random_state=0, output_distribution=\"normal\")\n",
    "    vec_len = len(train_features[col].values)\n",
    "    vec_len_test = len(test_features[col].values)\n",
    "    raw_vec = train_features[col].values.reshape(vec_len, 1)\n",
    "    transformer.fit(raw_vec)\n",
    "    train_features[col] = transformer.transform(raw_vec).reshape(1, vec_len)[0]\n",
    "    test_features[col] = transformer.transform(test_features[col].values.reshape(vec_len_test, 1)).reshape(1, vec_len_test)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-20T23:25:24.556129Z",
     "iopub.status.busy": "2020-11-20T23:25:24.555450Z",
     "iopub.status.idle": "2020-11-20T23:25:24.563620Z",
     "shell.execute_reply": "2020-11-20T23:25:24.563050Z"
    },
    "papermill": {
     "duration": 0.044684,
     "end_time": "2020-11-20T23:25:24.563754",
     "exception": false,
     "start_time": "2020-11-20T23:25:24.519070",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def seed_everything(seed=42):\n",
    "    random.seed(seed)\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    \n",
    "seed_everything(seed=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-20T23:25:24.637462Z",
     "iopub.status.busy": "2020-11-20T23:25:24.636389Z",
     "iopub.status.idle": "2020-11-20T23:25:38.277297Z",
     "shell.execute_reply": "2020-11-20T23:25:38.275679Z"
    },
    "papermill": {
     "duration": 13.682867,
     "end_time": "2020-11-20T23:25:38.277421",
     "exception": false,
     "start_time": "2020-11-20T23:25:24.594554",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "n_comp = 600  #<--Update\n",
    "\n",
    "data = pd.concat([pd.DataFrame(train_features[GENES]), pd.DataFrame(test_features[GENES])])\n",
    "data2 = (PCA(n_components=n_comp, random_state=42).fit_transform(data[GENES]))\n",
    "train2 = data2[:train_features.shape[0]]; test2 = data2[-test_features.shape[0]:]\n",
    "\n",
    "train2 = pd.DataFrame(train2, columns=[f'pca_G-{i}' for i in range(n_comp)])\n",
    "test2 = pd.DataFrame(test2, columns=[f'pca_G-{i}' for i in range(n_comp)])\n",
    "\n",
    "# drop_cols = [f'c-{i}' for i in range(n_comp,len(GENES))]\n",
    "train_features = pd.concat((train_features, train2), axis=1)\n",
    "test_features = pd.concat((test_features, test2), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-20T23:25:38.347772Z",
     "iopub.status.busy": "2020-11-20T23:25:38.346435Z",
     "iopub.status.idle": "2020-11-20T23:25:39.090034Z",
     "shell.execute_reply": "2020-11-20T23:25:39.089433Z"
    },
    "papermill": {
     "duration": 0.783371,
     "end_time": "2020-11-20T23:25:39.090181",
     "exception": false,
     "start_time": "2020-11-20T23:25:38.306810",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "n_comp = 50  #<--Update\n",
    "\n",
    "data = pd.concat([pd.DataFrame(train_features[CELLS]), pd.DataFrame(test_features[CELLS])])\n",
    "data2 = (PCA(n_components=n_comp, random_state=42).fit_transform(data[CELLS]))\n",
    "train2 = data2[:train_features.shape[0]]; test2 = data2[-test_features.shape[0]:]\n",
    "\n",
    "train2 = pd.DataFrame(train2, columns=[f'pca_C-{i}' for i in range(n_comp)])\n",
    "test2 = pd.DataFrame(test2, columns=[f'pca_C-{i}' for i in range(n_comp)])\n",
    "\n",
    "# drop_cols = [f'c-{i}' for i in range(n_comp,len(CELLS))]\n",
    "train_features = pd.concat((train_features, train2), axis=1)\n",
    "test_features = pd.concat((test_features, test2), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-20T23:25:39.160150Z",
     "iopub.status.busy": "2020-11-20T23:25:39.159387Z",
     "iopub.status.idle": "2020-11-20T23:25:40.340191Z",
     "shell.execute_reply": "2020-11-20T23:25:40.339122Z"
    },
    "papermill": {
     "duration": 1.220404,
     "end_time": "2020-11-20T23:25:40.340376",
     "exception": false,
     "start_time": "2020-11-20T23:25:39.119972",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(23814, 1040)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.feature_selection import VarianceThreshold\n",
    "\n",
    "\n",
    "var_thresh = VarianceThreshold(0.8)  #<-- Update\n",
    "data = train_features.append(test_features)\n",
    "data_transformed = var_thresh.fit_transform(data.iloc[:, 4:])\n",
    "\n",
    "train_features_transformed = data_transformed[ : train_features.shape[0]]\n",
    "test_features_transformed = data_transformed[-test_features.shape[0] : ]\n",
    "\n",
    "\n",
    "train_features = pd.DataFrame(train_features[['sig_id','cp_type','cp_time','cp_dose']].values.reshape(-1, 4),\\\n",
    "                              columns=['sig_id','cp_type','cp_time','cp_dose'])\n",
    "\n",
    "train_features = pd.concat([train_features, pd.DataFrame(train_features_transformed)], axis=1)\n",
    "\n",
    "\n",
    "test_features = pd.DataFrame(test_features[['sig_id','cp_type','cp_time','cp_dose']].values.reshape(-1, 4),\\\n",
    "                             columns=['sig_id','cp_type','cp_time','cp_dose'])\n",
    "\n",
    "test_features = pd.concat([test_features, pd.DataFrame(test_features_transformed)], axis=1)\n",
    "\n",
    "train_features.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-20T23:25:40.436043Z",
     "iopub.status.busy": "2020-11-20T23:25:40.435114Z",
     "iopub.status.idle": "2020-11-20T23:25:40.935982Z",
     "shell.execute_reply": "2020-11-20T23:25:40.937297Z"
    },
    "papermill": {
     "duration": 0.553204,
     "end_time": "2020-11-20T23:25:40.937496",
     "exception": false,
     "start_time": "2020-11-20T23:25:40.384292",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "train = train_features.merge(train_targets_scored, on='sig_id')\n",
    "train = train[train['cp_type']!='ctl_vehicle'].reset_index(drop=True)\n",
    "test = test_features[test_features['cp_type']!='ctl_vehicle'].reset_index(drop=True)\n",
    "\n",
    "target = train[train_targets_scored.columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-20T23:25:41.123160Z",
     "iopub.status.busy": "2020-11-20T23:25:41.122302Z",
     "iopub.status.idle": "2020-11-20T23:25:41.125927Z",
     "shell.execute_reply": "2020-11-20T23:25:41.127022Z"
    },
    "papermill": {
     "duration": 0.142965,
     "end_time": "2020-11-20T23:25:41.127200",
     "exception": false,
     "start_time": "2020-11-20T23:25:40.984235",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "train = train.drop('cp_type', axis=1)\n",
    "test = test.drop('cp_type', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-20T23:25:41.216542Z",
     "iopub.status.busy": "2020-11-20T23:25:41.215728Z",
     "iopub.status.idle": "2020-11-20T23:25:41.241833Z",
     "shell.execute_reply": "2020-11-20T23:25:41.243050Z"
    },
    "papermill": {
     "duration": 0.076498,
     "end_time": "2020-11-20T23:25:41.243264",
     "exception": false,
     "start_time": "2020-11-20T23:25:41.166766",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "target_cols = target.drop('sig_id', axis=1).columns.values.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-20T23:25:41.350781Z",
     "iopub.status.busy": "2020-11-20T23:25:41.349371Z",
     "iopub.status.idle": "2020-11-20T23:25:47.446215Z",
     "shell.execute_reply": "2020-11-20T23:25:47.445565Z"
    },
    "papermill": {
     "duration": 6.158898,
     "end_time": "2020-11-20T23:25:47.446348",
     "exception": false,
     "start_time": "2020-11-20T23:25:41.287450",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sig_id</th>\n",
       "      <th>cp_time</th>\n",
       "      <th>cp_dose</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>...</th>\n",
       "      <th>vesicular_monoamine_transporter_inhibitor</th>\n",
       "      <th>vitamin_k_antagonist</th>\n",
       "      <th>voltage-gated_calcium_channel_ligand</th>\n",
       "      <th>voltage-gated_potassium_channel_activator</th>\n",
       "      <th>voltage-gated_sodium_channel_blocker</th>\n",
       "      <th>wdr5_mll_interaction_inhibitor</th>\n",
       "      <th>wnt_agonist</th>\n",
       "      <th>xanthine_oxidase_inhibitor</th>\n",
       "      <th>xiap_inhibitor</th>\n",
       "      <th>kfold</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>id_000644bb2</td>\n",
       "      <td>24</td>\n",
       "      <td>D1</td>\n",
       "      <td>1.134849</td>\n",
       "      <td>0.907687</td>\n",
       "      <td>-0.416385</td>\n",
       "      <td>-0.966814</td>\n",
       "      <td>-0.254723</td>\n",
       "      <td>-1.017473</td>\n",
       "      <td>-1.364787</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>id_000779bfc</td>\n",
       "      <td>72</td>\n",
       "      <td>D1</td>\n",
       "      <td>0.119282</td>\n",
       "      <td>0.681738</td>\n",
       "      <td>0.272399</td>\n",
       "      <td>0.080113</td>\n",
       "      <td>1.205169</td>\n",
       "      <td>0.686517</td>\n",
       "      <td>0.313396</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>id_000a6266a</td>\n",
       "      <td>48</td>\n",
       "      <td>D1</td>\n",
       "      <td>0.779973</td>\n",
       "      <td>0.946463</td>\n",
       "      <td>1.425350</td>\n",
       "      <td>-0.132928</td>\n",
       "      <td>-0.006122</td>\n",
       "      <td>1.492493</td>\n",
       "      <td>0.235577</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>id_0015fd391</td>\n",
       "      <td>48</td>\n",
       "      <td>D1</td>\n",
       "      <td>-0.734910</td>\n",
       "      <td>-0.274641</td>\n",
       "      <td>-0.438509</td>\n",
       "      <td>0.759097</td>\n",
       "      <td>2.346330</td>\n",
       "      <td>-0.858153</td>\n",
       "      <td>-2.288417</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>id_001626bd3</td>\n",
       "      <td>72</td>\n",
       "      <td>D2</td>\n",
       "      <td>-0.452718</td>\n",
       "      <td>-0.477513</td>\n",
       "      <td>0.972316</td>\n",
       "      <td>0.970731</td>\n",
       "      <td>1.463427</td>\n",
       "      <td>-0.869555</td>\n",
       "      <td>-0.375501</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21943</th>\n",
       "      <td>id_fff8c2444</td>\n",
       "      <td>72</td>\n",
       "      <td>D1</td>\n",
       "      <td>0.237856</td>\n",
       "      <td>-1.228203</td>\n",
       "      <td>0.218376</td>\n",
       "      <td>-0.365976</td>\n",
       "      <td>-0.330177</td>\n",
       "      <td>0.569243</td>\n",
       "      <td>-0.150978</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21944</th>\n",
       "      <td>id_fffb1ceed</td>\n",
       "      <td>24</td>\n",
       "      <td>D2</td>\n",
       "      <td>0.209361</td>\n",
       "      <td>-0.022389</td>\n",
       "      <td>-0.235888</td>\n",
       "      <td>-0.796989</td>\n",
       "      <td>-0.674009</td>\n",
       "      <td>0.919312</td>\n",
       "      <td>0.735603</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21945</th>\n",
       "      <td>id_fffb70c0c</td>\n",
       "      <td>24</td>\n",
       "      <td>D2</td>\n",
       "      <td>-1.911021</td>\n",
       "      <td>0.587228</td>\n",
       "      <td>-0.588417</td>\n",
       "      <td>1.296405</td>\n",
       "      <td>-1.002640</td>\n",
       "      <td>0.850589</td>\n",
       "      <td>-0.304313</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21946</th>\n",
       "      <td>id_fffcb9e7c</td>\n",
       "      <td>24</td>\n",
       "      <td>D1</td>\n",
       "      <td>0.816407</td>\n",
       "      <td>0.417618</td>\n",
       "      <td>0.431631</td>\n",
       "      <td>0.300617</td>\n",
       "      <td>1.070346</td>\n",
       "      <td>-0.024189</td>\n",
       "      <td>0.048942</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21947</th>\n",
       "      <td>id_ffffdd77b</td>\n",
       "      <td>72</td>\n",
       "      <td>D1</td>\n",
       "      <td>-1.243096</td>\n",
       "      <td>1.567730</td>\n",
       "      <td>-0.269573</td>\n",
       "      <td>1.083636</td>\n",
       "      <td>-0.511235</td>\n",
       "      <td>-2.099634</td>\n",
       "      <td>-1.622462</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>21948 rows Ã— 1442 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             sig_id cp_time cp_dose         0         1         2         3  \\\n",
       "0      id_000644bb2      24      D1  1.134849  0.907687 -0.416385 -0.966814   \n",
       "1      id_000779bfc      72      D1  0.119282  0.681738  0.272399  0.080113   \n",
       "2      id_000a6266a      48      D1  0.779973  0.946463  1.425350 -0.132928   \n",
       "3      id_0015fd391      48      D1 -0.734910 -0.274641 -0.438509  0.759097   \n",
       "4      id_001626bd3      72      D2 -0.452718 -0.477513  0.972316  0.970731   \n",
       "...             ...     ...     ...       ...       ...       ...       ...   \n",
       "21943  id_fff8c2444      72      D1  0.237856 -1.228203  0.218376 -0.365976   \n",
       "21944  id_fffb1ceed      24      D2  0.209361 -0.022389 -0.235888 -0.796989   \n",
       "21945  id_fffb70c0c      24      D2 -1.911021  0.587228 -0.588417  1.296405   \n",
       "21946  id_fffcb9e7c      24      D1  0.816407  0.417618  0.431631  0.300617   \n",
       "21947  id_ffffdd77b      72      D1 -1.243096  1.567730 -0.269573  1.083636   \n",
       "\n",
       "              4         5         6  ...  \\\n",
       "0     -0.254723 -1.017473 -1.364787  ...   \n",
       "1      1.205169  0.686517  0.313396  ...   \n",
       "2     -0.006122  1.492493  0.235577  ...   \n",
       "3      2.346330 -0.858153 -2.288417  ...   \n",
       "4      1.463427 -0.869555 -0.375501  ...   \n",
       "...         ...       ...       ...  ...   \n",
       "21943 -0.330177  0.569243 -0.150978  ...   \n",
       "21944 -0.674009  0.919312  0.735603  ...   \n",
       "21945 -1.002640  0.850589 -0.304313  ...   \n",
       "21946  1.070346 -0.024189  0.048942  ...   \n",
       "21947 -0.511235 -2.099634 -1.622462  ...   \n",
       "\n",
       "       vesicular_monoamine_transporter_inhibitor  vitamin_k_antagonist  \\\n",
       "0                                              0                     0   \n",
       "1                                              0                     0   \n",
       "2                                              0                     0   \n",
       "3                                              0                     0   \n",
       "4                                              0                     0   \n",
       "...                                          ...                   ...   \n",
       "21943                                          0                     0   \n",
       "21944                                          0                     0   \n",
       "21945                                          0                     0   \n",
       "21946                                          0                     0   \n",
       "21947                                          0                     0   \n",
       "\n",
       "       voltage-gated_calcium_channel_ligand  \\\n",
       "0                                         0   \n",
       "1                                         0   \n",
       "2                                         0   \n",
       "3                                         0   \n",
       "4                                         0   \n",
       "...                                     ...   \n",
       "21943                                     0   \n",
       "21944                                     0   \n",
       "21945                                     0   \n",
       "21946                                     0   \n",
       "21947                                     0   \n",
       "\n",
       "       voltage-gated_potassium_channel_activator  \\\n",
       "0                                              0   \n",
       "1                                              0   \n",
       "2                                              0   \n",
       "3                                              0   \n",
       "4                                              0   \n",
       "...                                          ...   \n",
       "21943                                          0   \n",
       "21944                                          0   \n",
       "21945                                          0   \n",
       "21946                                          0   \n",
       "21947                                          0   \n",
       "\n",
       "       voltage-gated_sodium_channel_blocker  wdr5_mll_interaction_inhibitor  \\\n",
       "0                                         0                               0   \n",
       "1                                         0                               0   \n",
       "2                                         0                               0   \n",
       "3                                         0                               0   \n",
       "4                                         0                               0   \n",
       "...                                     ...                             ...   \n",
       "21943                                     0                               0   \n",
       "21944                                     0                               0   \n",
       "21945                                     0                               0   \n",
       "21946                                     0                               0   \n",
       "21947                                     0                               0   \n",
       "\n",
       "       wnt_agonist  xanthine_oxidase_inhibitor  xiap_inhibitor  kfold  \n",
       "0                0                           0               0      3  \n",
       "1                0                           0               0      0  \n",
       "2                0                           0               0      6  \n",
       "3                0                           0               0      4  \n",
       "4                0                           0               0      3  \n",
       "...            ...                         ...             ...    ...  \n",
       "21943            0                           0               0      0  \n",
       "21944            0                           0               0      1  \n",
       "21945            0                           0               0      4  \n",
       "21946            0                           0               0      2  \n",
       "21947            0                           0               0      1  \n",
       "\n",
       "[21948 rows x 1442 columns]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "folds = train.copy()\n",
    "\n",
    "mskf = MultilabelStratifiedKFold(n_splits=7)\n",
    "\n",
    "for f, (t_idx, v_idx) in enumerate(mskf.split(X=train, y=target)):\n",
    "    folds.loc[v_idx, 'kfold'] = int(f)\n",
    "\n",
    "folds['kfold'] = folds['kfold'].astype(int)\n",
    "folds\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-20T23:25:47.520529Z",
     "iopub.status.busy": "2020-11-20T23:25:47.519627Z",
     "iopub.status.idle": "2020-11-20T23:25:47.526334Z",
     "shell.execute_reply": "2020-11-20T23:25:47.527070Z"
    },
    "papermill": {
     "duration": 0.045038,
     "end_time": "2020-11-20T23:25:47.527224",
     "exception": false,
     "start_time": "2020-11-20T23:25:47.482186",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(21948, 1441)\n",
      "(21948, 1442)\n",
      "(3624, 1039)\n",
      "(21948, 403)\n",
      "(3982, 207)\n"
     ]
    }
   ],
   "source": [
    "print(train.shape)\n",
    "print(folds.shape)\n",
    "print(test.shape)\n",
    "print(target.shape)\n",
    "print(sample_submission.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-20T23:25:47.604864Z",
     "iopub.status.busy": "2020-11-20T23:25:47.604068Z",
     "iopub.status.idle": "2020-11-20T23:25:47.608016Z",
     "shell.execute_reply": "2020-11-20T23:25:47.607356Z"
    },
    "papermill": {
     "duration": 0.047856,
     "end_time": "2020-11-20T23:25:47.608142",
     "exception": false,
     "start_time": "2020-11-20T23:25:47.560286",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class MoADataset:\n",
    "    def __init__(self, features, targets):\n",
    "        self.features = features\n",
    "        self.targets = targets\n",
    "        \n",
    "    def __len__(self):\n",
    "        return (self.features.shape[0])\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        dct = {\n",
    "            'x' : torch.tensor(self.features[idx, :], dtype=torch.float),\n",
    "            'y' : torch.tensor(self.targets[idx, :], dtype=torch.float)            \n",
    "        }\n",
    "        return dct\n",
    "    \n",
    "class TestDataset:\n",
    "    def __init__(self, features):\n",
    "        self.features = features\n",
    "        \n",
    "    def __len__(self):\n",
    "        return (self.features.shape[0])\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        dct = {\n",
    "            'x' : torch.tensor(self.features[idx, :], dtype=torch.float)\n",
    "        }\n",
    "        return dct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-20T23:25:47.690982Z",
     "iopub.status.busy": "2020-11-20T23:25:47.689977Z",
     "iopub.status.idle": "2020-11-20T23:25:47.692865Z",
     "shell.execute_reply": "2020-11-20T23:25:47.693367Z"
    },
    "papermill": {
     "duration": 0.053324,
     "end_time": "2020-11-20T23:25:47.693493",
     "exception": false,
     "start_time": "2020-11-20T23:25:47.640169",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def train_fn(model, optimizer, scheduler, loss_fn, dataloader, device):\n",
    "    model.train()\n",
    "    final_loss = 0\n",
    "    \n",
    "    for data in dataloader:\n",
    "        optimizer.zero_grad()\n",
    "        inputs, targets = data['x'].to(device), data['y'].to(device)\n",
    "        outputs = model(inputs)\n",
    "        loss = loss_fn(outputs, targets)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        scheduler.step()\n",
    "        \n",
    "        final_loss += loss.item()\n",
    "        \n",
    "    final_loss /= len(dataloader)\n",
    "    \n",
    "    return final_loss\n",
    "\n",
    "\n",
    "def valid_fn(model, loss_fn, dataloader, device):\n",
    "    model.eval()\n",
    "    final_loss = 0\n",
    "    valid_preds = []\n",
    "    \n",
    "    for data in dataloader:\n",
    "        inputs, targets = data['x'].to(device), data['y'].to(device)\n",
    "        outputs = model(inputs)\n",
    "        loss = loss_fn(outputs, targets)\n",
    "        \n",
    "        final_loss += loss.item()\n",
    "        valid_preds.append(outputs.sigmoid().detach().cpu().numpy())\n",
    "        \n",
    "    final_loss /= len(dataloader)\n",
    "    valid_preds = np.concatenate(valid_preds)\n",
    "    \n",
    "    return final_loss, valid_preds\n",
    "\n",
    "def inference_fn(model, dataloader, device):\n",
    "    model.eval()\n",
    "    preds = []\n",
    "    \n",
    "    for data in dataloader:\n",
    "        inputs = data['x'].to(device)\n",
    "\n",
    "        with torch.no_grad():\n",
    "            outputs = model(inputs)\n",
    "        \n",
    "        preds.append(outputs.sigmoid().detach().cpu().numpy())\n",
    "        \n",
    "    preds = np.concatenate(preds)\n",
    "    \n",
    "    return preds\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-20T23:25:47.773180Z",
     "iopub.status.busy": "2020-11-20T23:25:47.772267Z",
     "iopub.status.idle": "2020-11-20T23:25:47.775190Z",
     "shell.execute_reply": "2020-11-20T23:25:47.774630Z"
    },
    "papermill": {
     "duration": 0.048353,
     "end_time": "2020-11-20T23:25:47.775308",
     "exception": false,
     "start_time": "2020-11-20T23:25:47.726955",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.nn.modules.loss import _WeightedLoss\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class SmoothBCEwLogits(_WeightedLoss):\n",
    "    def __init__(self, weight=None, reduction='mean', smoothing=0.0):\n",
    "        super().__init__(weight=weight, reduction=reduction)\n",
    "        self.smoothing = smoothing\n",
    "        self.weight = weight\n",
    "        self.reduction = reduction\n",
    "\n",
    "    @staticmethod\n",
    "    def _smooth(targets:torch.Tensor, n_labels:int, smoothing=0.0):\n",
    "        assert 0 <= smoothing < 1\n",
    "        with torch.no_grad():\n",
    "            targets = targets * (1.0 - smoothing) + 0.5 * smoothing\n",
    "        return targets\n",
    "\n",
    "    def forward(self, inputs, targets):\n",
    "        targets = SmoothBCEwLogits._smooth(targets, inputs.size(-1),\n",
    "            self.smoothing)\n",
    "        loss = F.binary_cross_entropy_with_logits(inputs, targets,self.weight)\n",
    "\n",
    "        if  self.reduction == 'sum':\n",
    "            loss = loss.sum()\n",
    "        elif  self.reduction == 'mean':\n",
    "            loss = loss.mean()\n",
    "\n",
    "        return loss\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-20T23:25:47.850315Z",
     "iopub.status.busy": "2020-11-20T23:25:47.849388Z",
     "iopub.status.idle": "2020-11-20T23:25:47.852173Z",
     "shell.execute_reply": "2020-11-20T23:25:47.852706Z"
    },
    "papermill": {
     "duration": 0.042496,
     "end_time": "2020-11-20T23:25:47.852838",
     "exception": false,
     "start_time": "2020-11-20T23:25:47.810342",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#0.2619422201258426\n",
    "#0.2619422201258426"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-20T23:25:47.937972Z",
     "iopub.status.busy": "2020-11-20T23:25:47.937038Z",
     "iopub.status.idle": "2020-11-20T23:25:47.939998Z",
     "shell.execute_reply": "2020-11-20T23:25:47.939359Z"
    },
    "papermill": {
     "duration": 0.05347,
     "end_time": "2020-11-20T23:25:47.940095",
     "exception": false,
     "start_time": "2020-11-20T23:25:47.886625",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class Model(nn.Module):\n",
    "    def __init__(self, num_features, num_targets, hidden_size):\n",
    "        super(Model, self).__init__()\n",
    "        self.batch_norm1 = nn.BatchNorm1d(num_features)\n",
    "        self.dense1 = nn.Linear(num_features, hidden_size)\n",
    "        \n",
    "        self.batch_norm2 = nn.BatchNorm1d(hidden_size)\n",
    "        self.dropout2 = nn.Dropout(0.2619422201258426)\n",
    "        self.dense2 = nn.Linear(hidden_size, hidden_size)\n",
    "        \n",
    "        self.batch_norm3 = nn.BatchNorm1d(hidden_size)\n",
    "        self.dropout3 = nn.Dropout(0.2619422201258426)\n",
    "        self.dense3 = nn.Linear(hidden_size, num_targets)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.batch_norm1(x)\n",
    "        x = F.leaky_relu(self.dense1(x))\n",
    "        \n",
    "        x = self.batch_norm2(x)\n",
    "        x = self.dropout2(x)\n",
    "        x = F.leaky_relu(self.dense2(x))\n",
    "        \n",
    "        x = self.batch_norm3(x)\n",
    "        x = self.dropout3(x)\n",
    "        x = self.dense3(x)\n",
    "        \n",
    "        return x\n",
    "    \n",
    "class LabelSmoothingLoss(nn.Module):\n",
    "    def __init__(self, classes, smoothing=0.0, dim=-1):\n",
    "        super(LabelSmoothingLoss, self).__init__()\n",
    "        self.confidence = 1.0 - smoothing\n",
    "        self.smoothing = smoothing\n",
    "        self.cls = classes\n",
    "        self.dim = dim\n",
    "\n",
    "    def forward(self, pred, target):\n",
    "        pred = pred.log_softmax(dim=self.dim)\n",
    "        with torch.no_grad():\n",
    "            # true_dist = pred.data.clone()\n",
    "            true_dist = torch.zeros_like(pred)\n",
    "            true_dist.fill_(self.smoothing / (self.cls - 1))\n",
    "            true_dist.scatter_(1, target.data.unsqueeze(1), self.confidence)\n",
    "        return torch.mean(torch.sum(-true_dist * pred, dim=self.dim))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-20T23:25:48.013668Z",
     "iopub.status.busy": "2020-11-20T23:25:48.012868Z",
     "iopub.status.idle": "2020-11-20T23:25:48.015247Z",
     "shell.execute_reply": "2020-11-20T23:25:48.015789Z"
    },
    "papermill": {
     "duration": 0.041385,
     "end_time": "2020-11-20T23:25:48.015909",
     "exception": false,
     "start_time": "2020-11-20T23:25:47.974524",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def process_data(data):\n",
    "    data = pd.get_dummies(data, columns=['cp_time','cp_dose'])\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-20T23:25:48.093198Z",
     "iopub.status.busy": "2020-11-20T23:25:48.091987Z",
     "iopub.status.idle": "2020-11-20T23:25:48.338463Z",
     "shell.execute_reply": "2020-11-20T23:25:48.338976Z"
    },
    "papermill": {
     "duration": 0.28923,
     "end_time": "2020-11-20T23:25:48.339112",
     "exception": false,
     "start_time": "2020-11-20T23:25:48.049882",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1041"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feature_cols = [c for c in process_data(folds).columns if c not in target_cols]\n",
    "feature_cols = [c for c in feature_cols if c not in ['kfold','sig_id']]\n",
    "len(feature_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-20T23:25:48.788206Z",
     "iopub.status.busy": "2020-11-20T23:25:48.787267Z",
     "iopub.status.idle": "2020-11-20T23:25:48.790799Z",
     "shell.execute_reply": "2020-11-20T23:25:48.790235Z"
    },
    "papermill": {
     "duration": 0.418054,
     "end_time": "2020-11-20T23:25:48.790968",
     "exception": false,
     "start_time": "2020-11-20T23:25:48.372914",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "DEVICE = ('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "EPOCHS = 26\n",
    "BATCH_SIZE = 256\n",
    "LEARNING_RATE = 6e-4\n",
    "WEIGHT_DECAY = 1e-5\n",
    "NFOLDS = 7           \n",
    "EARLY_STOPPING_STEPS = 10\n",
    "EARLY_STOP = True\n",
    "\n",
    "num_features=len(feature_cols)\n",
    "num_targets=len(target_cols)\n",
    "hidden_size=2028"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-20T23:25:48.890108Z",
     "iopub.status.busy": "2020-11-20T23:25:48.888286Z",
     "iopub.status.idle": "2020-11-20T23:25:48.890884Z",
     "shell.execute_reply": "2020-11-20T23:25:48.891418Z"
    },
    "papermill": {
     "duration": 0.063701,
     "end_time": "2020-11-20T23:25:48.891557",
     "exception": false,
     "start_time": "2020-11-20T23:25:48.827856",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def run_training(fold, seed):\n",
    "    \n",
    "    seed_everything(seed)\n",
    "    \n",
    "    train = process_data(folds)\n",
    "    test_ = process_data(test)\n",
    "\n",
    "    \n",
    "    \n",
    "    trn_idx = train[train['kfold'] != fold].index\n",
    "    val_idx = train[train['kfold'] == fold].index\n",
    "    \n",
    "    train_df = train[train['kfold'] != fold].reset_index(drop=True)\n",
    "    valid_df = train[train['kfold'] == fold].reset_index(drop=True)\n",
    "    \n",
    "    x_train, y_train  = train_df[feature_cols].values, train_df[target_cols].values\n",
    "    x_valid, y_valid =  valid_df[feature_cols].values, valid_df[target_cols].values\n",
    "    \n",
    "    train_dataset = MoADataset(x_train, y_train)\n",
    "    valid_dataset = MoADataset(x_valid, y_valid)\n",
    "    trainloader = torch.utils.data.DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True)\n",
    "    validloader = torch.utils.data.DataLoader(valid_dataset, batch_size=BATCH_SIZE, shuffle=False)\n",
    "    \n",
    "    model = Model(\n",
    "        num_features=num_features,\n",
    "        num_targets=num_targets,\n",
    "        hidden_size=hidden_size,\n",
    "    )\n",
    "    \n",
    "    model.to(DEVICE)\n",
    "    \n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=LEARNING_RATE, weight_decay=WEIGHT_DECAY)\n",
    "    scheduler = optim.lr_scheduler.OneCycleLR(optimizer=optimizer, pct_start=0.1, div_factor=1e3, \n",
    "                                              max_lr=1e-2, epochs=EPOCHS, steps_per_epoch=len(trainloader))\n",
    "    \n",
    "    loss_fn = nn.BCEWithLogitsLoss()\n",
    "    loss_tr = SmoothBCEwLogits(smoothing =0.001)\n",
    "    \n",
    "    early_stopping_steps = EARLY_STOPPING_STEPS\n",
    "    early_step = 0\n",
    "   \n",
    "    oof = np.zeros((len(train), target.iloc[:, 1:].shape[1]))\n",
    "    best_loss = np.inf\n",
    "    \n",
    "    for epoch in range(EPOCHS):\n",
    "        \n",
    "        train_loss = train_fn(model, optimizer,scheduler, loss_tr, trainloader, DEVICE)\n",
    "        print(f\"FOLD: {fold}, EPOCH: {epoch}, train_loss: {train_loss}\")\n",
    "        valid_loss, valid_preds = valid_fn(model, loss_fn, validloader, DEVICE)\n",
    "        print(f\"FOLD: {fold}, EPOCH: {epoch}, valid_loss: {valid_loss}\")\n",
    "        \n",
    "        if valid_loss < best_loss:\n",
    "            \n",
    "            best_loss = valid_loss\n",
    "            oof[val_idx] = valid_preds\n",
    "            torch.save(model.state_dict(), f\"FOLD{fold}_non_scored.pth\")\n",
    "        \n",
    "        elif(EARLY_STOP == True):\n",
    "            \n",
    "            early_step += 1\n",
    "            if (early_step >= early_stopping_steps):\n",
    "                break\n",
    "            \n",
    "    \n",
    "    #--------------------- PREDICTION---------------------\n",
    "    x_test = test_[feature_cols].values\n",
    "    testdataset = TestDataset(x_test)\n",
    "    testloader = torch.utils.data.DataLoader(testdataset, batch_size=BATCH_SIZE, shuffle=False)\n",
    "    \n",
    "    model = Model(\n",
    "        num_features=num_features,\n",
    "        num_targets=num_targets,\n",
    "        hidden_size=hidden_size,\n",
    "\n",
    "    )\n",
    "    \n",
    "    model.load_state_dict(torch.load(f\"FOLD{fold}_non_scored.pth\"))\n",
    "    model.to(DEVICE)\n",
    "    \n",
    "    predictions = np.zeros((len(test_), target.iloc[:, 1:].shape[1]))\n",
    "    predictions = inference_fn(model, testloader, DEVICE)\n",
    "    \n",
    "    return oof, predictions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-20T23:25:48.969622Z",
     "iopub.status.busy": "2020-11-20T23:25:48.964074Z",
     "iopub.status.idle": "2020-11-20T23:25:48.972529Z",
     "shell.execute_reply": "2020-11-20T23:25:48.972026Z"
    },
    "papermill": {
     "duration": 0.046811,
     "end_time": "2020-11-20T23:25:48.972684",
     "exception": false,
     "start_time": "2020-11-20T23:25:48.925873",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def run_k_fold(NFOLDS, seed):\n",
    "    oof = np.zeros((len(train), len(target_cols)))\n",
    "    predictions = np.zeros((len(test), len(target_cols)))\n",
    "\n",
    "    \n",
    "    for fold in range(NFOLDS):\n",
    "        oof_, pred_ = run_training(fold, seed)\n",
    "        \n",
    "        predictions += pred_ / NFOLDS\n",
    "        oof += oof_\n",
    "        \n",
    "    return oof, predictions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-20T23:25:49.059076Z",
     "iopub.status.busy": "2020-11-20T23:25:49.057568Z",
     "iopub.status.idle": "2020-11-20T23:44:13.309887Z",
     "shell.execute_reply": "2020-11-20T23:44:13.309234Z"
    },
    "papermill": {
     "duration": 1104.298749,
     "end_time": "2020-11-20T23:44:13.310050",
     "exception": false,
     "start_time": "2020-11-20T23:25:49.011301",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FOLD: 0, EPOCH: 0, train_loss: 0.5800778359376095\n",
      "FOLD: 0, EPOCH: 0, valid_loss: 0.02859171021443147\n",
      "FOLD: 0, EPOCH: 1, train_loss: 0.010696040969845411\n",
      "FOLD: 0, EPOCH: 1, valid_loss: 0.005020973953203513\n",
      "FOLD: 0, EPOCH: 2, train_loss: 0.0090027072127103\n",
      "FOLD: 0, EPOCH: 2, valid_loss: 0.005552638966876727\n",
      "FOLD: 0, EPOCH: 3, train_loss: 0.017750168609357363\n",
      "FOLD: 0, EPOCH: 3, valid_loss: 0.005159553176221939\n",
      "FOLD: 0, EPOCH: 4, train_loss: 0.00907663389964885\n",
      "FOLD: 0, EPOCH: 4, valid_loss: 0.004967480217321561\n",
      "FOLD: 0, EPOCH: 5, train_loss: 0.008477273151731572\n",
      "FOLD: 0, EPOCH: 5, valid_loss: 0.004920330722458088\n",
      "FOLD: 0, EPOCH: 6, train_loss: 0.00833303207607084\n",
      "FOLD: 0, EPOCH: 6, valid_loss: 0.004882213946145315\n",
      "FOLD: 0, EPOCH: 7, train_loss: 0.00833328887568535\n",
      "FOLD: 0, EPOCH: 7, valid_loss: 0.004760957072274043\n",
      "FOLD: 0, EPOCH: 8, train_loss: 0.00821552873035339\n",
      "FOLD: 0, EPOCH: 8, valid_loss: 0.004869152218676531\n",
      "FOLD: 0, EPOCH: 9, train_loss: 0.008152926019770471\n",
      "FOLD: 0, EPOCH: 9, valid_loss: 0.004674504367777934\n",
      "FOLD: 0, EPOCH: 10, train_loss: 0.00805187872862695\n",
      "FOLD: 0, EPOCH: 10, valid_loss: 0.004654275719076395\n",
      "FOLD: 0, EPOCH: 11, train_loss: 0.007994899318578679\n",
      "FOLD: 0, EPOCH: 11, valid_loss: 0.004636202831394398\n",
      "FOLD: 0, EPOCH: 12, train_loss: 0.007901309794318434\n",
      "FOLD: 0, EPOCH: 12, valid_loss: 0.004530898295342922\n",
      "FOLD: 0, EPOCH: 13, train_loss: 0.007844117784721626\n",
      "FOLD: 0, EPOCH: 13, valid_loss: 0.004556306100522096\n",
      "FOLD: 0, EPOCH: 14, train_loss: 0.007802113632646364\n",
      "FOLD: 0, EPOCH: 14, valid_loss: 0.004536946877264059\n",
      "FOLD: 0, EPOCH: 15, train_loss: 0.007727660647769635\n",
      "FOLD: 0, EPOCH: 15, valid_loss: 0.00449741158920985\n",
      "FOLD: 0, EPOCH: 16, train_loss: 0.007644437593282075\n",
      "FOLD: 0, EPOCH: 16, valid_loss: 0.004498656516751418\n",
      "FOLD: 0, EPOCH: 17, train_loss: 0.007535243438355424\n",
      "FOLD: 0, EPOCH: 17, valid_loss: 0.00446170589958246\n",
      "FOLD: 0, EPOCH: 18, train_loss: 0.007433175027521478\n",
      "FOLD: 0, EPOCH: 18, valid_loss: 0.004403739110924876\n",
      "FOLD: 0, EPOCH: 19, train_loss: 0.007303502945531462\n",
      "FOLD: 0, EPOCH: 19, valid_loss: 0.004432049347087741\n",
      "FOLD: 0, EPOCH: 20, train_loss: 0.00713576381472317\n",
      "FOLD: 0, EPOCH: 20, valid_loss: 0.00442015531902703\n",
      "FOLD: 0, EPOCH: 21, train_loss: 0.006963831825634917\n",
      "FOLD: 0, EPOCH: 21, valid_loss: 0.004388603901204009\n",
      "FOLD: 0, EPOCH: 22, train_loss: 0.0067775335880248125\n",
      "FOLD: 0, EPOCH: 22, valid_loss: 0.004384365810367923\n",
      "FOLD: 0, EPOCH: 23, train_loss: 0.0066118407931581545\n",
      "FOLD: 0, EPOCH: 23, valid_loss: 0.004397932672873139\n",
      "FOLD: 0, EPOCH: 24, train_loss: 0.006487954470857575\n",
      "FOLD: 0, EPOCH: 24, valid_loss: 0.0043783043690312365\n",
      "FOLD: 0, EPOCH: 25, train_loss: 0.0064324107889488745\n",
      "FOLD: 0, EPOCH: 25, valid_loss: 0.004382470891309472\n",
      "FOLD: 1, EPOCH: 0, train_loss: 0.5762788763622174\n",
      "FOLD: 1, EPOCH: 0, valid_loss: 0.025060870326482333\n",
      "FOLD: 1, EPOCH: 1, train_loss: 0.01026696925731124\n",
      "FOLD: 1, EPOCH: 1, valid_loss: 0.0045982495559236175\n",
      "FOLD: 1, EPOCH: 2, train_loss: 0.008936930391182369\n",
      "FOLD: 1, EPOCH: 2, valid_loss: 0.004961852843944843\n",
      "FOLD: 1, EPOCH: 3, train_loss: 0.009036309733936513\n",
      "FOLD: 1, EPOCH: 3, valid_loss: 0.004936982913372608\n",
      "FOLD: 1, EPOCH: 4, train_loss: 0.00855164007736823\n",
      "FOLD: 1, EPOCH: 4, valid_loss: 0.004994701307553511\n",
      "FOLD: 1, EPOCH: 5, train_loss: 0.009055113438768563\n",
      "FOLD: 1, EPOCH: 5, valid_loss: 0.0045866938307881355\n",
      "FOLD: 1, EPOCH: 6, train_loss: 0.0082662695817448\n",
      "FOLD: 1, EPOCH: 6, valid_loss: 0.004724790234691822\n",
      "FOLD: 1, EPOCH: 7, train_loss: 0.00806348247302545\n",
      "FOLD: 1, EPOCH: 7, valid_loss: 0.004659037893781295\n",
      "FOLD: 1, EPOCH: 8, train_loss: 0.007995222953173358\n",
      "FOLD: 1, EPOCH: 8, valid_loss: 0.004660282606402269\n",
      "FOLD: 1, EPOCH: 9, train_loss: 0.007930869815518727\n",
      "FOLD: 1, EPOCH: 9, valid_loss: 0.004602276093254869\n",
      "FOLD: 1, EPOCH: 10, train_loss: 0.00788636424427701\n",
      "FOLD: 1, EPOCH: 10, valid_loss: 0.004522036044643476\n",
      "FOLD: 1, EPOCH: 11, train_loss: 0.007864505662960378\n",
      "FOLD: 1, EPOCH: 11, valid_loss: 0.004671861095210681\n",
      "FOLD: 1, EPOCH: 12, train_loss: 0.007826161042258546\n",
      "FOLD: 1, EPOCH: 12, valid_loss: 0.004482250535287536\n",
      "FOLD: 1, EPOCH: 13, train_loss: 0.007799361750634538\n",
      "FOLD: 1, EPOCH: 13, valid_loss: 0.0044937285128980875\n",
      "FOLD: 1, EPOCH: 14, train_loss: 0.007747418675068262\n",
      "FOLD: 1, EPOCH: 14, valid_loss: 0.004583709765798771\n",
      "FOLD: 2, EPOCH: 0, train_loss: 0.5773651004844421\n",
      "FOLD: 2, EPOCH: 0, valid_loss: 0.024634556988110907\n",
      "FOLD: 2, EPOCH: 1, train_loss: 0.011090407500395904\n",
      "FOLD: 2, EPOCH: 1, valid_loss: 0.00479762707478725\n",
      "FOLD: 2, EPOCH: 2, train_loss: 0.009103626233047328\n",
      "FOLD: 2, EPOCH: 2, valid_loss: 0.005068585348243897\n",
      "FOLD: 2, EPOCH: 3, train_loss: 0.008864516417521078\n",
      "FOLD: 2, EPOCH: 3, valid_loss: 0.00522467250434252\n",
      "FOLD: 2, EPOCH: 4, train_loss: 0.008838329080341233\n",
      "FOLD: 2, EPOCH: 4, valid_loss: 0.005018298764928029\n",
      "FOLD: 2, EPOCH: 5, train_loss: 0.00853145883947208\n",
      "FOLD: 2, EPOCH: 5, valid_loss: 0.015164459195847694\n",
      "FOLD: 2, EPOCH: 6, train_loss: 0.0090456415987196\n",
      "FOLD: 2, EPOCH: 6, valid_loss: 0.004866484158600752\n",
      "FOLD: 2, EPOCH: 7, train_loss: 0.008235281780110421\n",
      "FOLD: 2, EPOCH: 7, valid_loss: 0.004761729890910478\n",
      "FOLD: 2, EPOCH: 8, train_loss: 0.008101136367012924\n",
      "FOLD: 2, EPOCH: 8, valid_loss: 0.00471723244453852\n",
      "FOLD: 2, EPOCH: 9, train_loss: 0.008034271313934712\n",
      "FOLD: 2, EPOCH: 9, valid_loss: 0.004615093079897074\n",
      "FOLD: 2, EPOCH: 10, train_loss: 0.007982545444188086\n",
      "FOLD: 2, EPOCH: 10, valid_loss: 0.004724149019099199\n",
      "FOLD: 2, EPOCH: 11, train_loss: 0.007929261717190212\n",
      "FOLD: 2, EPOCH: 11, valid_loss: 0.004650654199604805\n",
      "FOLD: 2, EPOCH: 12, train_loss: 0.007906761951744556\n",
      "FOLD: 2, EPOCH: 12, valid_loss: 0.004613863268437294\n",
      "FOLD: 2, EPOCH: 13, train_loss: 0.007848925083070188\n",
      "FOLD: 2, EPOCH: 13, valid_loss: 0.004647238502422204\n",
      "FOLD: 2, EPOCH: 14, train_loss: 0.007808237613455669\n",
      "FOLD: 2, EPOCH: 14, valid_loss: 0.004563011515599031\n",
      "FOLD: 2, EPOCH: 15, train_loss: 0.007751070220979887\n",
      "FOLD: 2, EPOCH: 15, valid_loss: 0.004563586858029549\n",
      "FOLD: 2, EPOCH: 16, train_loss: 0.007689121084891864\n",
      "FOLD: 2, EPOCH: 16, valid_loss: 0.004494509588067348\n",
      "FOLD: 2, EPOCH: 17, train_loss: 0.0076135941277686\n",
      "FOLD: 2, EPOCH: 17, valid_loss: 0.004591881619909635\n",
      "FOLD: 3, EPOCH: 0, train_loss: 0.576419106709796\n",
      "FOLD: 3, EPOCH: 0, valid_loss: 0.03848879555096993\n",
      "FOLD: 3, EPOCH: 1, train_loss: 0.010643885017850914\n",
      "FOLD: 3, EPOCH: 1, valid_loss: 0.004734664367368588\n",
      "FOLD: 3, EPOCH: 2, train_loss: 0.009711596844214443\n",
      "FOLD: 3, EPOCH: 2, valid_loss: 0.0050999680534005165\n",
      "FOLD: 3, EPOCH: 3, train_loss: 0.009041324994098899\n",
      "FOLD: 3, EPOCH: 3, valid_loss: 0.007309486659673544\n",
      "FOLD: 3, EPOCH: 4, train_loss: 0.008741965410425453\n",
      "FOLD: 3, EPOCH: 4, valid_loss: 0.00483864051504777\n",
      "FOLD: 3, EPOCH: 5, train_loss: 0.00835659248578186\n",
      "FOLD: 3, EPOCH: 5, valid_loss: 0.004979642609564157\n",
      "FOLD: 3, EPOCH: 6, train_loss: 0.008186843598613868\n",
      "FOLD: 3, EPOCH: 6, valid_loss: 0.004839806423450892\n",
      "FOLD: 3, EPOCH: 7, train_loss: 0.008000770514528896\n",
      "FOLD: 3, EPOCH: 7, valid_loss: 0.004744458227203443\n",
      "FOLD: 3, EPOCH: 8, train_loss: 0.008020162418786739\n",
      "FOLD: 3, EPOCH: 8, valid_loss: 0.004773392771872191\n",
      "FOLD: 3, EPOCH: 9, train_loss: 0.007930493624125784\n",
      "FOLD: 3, EPOCH: 9, valid_loss: 0.004632109203017675\n",
      "FOLD: 3, EPOCH: 10, train_loss: 0.007928082983739473\n",
      "FOLD: 3, EPOCH: 10, valid_loss: 0.004701752967845935\n",
      "FOLD: 3, EPOCH: 11, train_loss: 0.00788118055316846\n",
      "FOLD: 3, EPOCH: 11, valid_loss: 0.004685410656608068\n",
      "FOLD: 3, EPOCH: 12, train_loss: 0.007863133151486918\n",
      "FOLD: 3, EPOCH: 12, valid_loss: 0.004641914310363622\n",
      "FOLD: 4, EPOCH: 0, train_loss: 0.578269005098657\n",
      "FOLD: 4, EPOCH: 0, valid_loss: 0.028817432574354686\n",
      "FOLD: 4, EPOCH: 1, train_loss: 0.010683444429289651\n",
      "FOLD: 4, EPOCH: 1, valid_loss: 0.004683717261426724\n",
      "FOLD: 4, EPOCH: 2, train_loss: 0.008970104818660262\n",
      "FOLD: 4, EPOCH: 2, valid_loss: 0.005037975139342821\n",
      "FOLD: 4, EPOCH: 3, train_loss: 0.009992013742039734\n",
      "FOLD: 4, EPOCH: 3, valid_loss: 0.0047602729083826905\n",
      "FOLD: 4, EPOCH: 4, train_loss: 0.008622653109046656\n",
      "FOLD: 4, EPOCH: 4, valid_loss: 0.004821154217307384\n",
      "FOLD: 4, EPOCH: 5, train_loss: 0.008405389528520204\n",
      "FOLD: 4, EPOCH: 5, valid_loss: 0.00509333352629955\n",
      "FOLD: 4, EPOCH: 6, train_loss: 0.008331828498961153\n",
      "FOLD: 4, EPOCH: 6, valid_loss: 0.004561884866024439\n",
      "FOLD: 4, EPOCH: 7, train_loss: 0.008062266946040295\n",
      "FOLD: 4, EPOCH: 7, valid_loss: 0.004687092231156735\n",
      "FOLD: 4, EPOCH: 8, train_loss: 0.007968002351353297\n",
      "FOLD: 4, EPOCH: 8, valid_loss: 0.004510139025604496\n",
      "FOLD: 4, EPOCH: 9, train_loss: 0.007928044163949183\n",
      "FOLD: 4, EPOCH: 9, valid_loss: 0.004710247095387716\n",
      "FOLD: 4, EPOCH: 10, train_loss: 0.00791280240298727\n",
      "FOLD: 4, EPOCH: 10, valid_loss: 0.0044938462714736276\n",
      "FOLD: 4, EPOCH: 11, train_loss: 0.007866947175431493\n",
      "FOLD: 4, EPOCH: 11, valid_loss: 0.0045487460537025565\n",
      "FOLD: 4, EPOCH: 12, train_loss: 0.007852601705471406\n",
      "FOLD: 4, EPOCH: 12, valid_loss: 0.004503071737977175\n",
      "FOLD: 4, EPOCH: 13, train_loss: 0.007808002378992937\n",
      "FOLD: 4, EPOCH: 13, valid_loss: 0.004610634337251003\n",
      "FOLD: 4, EPOCH: 14, train_loss: 0.007764180367057388\n",
      "FOLD: 4, EPOCH: 14, valid_loss: 0.004471656651451037\n",
      "FOLD: 4, EPOCH: 15, train_loss: 0.007712142648980827\n",
      "FOLD: 4, EPOCH: 15, valid_loss: 0.0044830522070137355\n",
      "FOLD: 5, EPOCH: 0, train_loss: 0.5755105719121324\n",
      "FOLD: 5, EPOCH: 0, valid_loss: 0.018010439351201057\n",
      "FOLD: 5, EPOCH: 1, train_loss: 0.01031940636803975\n",
      "FOLD: 5, EPOCH: 1, valid_loss: 0.004876071479744636\n",
      "FOLD: 5, EPOCH: 2, train_loss: 0.022465584579402127\n",
      "FOLD: 5, EPOCH: 2, valid_loss: 0.044375074884066217\n",
      "FOLD: 5, EPOCH: 3, train_loss: 0.01234083269043146\n",
      "FOLD: 5, EPOCH: 3, valid_loss: 0.005164455228413527\n",
      "FOLD: 5, EPOCH: 4, train_loss: 0.0097839054525704\n",
      "FOLD: 5, EPOCH: 4, valid_loss: 0.005278608940828305\n",
      "FOLD: 5, EPOCH: 5, train_loss: 0.008934852629396561\n",
      "FOLD: 5, EPOCH: 5, valid_loss: 0.005140722980006383\n",
      "FOLD: 5, EPOCH: 6, train_loss: 0.00860475456165905\n",
      "FOLD: 5, EPOCH: 6, valid_loss: 0.0051316184779772395\n",
      "FOLD: 5, EPOCH: 7, train_loss: 0.00843157380114536\n",
      "FOLD: 5, EPOCH: 7, valid_loss: 0.0050603610893281605\n",
      "FOLD: 5, EPOCH: 8, train_loss: 0.008396381940189246\n",
      "FOLD: 5, EPOCH: 8, valid_loss: 0.004862909885839774\n",
      "FOLD: 5, EPOCH: 9, train_loss: 0.00830227555077825\n",
      "FOLD: 5, EPOCH: 9, valid_loss: 0.00484252327050154\n",
      "FOLD: 5, EPOCH: 10, train_loss: 0.008237280505331786\n",
      "FOLD: 5, EPOCH: 10, valid_loss: 0.004775869839179974\n",
      "FOLD: 5, EPOCH: 11, train_loss: 0.00812149837587935\n",
      "FOLD: 5, EPOCH: 11, valid_loss: 0.0046534097681824975\n",
      "FOLD: 5, EPOCH: 12, train_loss: 0.00802038550829968\n",
      "FOLD: 5, EPOCH: 12, valid_loss: 0.00464624918710727\n",
      "FOLD: 5, EPOCH: 13, train_loss: 0.00793659848765143\n",
      "FOLD: 5, EPOCH: 13, valid_loss: 0.0046387788338156846\n",
      "FOLD: 5, EPOCH: 14, train_loss: 0.007863490294816124\n",
      "FOLD: 5, EPOCH: 14, valid_loss: 0.004560794573850357\n",
      "FOLD: 5, EPOCH: 15, train_loss: 0.007762511858615924\n",
      "FOLD: 5, EPOCH: 15, valid_loss: 0.0045303646475076675\n",
      "FOLD: 5, EPOCH: 16, train_loss: 0.007674119284225477\n",
      "FOLD: 5, EPOCH: 16, valid_loss: 0.0045496277654400235\n",
      "FOLD: 5, EPOCH: 17, train_loss: 0.007552583380979863\n",
      "FOLD: 5, EPOCH: 17, valid_loss: 0.004470414088036005\n",
      "FOLD: 5, EPOCH: 18, train_loss: 0.007429998034510661\n",
      "FOLD: 5, EPOCH: 18, valid_loss: 0.00445153617944855\n",
      "FOLD: 5, EPOCH: 19, train_loss: 0.007268617061797429\n",
      "FOLD: 5, EPOCH: 19, valid_loss: 0.004459459280881744\n",
      "FOLD: 5, EPOCH: 20, train_loss: 0.007075456298283629\n",
      "FOLD: 5, EPOCH: 20, valid_loss: 0.0044384420706102485\n",
      "FOLD: 5, EPOCH: 21, train_loss: 0.006855382061739628\n",
      "FOLD: 5, EPOCH: 21, valid_loss: 0.004428504858739101\n",
      "FOLD: 5, EPOCH: 22, train_loss: 0.006628869655164513\n",
      "FOLD: 5, EPOCH: 22, valid_loss: 0.0044516715794228594\n",
      "FOLD: 5, EPOCH: 23, train_loss: 0.006418069566574854\n",
      "FOLD: 5, EPOCH: 23, valid_loss: 0.004423708654940128\n",
      "FOLD: 5, EPOCH: 24, train_loss: 0.006262139662647167\n",
      "FOLD: 5, EPOCH: 24, valid_loss: 0.004426071957613413\n",
      "FOLD: 6, EPOCH: 0, train_loss: 0.5777896496190412\n",
      "FOLD: 6, EPOCH: 0, valid_loss: 0.023435996988644965\n",
      "FOLD: 6, EPOCH: 1, train_loss: 0.010395076604106941\n",
      "FOLD: 6, EPOCH: 1, valid_loss: 0.004735544144820709\n",
      "FOLD: 6, EPOCH: 2, train_loss: 0.008994826965185033\n",
      "FOLD: 6, EPOCH: 2, valid_loss: 0.004985180755074208\n",
      "FOLD: 6, EPOCH: 3, train_loss: 0.00874509513881561\n",
      "FOLD: 6, EPOCH: 3, valid_loss: 0.005459591137388578\n",
      "FOLD: 6, EPOCH: 4, train_loss: 0.008371701759814814\n",
      "FOLD: 6, EPOCH: 4, valid_loss: 0.005152352691556399\n",
      "FOLD: 6, EPOCH: 5, train_loss: 0.008818616788532282\n",
      "FOLD: 6, EPOCH: 5, valid_loss: 0.004885474864680033\n",
      "FOLD: 6, EPOCH: 6, train_loss: 0.008288608127701524\n",
      "FOLD: 6, EPOCH: 6, valid_loss: 0.004766166926576541\n",
      "FOLD: 6, EPOCH: 7, train_loss: 0.008139560043157355\n",
      "FOLD: 6, EPOCH: 7, valid_loss: 0.004634474977277792\n",
      "FOLD: 6, EPOCH: 8, train_loss: 0.008043528811351673\n",
      "FOLD: 6, EPOCH: 8, valid_loss: 0.00475449670249453\n",
      "FOLD: 6, EPOCH: 9, train_loss: 0.007992907886619906\n",
      "FOLD: 6, EPOCH: 9, valid_loss: 0.004742854453909855\n",
      "FOLD: 6, EPOCH: 10, train_loss: 0.007958089416796292\n",
      "FOLD: 6, EPOCH: 10, valid_loss: 0.004794981581373856\n",
      "FOLD: 6, EPOCH: 11, train_loss: 0.007931437966338283\n",
      "FOLD: 6, EPOCH: 11, valid_loss: 0.004638571901103625\n",
      "FOLD: 6, EPOCH: 12, train_loss: 0.007890770060790551\n",
      "FOLD: 6, EPOCH: 12, valid_loss: 0.00456935718942147\n",
      "FOLD: 6, EPOCH: 13, train_loss: 0.007856634684611816\n",
      "FOLD: 6, EPOCH: 13, valid_loss: 0.00470225029410078\n",
      "FOLD: 0, EPOCH: 0, train_loss: 0.5784130401506618\n",
      "FOLD: 0, EPOCH: 0, valid_loss: 0.03459232644392894\n",
      "FOLD: 0, EPOCH: 1, train_loss: 0.010538880763625776\n",
      "FOLD: 0, EPOCH: 1, valid_loss: 0.0047236125056560226\n",
      "FOLD: 0, EPOCH: 2, train_loss: 0.008882678944516826\n",
      "FOLD: 0, EPOCH: 2, valid_loss: 0.005031616032983248\n",
      "FOLD: 0, EPOCH: 3, train_loss: 0.011659404181094991\n",
      "FOLD: 0, EPOCH: 3, valid_loss: 0.004946643486618996\n",
      "FOLD: 0, EPOCH: 4, train_loss: 0.00889520875706866\n",
      "FOLD: 0, EPOCH: 4, valid_loss: 0.004906801184496054\n",
      "FOLD: 0, EPOCH: 5, train_loss: 0.008424623126818522\n",
      "FOLD: 0, EPOCH: 5, valid_loss: 0.004952638768232786\n",
      "FOLD: 0, EPOCH: 6, train_loss: 0.008337743064338292\n",
      "FOLD: 0, EPOCH: 6, valid_loss: 0.004749852017714427\n",
      "FOLD: 0, EPOCH: 7, train_loss: 0.008283129414996586\n",
      "FOLD: 0, EPOCH: 7, valid_loss: 0.004875681792887358\n",
      "FOLD: 0, EPOCH: 8, train_loss: 0.008213913269542359\n",
      "FOLD: 0, EPOCH: 8, valid_loss: 0.004748980801265974\n",
      "FOLD: 0, EPOCH: 9, train_loss: 0.008128951020488466\n",
      "FOLD: 0, EPOCH: 9, valid_loss: 0.0046319430335783045\n",
      "FOLD: 0, EPOCH: 10, train_loss: 0.00807611205036173\n",
      "FOLD: 0, EPOCH: 10, valid_loss: 0.004760127801161546\n",
      "FOLD: 0, EPOCH: 11, train_loss: 0.008012991971210451\n",
      "FOLD: 0, EPOCH: 11, valid_loss: 0.004613585447749266\n",
      "FOLD: 0, EPOCH: 12, train_loss: 0.007956795532860467\n",
      "FOLD: 0, EPOCH: 12, valid_loss: 0.004646045191643329\n",
      "FOLD: 0, EPOCH: 13, train_loss: 0.007896122327577826\n",
      "FOLD: 0, EPOCH: 13, valid_loss: 0.004565072353356159\n",
      "FOLD: 0, EPOCH: 14, train_loss: 0.007852388174600294\n",
      "FOLD: 0, EPOCH: 14, valid_loss: 0.004486823347038948\n",
      "FOLD: 0, EPOCH: 15, train_loss: 0.00777066991714811\n",
      "FOLD: 0, EPOCH: 15, valid_loss: 0.004522295382160407\n",
      "FOLD: 1, EPOCH: 0, train_loss: 0.5777452892649013\n",
      "FOLD: 1, EPOCH: 0, valid_loss: 0.030710305875310533\n",
      "FOLD: 1, EPOCH: 1, train_loss: 0.010457231260433391\n",
      "FOLD: 1, EPOCH: 1, valid_loss: 0.004669039796751279\n",
      "FOLD: 1, EPOCH: 2, train_loss: 0.009544406514111403\n",
      "FOLD: 1, EPOCH: 2, valid_loss: 0.004775233853321809\n",
      "FOLD: 1, EPOCH: 3, train_loss: 0.008794049417751061\n",
      "FOLD: 1, EPOCH: 3, valid_loss: 0.004964290437503503\n",
      "FOLD: 1, EPOCH: 4, train_loss: 0.008960590905484718\n",
      "FOLD: 1, EPOCH: 4, valid_loss: 0.0046888105213069\n",
      "FOLD: 1, EPOCH: 5, train_loss: 0.008230700541438686\n",
      "FOLD: 1, EPOCH: 5, valid_loss: 0.004876288370444224\n",
      "FOLD: 1, EPOCH: 6, train_loss: 0.008043767500517739\n",
      "FOLD: 1, EPOCH: 6, valid_loss: 0.004803417035593436\n",
      "FOLD: 1, EPOCH: 7, train_loss: 0.007949469460023416\n",
      "FOLD: 1, EPOCH: 7, valid_loss: 0.004710304765747144\n",
      "FOLD: 1, EPOCH: 8, train_loss: 0.00790997700312653\n",
      "FOLD: 1, EPOCH: 8, valid_loss: 0.004718876013962122\n",
      "FOLD: 1, EPOCH: 9, train_loss: 0.007859234597433257\n",
      "FOLD: 1, EPOCH: 9, valid_loss: 0.004634900591694391\n",
      "FOLD: 1, EPOCH: 10, train_loss: 0.007848763857288537\n",
      "FOLD: 1, EPOCH: 10, valid_loss: 0.004637398255559115\n",
      "FOLD: 1, EPOCH: 11, train_loss: 0.007819137347207681\n",
      "FOLD: 1, EPOCH: 11, valid_loss: 0.004574995917769579\n",
      "FOLD: 1, EPOCH: 12, train_loss: 0.007817226436895293\n",
      "FOLD: 1, EPOCH: 12, valid_loss: 0.004514266056223557\n",
      "FOLD: 1, EPOCH: 13, train_loss: 0.007764035546397035\n",
      "FOLD: 1, EPOCH: 13, valid_loss: 0.004606504244013474\n",
      "FOLD: 1, EPOCH: 14, train_loss: 0.007742217905517365\n",
      "FOLD: 1, EPOCH: 14, valid_loss: 0.004648711801005097\n",
      "FOLD: 2, EPOCH: 0, train_loss: 0.5757386738535117\n",
      "FOLD: 2, EPOCH: 0, valid_loss: 0.02982956128051648\n",
      "FOLD: 2, EPOCH: 1, train_loss: 0.010721499817697582\n",
      "FOLD: 2, EPOCH: 1, valid_loss: 0.0049394164234399796\n",
      "FOLD: 2, EPOCH: 2, train_loss: 0.009068037785992428\n",
      "FOLD: 2, EPOCH: 2, valid_loss: 0.004936619052806726\n",
      "FOLD: 2, EPOCH: 3, train_loss: 0.009263812104944844\n",
      "FOLD: 2, EPOCH: 3, valid_loss: 0.0047446186654269695\n",
      "FOLD: 2, EPOCH: 4, train_loss: 0.008634752285591251\n",
      "FOLD: 2, EPOCH: 4, valid_loss: 0.005181619252722997\n",
      "FOLD: 2, EPOCH: 5, train_loss: 0.008296425297000521\n",
      "FOLD: 2, EPOCH: 5, valid_loss: 0.004955849753549466\n",
      "FOLD: 2, EPOCH: 6, train_loss: 0.008163940337662762\n",
      "FOLD: 2, EPOCH: 6, valid_loss: 0.004863274785188528\n",
      "FOLD: 2, EPOCH: 7, train_loss: 0.008031243496146557\n",
      "FOLD: 2, EPOCH: 7, valid_loss: 0.0048173893099794024\n",
      "FOLD: 2, EPOCH: 8, train_loss: 0.007951137188167588\n",
      "FOLD: 2, EPOCH: 8, valid_loss: 0.0047353902974954015\n",
      "FOLD: 2, EPOCH: 9, train_loss: 0.007934551944050032\n",
      "FOLD: 2, EPOCH: 9, valid_loss: 0.004746630966949921\n",
      "FOLD: 2, EPOCH: 10, train_loss: 0.007890574885783968\n",
      "FOLD: 2, EPOCH: 10, valid_loss: 0.00465357733460573\n",
      "FOLD: 2, EPOCH: 11, train_loss: 0.007862564925154721\n",
      "FOLD: 2, EPOCH: 11, valid_loss: 0.004617108426128442\n",
      "FOLD: 2, EPOCH: 12, train_loss: 0.007844668435486587\n",
      "FOLD: 2, EPOCH: 12, valid_loss: 0.004537562445665781\n",
      "FOLD: 2, EPOCH: 13, train_loss: 0.007792832682261596\n",
      "FOLD: 2, EPOCH: 13, valid_loss: 0.004565888550132513\n",
      "FOLD: 2, EPOCH: 14, train_loss: 0.00775420492061892\n",
      "FOLD: 2, EPOCH: 14, valid_loss: 0.004702116326930432\n",
      "FOLD: 2, EPOCH: 15, train_loss: 0.007713932833458121\n",
      "FOLD: 2, EPOCH: 15, valid_loss: 0.004668851526310811\n",
      "FOLD: 2, EPOCH: 16, train_loss: 0.00764465651072159\n",
      "FOLD: 2, EPOCH: 16, valid_loss: 0.00459290686278389\n",
      "FOLD: 2, EPOCH: 17, train_loss: 0.007571540294668159\n",
      "FOLD: 2, EPOCH: 17, valid_loss: 0.004567788269084234\n",
      "FOLD: 3, EPOCH: 0, train_loss: 0.5781686253896033\n",
      "FOLD: 3, EPOCH: 0, valid_loss: 0.019102240411134865\n",
      "FOLD: 3, EPOCH: 1, train_loss: 0.010766806823478357\n",
      "FOLD: 3, EPOCH: 1, valid_loss: 0.004766531037883117\n",
      "FOLD: 3, EPOCH: 2, train_loss: 0.00901079287349775\n",
      "FOLD: 3, EPOCH: 2, valid_loss: 0.005409974389924453\n",
      "FOLD: 3, EPOCH: 3, train_loss: 0.009101554373832973\n",
      "FOLD: 3, EPOCH: 3, valid_loss: 0.004950189855522835\n",
      "FOLD: 3, EPOCH: 4, train_loss: 0.008527274369388013\n",
      "FOLD: 3, EPOCH: 4, valid_loss: 0.005667491672703853\n",
      "FOLD: 3, EPOCH: 5, train_loss: 0.008351732863465676\n",
      "FOLD: 3, EPOCH: 5, valid_loss: 0.004782896703825547\n",
      "FOLD: 3, EPOCH: 6, train_loss: 0.008133241881591242\n",
      "FOLD: 3, EPOCH: 6, valid_loss: 0.004617084999783681\n",
      "FOLD: 3, EPOCH: 7, train_loss: 0.007965372560696828\n",
      "FOLD: 3, EPOCH: 7, valid_loss: 0.004732210511484971\n",
      "FOLD: 3, EPOCH: 8, train_loss: 0.007889465303034396\n",
      "FOLD: 3, EPOCH: 8, valid_loss: 0.004537290463653894\n",
      "FOLD: 3, EPOCH: 9, train_loss: 0.007867505132044489\n",
      "FOLD: 3, EPOCH: 9, valid_loss: 0.004557958947351346\n",
      "FOLD: 3, EPOCH: 10, train_loss: 0.007841733403856287\n",
      "FOLD: 3, EPOCH: 10, valid_loss: 0.004547403086549961\n",
      "FOLD: 3, EPOCH: 11, train_loss: 0.00781376741046237\n",
      "FOLD: 3, EPOCH: 11, valid_loss: 0.004731859474514539\n",
      "FOLD: 3, EPOCH: 12, train_loss: 0.007776428511164881\n",
      "FOLD: 3, EPOCH: 12, valid_loss: 0.004656915588734241\n",
      "FOLD: 3, EPOCH: 13, train_loss: 0.007747314801137592\n",
      "FOLD: 3, EPOCH: 13, valid_loss: 0.004583010700746224\n",
      "FOLD: 4, EPOCH: 0, train_loss: 0.5777775553885747\n",
      "FOLD: 4, EPOCH: 0, valid_loss: 0.02494886159323729\n",
      "FOLD: 4, EPOCH: 1, train_loss: 0.010389739043406537\n",
      "FOLD: 4, EPOCH: 1, valid_loss: 0.004650207809530771\n",
      "FOLD: 4, EPOCH: 2, train_loss: 0.00888468196766602\n",
      "FOLD: 4, EPOCH: 2, valid_loss: 0.0051711856100994805\n",
      "FOLD: 4, EPOCH: 3, train_loss: 0.008769093458918301\n",
      "FOLD: 4, EPOCH: 3, valid_loss: 0.006867962423712015\n",
      "FOLD: 4, EPOCH: 4, train_loss: 0.009755373391247279\n",
      "FOLD: 4, EPOCH: 4, valid_loss: 0.004743892484559462\n",
      "FOLD: 4, EPOCH: 5, train_loss: 0.008398935463078119\n",
      "FOLD: 4, EPOCH: 5, valid_loss: 0.005042901155180656\n",
      "FOLD: 4, EPOCH: 6, train_loss: 0.00829757220816572\n",
      "FOLD: 4, EPOCH: 6, valid_loss: 0.005217750055285601\n",
      "FOLD: 4, EPOCH: 7, train_loss: 0.008144817875094107\n",
      "FOLD: 4, EPOCH: 7, valid_loss: 0.004738112481740804\n",
      "FOLD: 4, EPOCH: 8, train_loss: 0.008058552605074805\n",
      "FOLD: 4, EPOCH: 8, valid_loss: 0.004677568526508717\n",
      "FOLD: 4, EPOCH: 9, train_loss: 0.007994784885463683\n",
      "FOLD: 4, EPOCH: 9, valid_loss: 0.004677063964593869\n",
      "FOLD: 4, EPOCH: 10, train_loss: 0.007954015654536921\n",
      "FOLD: 4, EPOCH: 10, valid_loss: 0.004707126269260278\n",
      "FOLD: 4, EPOCH: 11, train_loss: 0.007912692802681311\n",
      "FOLD: 4, EPOCH: 11, valid_loss: 0.004607857276613896\n",
      "FOLD: 4, EPOCH: 12, train_loss: 0.007884115874263886\n",
      "FOLD: 4, EPOCH: 12, valid_loss: 0.004719285258593468\n",
      "FOLD: 5, EPOCH: 0, train_loss: 0.5776117893086897\n",
      "FOLD: 5, EPOCH: 0, valid_loss: 0.026796411866178878\n",
      "FOLD: 5, EPOCH: 1, train_loss: 0.010701928463940686\n",
      "FOLD: 5, EPOCH: 1, valid_loss: 0.004817685972039516\n",
      "FOLD: 5, EPOCH: 2, train_loss: 0.008970807111394164\n",
      "FOLD: 5, EPOCH: 2, valid_loss: 0.00552584295375989\n",
      "FOLD: 5, EPOCH: 3, train_loss: 0.008755430453331084\n",
      "FOLD: 5, EPOCH: 3, valid_loss: 0.005125779551095688\n",
      "FOLD: 5, EPOCH: 4, train_loss: 0.00856229435098735\n",
      "FOLD: 5, EPOCH: 4, valid_loss: 0.006287860469176219\n",
      "FOLD: 5, EPOCH: 5, train_loss: 0.009500625367100174\n",
      "FOLD: 5, EPOCH: 5, valid_loss: 0.0048459747877831645\n",
      "FOLD: 5, EPOCH: 6, train_loss: 0.008541571586770384\n",
      "FOLD: 5, EPOCH: 6, valid_loss: 0.004837759949553471\n",
      "FOLD: 5, EPOCH: 7, train_loss: 0.008209653437842388\n",
      "FOLD: 5, EPOCH: 7, valid_loss: 0.005068190109271269\n",
      "FOLD: 5, EPOCH: 8, train_loss: 0.00812420851827876\n",
      "FOLD: 5, EPOCH: 8, valid_loss: 0.004693302863205855\n",
      "FOLD: 5, EPOCH: 9, train_loss: 0.008018553401721088\n",
      "FOLD: 5, EPOCH: 9, valid_loss: 0.004795671297380557\n",
      "FOLD: 5, EPOCH: 10, train_loss: 0.00797713451666405\n",
      "FOLD: 5, EPOCH: 10, valid_loss: 0.004656675988091872\n",
      "FOLD: 5, EPOCH: 11, train_loss: 0.007934229435852251\n",
      "FOLD: 5, EPOCH: 11, valid_loss: 0.004671320856477206\n",
      "FOLD: 5, EPOCH: 12, train_loss: 0.007894780367260447\n",
      "FOLD: 5, EPOCH: 12, valid_loss: 0.004659637343138456\n",
      "FOLD: 5, EPOCH: 13, train_loss: 0.007877789720943247\n",
      "FOLD: 5, EPOCH: 13, valid_loss: 0.004593337420374155\n",
      "FOLD: 5, EPOCH: 14, train_loss: 0.007835368166451116\n",
      "FOLD: 5, EPOCH: 14, valid_loss: 0.004617406950833706\n",
      "FOLD: 6, EPOCH: 0, train_loss: 0.5779718179255724\n",
      "FOLD: 6, EPOCH: 0, valid_loss: 0.02093669227682627\n",
      "FOLD: 6, EPOCH: 1, train_loss: 0.01044826047192957\n",
      "FOLD: 6, EPOCH: 1, valid_loss: 0.004719903513502616\n",
      "FOLD: 6, EPOCH: 2, train_loss: 0.008897115828821788\n",
      "FOLD: 6, EPOCH: 2, valid_loss: 0.0049976817905329745\n",
      "FOLD: 6, EPOCH: 3, train_loss: 0.009221785638884112\n",
      "FOLD: 6, EPOCH: 3, valid_loss: 0.0050136064752363246\n",
      "FOLD: 6, EPOCH: 4, train_loss: 0.00844632598219087\n",
      "FOLD: 6, EPOCH: 4, valid_loss: 0.004888550056001315\n",
      "FOLD: 6, EPOCH: 5, train_loss: 0.008266719416841059\n",
      "FOLD: 6, EPOCH: 5, valid_loss: 0.004870051195701728\n",
      "FOLD: 6, EPOCH: 6, train_loss: 0.00809135616480096\n",
      "FOLD: 6, EPOCH: 6, valid_loss: 0.00472445606898803\n",
      "FOLD: 6, EPOCH: 7, train_loss: 0.007958609415721652\n",
      "FOLD: 6, EPOCH: 7, valid_loss: 0.004619015129999473\n",
      "FOLD: 6, EPOCH: 8, train_loss: 0.007913138276922542\n",
      "FOLD: 6, EPOCH: 8, valid_loss: 0.0049618842939917855\n",
      "FOLD: 6, EPOCH: 9, train_loss: 0.007859287393354886\n",
      "FOLD: 6, EPOCH: 9, valid_loss: 0.004799016966269567\n",
      "FOLD: 6, EPOCH: 10, train_loss: 0.007849975526836273\n",
      "FOLD: 6, EPOCH: 10, valid_loss: 0.004773171618580818\n",
      "FOLD: 6, EPOCH: 11, train_loss: 0.007815207241455445\n",
      "FOLD: 6, EPOCH: 11, valid_loss: 0.004586711973668291\n",
      "FOLD: 6, EPOCH: 12, train_loss: 0.007786463618882604\n",
      "FOLD: 6, EPOCH: 12, valid_loss: 0.004565432058790555\n",
      "FOLD: 6, EPOCH: 13, train_loss: 0.007773573227176392\n",
      "FOLD: 6, EPOCH: 13, valid_loss: 0.00471447089400429\n",
      "FOLD: 6, EPOCH: 14, train_loss: 0.00773678399697953\n",
      "FOLD: 6, EPOCH: 14, valid_loss: 0.004555310480869734\n",
      "FOLD: 6, EPOCH: 15, train_loss: 0.007677458893709086\n",
      "FOLD: 6, EPOCH: 15, valid_loss: 0.004520846835265939\n",
      "FOLD: 6, EPOCH: 16, train_loss: 0.007612020073055818\n",
      "FOLD: 6, EPOCH: 16, valid_loss: 0.004570549533057671\n",
      "FOLD: 0, EPOCH: 0, train_loss: 0.5779611299921935\n",
      "FOLD: 0, EPOCH: 0, valid_loss: 0.029833050158161383\n",
      "FOLD: 0, EPOCH: 1, train_loss: 0.010292063278422968\n",
      "FOLD: 0, EPOCH: 1, valid_loss: 0.004698976838531403\n",
      "FOLD: 0, EPOCH: 2, train_loss: 0.009262766487695076\n",
      "FOLD: 0, EPOCH: 2, valid_loss: 0.006551671486634474\n",
      "FOLD: 0, EPOCH: 3, train_loss: 0.008861004356043162\n",
      "FOLD: 0, EPOCH: 3, valid_loss: 0.0049297144779792195\n",
      "FOLD: 0, EPOCH: 4, train_loss: 0.00946417435173046\n",
      "FOLD: 0, EPOCH: 4, valid_loss: 0.005161130299361853\n",
      "FOLD: 0, EPOCH: 5, train_loss: 0.008683407093977203\n",
      "FOLD: 0, EPOCH: 5, valid_loss: 0.0047216638922691345\n",
      "FOLD: 0, EPOCH: 6, train_loss: 0.00822314463329275\n",
      "FOLD: 0, EPOCH: 6, valid_loss: 0.004997062138639963\n",
      "FOLD: 0, EPOCH: 7, train_loss: 0.008133946999756468\n",
      "FOLD: 0, EPOCH: 7, valid_loss: 0.004664057256797185\n",
      "FOLD: 0, EPOCH: 8, train_loss: 0.008056880321001282\n",
      "FOLD: 0, EPOCH: 8, valid_loss: 0.004712535641514338\n",
      "FOLD: 0, EPOCH: 9, train_loss: 0.008012652611108246\n",
      "FOLD: 0, EPOCH: 9, valid_loss: 0.004685291411498418\n",
      "FOLD: 0, EPOCH: 10, train_loss: 0.007964182254933828\n",
      "FOLD: 0, EPOCH: 10, valid_loss: 0.004632384480478672\n",
      "FOLD: 0, EPOCH: 11, train_loss: 0.007925315118218595\n",
      "FOLD: 0, EPOCH: 11, valid_loss: 0.004557491566699285\n",
      "FOLD: 0, EPOCH: 12, train_loss: 0.007907752438473541\n",
      "FOLD: 0, EPOCH: 12, valid_loss: 0.004593288597579186\n",
      "FOLD: 0, EPOCH: 13, train_loss: 0.007870779391629872\n",
      "FOLD: 0, EPOCH: 13, valid_loss: 0.004536144399585633\n",
      "FOLD: 0, EPOCH: 14, train_loss: 0.007822694313536221\n",
      "FOLD: 0, EPOCH: 14, valid_loss: 0.004584992447724709\n",
      "FOLD: 0, EPOCH: 15, train_loss: 0.0077858231332455135\n",
      "FOLD: 0, EPOCH: 15, valid_loss: 0.0046252305261217635\n",
      "FOLD: 1, EPOCH: 0, train_loss: 0.5770579726510757\n",
      "FOLD: 1, EPOCH: 0, valid_loss: 0.02487378051647773\n",
      "FOLD: 1, EPOCH: 1, train_loss: 0.010352480829366156\n",
      "FOLD: 1, EPOCH: 1, valid_loss: 0.0045925767984814365\n",
      "FOLD: 1, EPOCH: 2, train_loss: 0.008915839874110109\n",
      "FOLD: 1, EPOCH: 2, valid_loss: 0.004898738545867113\n",
      "FOLD: 1, EPOCH: 3, train_loss: 0.008888188302768645\n",
      "FOLD: 1, EPOCH: 3, valid_loss: 0.004957590502901719\n",
      "FOLD: 1, EPOCH: 4, train_loss: 0.02105282181622209\n",
      "FOLD: 1, EPOCH: 4, valid_loss: 0.004972774356317062\n",
      "FOLD: 1, EPOCH: 5, train_loss: 0.00883806700113456\n",
      "FOLD: 1, EPOCH: 5, valid_loss: 0.004874904317638049\n",
      "FOLD: 1, EPOCH: 6, train_loss: 0.008533005004849386\n",
      "FOLD: 1, EPOCH: 6, valid_loss: 0.0048239467164071705\n",
      "FOLD: 1, EPOCH: 7, train_loss: 0.008337709725507209\n",
      "FOLD: 1, EPOCH: 7, valid_loss: 0.0048143722188587375\n",
      "FOLD: 1, EPOCH: 8, train_loss: 0.008256110538904732\n",
      "FOLD: 1, EPOCH: 8, valid_loss: 0.004756289820831556\n",
      "FOLD: 1, EPOCH: 9, train_loss: 0.008205379271326033\n",
      "FOLD: 1, EPOCH: 9, valid_loss: 0.004939889857688775\n",
      "FOLD: 1, EPOCH: 10, train_loss: 0.00818180464636031\n",
      "FOLD: 1, EPOCH: 10, valid_loss: 0.004724641509640675\n",
      "FOLD: 1, EPOCH: 11, train_loss: 0.008079878337731635\n",
      "FOLD: 1, EPOCH: 11, valid_loss: 0.004764279887939875\n",
      "FOLD: 2, EPOCH: 0, train_loss: 0.5769532952155616\n",
      "FOLD: 2, EPOCH: 0, valid_loss: 0.022913300074063815\n",
      "FOLD: 2, EPOCH: 1, train_loss: 0.010441607455848842\n",
      "FOLD: 2, EPOCH: 1, valid_loss: 0.004659637808799744\n",
      "FOLD: 2, EPOCH: 2, train_loss: 0.017083263301567453\n",
      "FOLD: 2, EPOCH: 2, valid_loss: 0.19019873612202132\n",
      "FOLD: 2, EPOCH: 3, train_loss: 0.010734016541391611\n",
      "FOLD: 2, EPOCH: 3, valid_loss: 0.004902540419537287\n",
      "FOLD: 2, EPOCH: 4, train_loss: 0.00880064713970028\n",
      "FOLD: 2, EPOCH: 4, valid_loss: 0.005263126276146907\n",
      "FOLD: 2, EPOCH: 5, train_loss: 0.008583819562871312\n",
      "FOLD: 2, EPOCH: 5, valid_loss: 0.005090605933219194\n",
      "FOLD: 2, EPOCH: 6, train_loss: 0.008387419980371723\n",
      "FOLD: 2, EPOCH: 6, valid_loss: 0.00493781422623075\n",
      "FOLD: 2, EPOCH: 7, train_loss: 0.008278693588500892\n",
      "FOLD: 2, EPOCH: 7, valid_loss: 0.004840656076199734\n",
      "FOLD: 2, EPOCH: 8, train_loss: 0.008187412259143751\n",
      "FOLD: 2, EPOCH: 8, valid_loss: 0.004797453562227579\n",
      "FOLD: 2, EPOCH: 9, train_loss: 0.008096696941081333\n",
      "FOLD: 2, EPOCH: 9, valid_loss: 0.004840786640460675\n",
      "FOLD: 2, EPOCH: 10, train_loss: 0.008032417352739218\n",
      "FOLD: 2, EPOCH: 10, valid_loss: 0.0047915508755697655\n",
      "FOLD: 2, EPOCH: 11, train_loss: 0.00795848067296115\n",
      "FOLD: 2, EPOCH: 11, valid_loss: 0.004702450564274421\n",
      "FOLD: 3, EPOCH: 0, train_loss: 0.5766821497094792\n",
      "FOLD: 3, EPOCH: 0, valid_loss: 0.027082742263491336\n",
      "FOLD: 3, EPOCH: 1, train_loss: 0.01024166977888829\n",
      "FOLD: 3, EPOCH: 1, valid_loss: 0.004665551492227958\n",
      "FOLD: 3, EPOCH: 2, train_loss: 0.009563065071061656\n",
      "FOLD: 3, EPOCH: 2, valid_loss: 0.01167786934484656\n",
      "FOLD: 3, EPOCH: 3, train_loss: 0.009006169536528556\n",
      "FOLD: 3, EPOCH: 3, valid_loss: 0.005201530463706989\n",
      "FOLD: 3, EPOCH: 4, train_loss: 0.00860925652464298\n",
      "FOLD: 3, EPOCH: 4, valid_loss: 0.00511137625345817\n",
      "FOLD: 3, EPOCH: 5, train_loss: 0.008360178436379175\n",
      "FOLD: 3, EPOCH: 5, valid_loss: 0.005064576076200375\n",
      "FOLD: 3, EPOCH: 6, train_loss: 0.00825294993842977\n",
      "FOLD: 3, EPOCH: 6, valid_loss: 0.004611705931333395\n",
      "FOLD: 3, EPOCH: 7, train_loss: 0.008102121253221019\n",
      "FOLD: 3, EPOCH: 7, valid_loss: 0.0047614181127685765\n",
      "FOLD: 3, EPOCH: 8, train_loss: 0.007967939738788316\n",
      "FOLD: 3, EPOCH: 8, valid_loss: 0.004725013823749928\n",
      "FOLD: 3, EPOCH: 9, train_loss: 0.00792135323422986\n",
      "FOLD: 3, EPOCH: 9, valid_loss: 0.004671304235951259\n",
      "FOLD: 3, EPOCH: 10, train_loss: 0.007894881793322999\n",
      "FOLD: 3, EPOCH: 10, valid_loss: 0.004662269153274023\n",
      "FOLD: 3, EPOCH: 11, train_loss: 0.007850399782025331\n",
      "FOLD: 3, EPOCH: 11, valid_loss: 0.00470678243212975\n",
      "FOLD: 3, EPOCH: 12, train_loss: 0.007856853199317245\n",
      "FOLD: 3, EPOCH: 12, valid_loss: 0.004635369190229819\n",
      "FOLD: 4, EPOCH: 0, train_loss: 0.5771521350016465\n",
      "FOLD: 4, EPOCH: 0, valid_loss: 0.022109961996857937\n",
      "FOLD: 4, EPOCH: 1, train_loss: 0.010260448098887463\n",
      "FOLD: 4, EPOCH: 1, valid_loss: 0.004616541035759907\n",
      "FOLD: 4, EPOCH: 2, train_loss: 0.008914904222144065\n",
      "FOLD: 4, EPOCH: 2, valid_loss: 0.004906679754360364\n",
      "FOLD: 4, EPOCH: 3, train_loss: 0.01302234802671985\n",
      "FOLD: 4, EPOCH: 3, valid_loss: 0.005005734399534189\n",
      "FOLD: 4, EPOCH: 4, train_loss: 0.008793079936121767\n",
      "FOLD: 4, EPOCH: 4, valid_loss: 0.004924330394715071\n",
      "FOLD: 4, EPOCH: 5, train_loss: 0.008463044361387556\n",
      "FOLD: 4, EPOCH: 5, valid_loss: 0.004882067871781496\n",
      "FOLD: 4, EPOCH: 6, train_loss: 0.008346403609155803\n",
      "FOLD: 4, EPOCH: 6, valid_loss: 0.00478085302389585\n",
      "FOLD: 4, EPOCH: 7, train_loss: 0.00827620769976764\n",
      "FOLD: 4, EPOCH: 7, valid_loss: 0.004783654764581185\n",
      "FOLD: 4, EPOCH: 8, train_loss: 0.00820745899644051\n",
      "FOLD: 4, EPOCH: 8, valid_loss: 0.004681580520879764\n",
      "FOLD: 4, EPOCH: 9, train_loss: 0.008146014171526642\n",
      "FOLD: 4, EPOCH: 9, valid_loss: 0.004696974387535682\n",
      "FOLD: 4, EPOCH: 10, train_loss: 0.008070259732571809\n",
      "FOLD: 4, EPOCH: 10, valid_loss: 0.004652491770684719\n",
      "FOLD: 4, EPOCH: 11, train_loss: 0.008025374099914287\n",
      "FOLD: 4, EPOCH: 11, valid_loss: 0.00461422773794486\n",
      "FOLD: 4, EPOCH: 12, train_loss: 0.00797113062612511\n",
      "FOLD: 4, EPOCH: 12, valid_loss: 0.004645834784381664\n",
      "FOLD: 5, EPOCH: 0, train_loss: 0.5766843484613944\n",
      "FOLD: 5, EPOCH: 0, valid_loss: 0.02391611268887153\n",
      "FOLD: 5, EPOCH: 1, train_loss: 0.010880779902878645\n",
      "FOLD: 5, EPOCH: 1, valid_loss: 0.0047268737107515335\n",
      "FOLD: 5, EPOCH: 2, train_loss: 0.009075889722569971\n",
      "FOLD: 5, EPOCH: 2, valid_loss: 0.0052091066295710895\n",
      "FOLD: 5, EPOCH: 3, train_loss: 0.008793195545975421\n",
      "FOLD: 5, EPOCH: 3, valid_loss: 0.005094588913310032\n",
      "FOLD: 5, EPOCH: 4, train_loss: 0.008452127121288228\n",
      "FOLD: 5, EPOCH: 4, valid_loss: 0.004814969375729561\n",
      "FOLD: 5, EPOCH: 5, train_loss: 0.008427162849772218\n",
      "FOLD: 5, EPOCH: 5, valid_loss: 0.004773827090572853\n",
      "FOLD: 5, EPOCH: 6, train_loss: 0.008127729521711936\n",
      "FOLD: 5, EPOCH: 6, valid_loss: 0.004965439761200776\n",
      "FOLD: 5, EPOCH: 7, train_loss: 0.007993996306951787\n",
      "FOLD: 5, EPOCH: 7, valid_loss: 0.004613207294963873\n",
      "FOLD: 5, EPOCH: 8, train_loss: 0.007904663864472831\n",
      "FOLD: 5, EPOCH: 8, valid_loss: 0.004775805864483118\n",
      "FOLD: 5, EPOCH: 9, train_loss: 0.007892434611111073\n",
      "FOLD: 5, EPOCH: 9, valid_loss: 0.004584328701289801\n",
      "FOLD: 5, EPOCH: 10, train_loss: 0.007852869725005852\n",
      "FOLD: 5, EPOCH: 10, valid_loss: 0.004599449654611258\n",
      "FOLD: 5, EPOCH: 11, train_loss: 0.007845458694154749\n",
      "FOLD: 5, EPOCH: 11, valid_loss: 0.004667664018387978\n",
      "FOLD: 5, EPOCH: 12, train_loss: 0.007805201382300741\n",
      "FOLD: 5, EPOCH: 12, valid_loss: 0.004612073839570467\n",
      "FOLD: 5, EPOCH: 13, train_loss: 0.007778750971664448\n",
      "FOLD: 5, EPOCH: 13, valid_loss: 0.0046350863547279285\n",
      "FOLD: 6, EPOCH: 0, train_loss: 0.577402496861445\n",
      "FOLD: 6, EPOCH: 0, valid_loss: 0.03669694653497292\n",
      "FOLD: 6, EPOCH: 1, train_loss: 0.01142995129968669\n",
      "FOLD: 6, EPOCH: 1, valid_loss: 0.004783939552278473\n",
      "FOLD: 6, EPOCH: 2, train_loss: 0.00904431045558807\n",
      "FOLD: 6, EPOCH: 2, valid_loss: 0.005095841972014079\n",
      "FOLD: 6, EPOCH: 3, train_loss: 0.009476798057958886\n",
      "FOLD: 6, EPOCH: 3, valid_loss: 0.009234164339991717\n",
      "FOLD: 6, EPOCH: 4, train_loss: 0.008725066480503694\n",
      "FOLD: 6, EPOCH: 4, valid_loss: 0.004895730481411402\n",
      "FOLD: 6, EPOCH: 5, train_loss: 0.00841984578181763\n",
      "FOLD: 6, EPOCH: 5, valid_loss: 0.004691166158478994\n",
      "FOLD: 6, EPOCH: 6, train_loss: 0.00828290738895334\n",
      "FOLD: 6, EPOCH: 6, valid_loss: 0.004676688462495804\n",
      "FOLD: 6, EPOCH: 7, train_loss: 0.008106894879224332\n",
      "FOLD: 6, EPOCH: 7, valid_loss: 0.004742842525816881\n",
      "FOLD: 6, EPOCH: 8, train_loss: 0.008003496401313995\n",
      "FOLD: 6, EPOCH: 8, valid_loss: 0.00472495171169822\n",
      "FOLD: 6, EPOCH: 9, train_loss: 0.007944444836293524\n",
      "FOLD: 6, EPOCH: 9, valid_loss: 0.00465037702367856\n",
      "FOLD: 6, EPOCH: 10, train_loss: 0.007927619159926434\n",
      "FOLD: 6, EPOCH: 10, valid_loss: 0.004622215834947733\n",
      "FOLD: 6, EPOCH: 11, train_loss: 0.007882002275437117\n",
      "FOLD: 6, EPOCH: 11, valid_loss: 0.004633289618560901\n",
      "FOLD: 6, EPOCH: 12, train_loss: 0.007852290763293166\n",
      "FOLD: 6, EPOCH: 12, valid_loss: 0.004648316472482223\n",
      "FOLD: 6, EPOCH: 13, train_loss: 0.0078319643712225\n",
      "FOLD: 6, EPOCH: 13, valid_loss: 0.004548337991134479\n",
      "FOLD: 6, EPOCH: 14, train_loss: 0.007768064724734506\n",
      "FOLD: 6, EPOCH: 14, valid_loss: 0.004588619411851351\n",
      "FOLD: 6, EPOCH: 15, train_loss: 0.007740540996294569\n",
      "FOLD: 6, EPOCH: 15, valid_loss: 0.004647735828677049\n",
      "FOLD: 6, EPOCH: 16, train_loss: 0.007678951784918034\n",
      "FOLD: 6, EPOCH: 16, valid_loss: 0.0046159266494214535\n",
      "FOLD: 0, EPOCH: 0, train_loss: 0.5781545240583049\n",
      "FOLD: 0, EPOCH: 0, valid_loss: 0.027713785521112956\n",
      "FOLD: 0, EPOCH: 1, train_loss: 0.010283253721993518\n",
      "FOLD: 0, EPOCH: 1, valid_loss: 0.004675472226853554\n",
      "FOLD: 0, EPOCH: 2, train_loss: 0.00902190653456224\n",
      "FOLD: 0, EPOCH: 2, valid_loss: 0.005292366939381911\n",
      "FOLD: 0, EPOCH: 3, train_loss: 0.008770831961285424\n",
      "FOLD: 0, EPOCH: 3, valid_loss: 0.004971140064299107\n",
      "FOLD: 0, EPOCH: 4, train_loss: 0.008999917391888998\n",
      "FOLD: 0, EPOCH: 4, valid_loss: 0.004866978834168269\n",
      "FOLD: 0, EPOCH: 5, train_loss: 0.008441782462083408\n",
      "FOLD: 0, EPOCH: 5, valid_loss: 0.004978769781211248\n",
      "FOLD: 0, EPOCH: 6, train_loss: 0.008156412979587913\n",
      "FOLD: 0, EPOCH: 6, valid_loss: 0.0047453902661800385\n",
      "FOLD: 0, EPOCH: 7, train_loss: 0.008043570884478253\n",
      "FOLD: 0, EPOCH: 7, valid_loss: 0.0046328677294346\n",
      "FOLD: 0, EPOCH: 8, train_loss: 0.007967617966838786\n",
      "FOLD: 0, EPOCH: 8, valid_loss: 0.00467129320336076\n",
      "FOLD: 0, EPOCH: 9, train_loss: 0.007941721095325979\n",
      "FOLD: 0, EPOCH: 9, valid_loss: 0.004636718891561031\n",
      "FOLD: 0, EPOCH: 10, train_loss: 0.007919095620210911\n",
      "FOLD: 0, EPOCH: 10, valid_loss: 0.004658987315801473\n",
      "FOLD: 0, EPOCH: 11, train_loss: 0.007905312662793172\n",
      "FOLD: 0, EPOCH: 11, valid_loss: 0.004610352898732974\n",
      "FOLD: 0, EPOCH: 12, train_loss: 0.007891076352648638\n",
      "FOLD: 0, EPOCH: 12, valid_loss: 0.004592696562982523\n",
      "FOLD: 0, EPOCH: 13, train_loss: 0.007844850685246088\n",
      "FOLD: 0, EPOCH: 13, valid_loss: 0.0045282795237234\n",
      "FOLD: 0, EPOCH: 14, train_loss: 0.007828575533789557\n",
      "FOLD: 0, EPOCH: 14, valid_loss: 0.004525705777968352\n",
      "FOLD: 0, EPOCH: 15, train_loss: 0.007788761053234339\n",
      "FOLD: 0, EPOCH: 15, valid_loss: 0.004572063971024293\n",
      "FOLD: 0, EPOCH: 16, train_loss: 0.007746492241937164\n",
      "FOLD: 0, EPOCH: 16, valid_loss: 0.00458899477066902\n",
      "FOLD: 1, EPOCH: 0, train_loss: 0.5776108913123608\n",
      "FOLD: 1, EPOCH: 0, valid_loss: 0.035719649436382145\n",
      "FOLD: 1, EPOCH: 1, train_loss: 0.011229998658637743\n",
      "FOLD: 1, EPOCH: 1, valid_loss: 0.005010808316560892\n",
      "FOLD: 1, EPOCH: 2, train_loss: 0.009140963930435278\n",
      "FOLD: 1, EPOCH: 2, valid_loss: 0.00492394224812205\n",
      "FOLD: 1, EPOCH: 3, train_loss: 0.00895867104692435\n",
      "FOLD: 1, EPOCH: 3, valid_loss: 0.0048342118971049786\n",
      "FOLD: 1, EPOCH: 4, train_loss: 0.008894611892567293\n",
      "FOLD: 1, EPOCH: 4, valid_loss: 0.0051554290291208485\n",
      "FOLD: 1, EPOCH: 5, train_loss: 0.008622371893678163\n",
      "FOLD: 1, EPOCH: 5, valid_loss: 0.004655885026575281\n",
      "FOLD: 1, EPOCH: 6, train_loss: 0.00819789748513014\n",
      "FOLD: 1, EPOCH: 6, valid_loss: 0.004783303011208773\n",
      "FOLD: 1, EPOCH: 7, train_loss: 0.008058789884671569\n",
      "FOLD: 1, EPOCH: 7, valid_loss: 0.004669201990159659\n",
      "FOLD: 1, EPOCH: 8, train_loss: 0.007972707229389532\n",
      "FOLD: 1, EPOCH: 8, valid_loss: 0.004589344249465144\n",
      "FOLD: 1, EPOCH: 9, train_loss: 0.007930974708870053\n",
      "FOLD: 1, EPOCH: 9, valid_loss: 0.004794068347949248\n",
      "FOLD: 1, EPOCH: 10, train_loss: 0.007912031450384372\n",
      "FOLD: 1, EPOCH: 10, valid_loss: 0.004611627270395939\n",
      "FOLD: 1, EPOCH: 11, train_loss: 0.007874540808434421\n",
      "FOLD: 1, EPOCH: 11, valid_loss: 0.004694329682164467\n",
      "FOLD: 1, EPOCH: 12, train_loss: 0.007852411117857776\n",
      "FOLD: 1, EPOCH: 12, valid_loss: 0.00463517214386509\n",
      "FOLD: 1, EPOCH: 13, train_loss: 0.00783876727989598\n",
      "FOLD: 1, EPOCH: 13, valid_loss: 0.004539042084406202\n",
      "FOLD: 1, EPOCH: 14, train_loss: 0.007791247080407433\n",
      "FOLD: 1, EPOCH: 14, valid_loss: 0.004619448696478055\n",
      "FOLD: 1, EPOCH: 15, train_loss: 0.007747835681043766\n",
      "FOLD: 1, EPOCH: 15, valid_loss: 0.004605860306093326\n",
      "FOLD: 1, EPOCH: 16, train_loss: 0.007709401074444523\n",
      "FOLD: 1, EPOCH: 16, valid_loss: 0.004558831435413315\n",
      "FOLD: 2, EPOCH: 0, train_loss: 0.577679169288761\n",
      "FOLD: 2, EPOCH: 0, valid_loss: 0.025966270468555964\n",
      "FOLD: 2, EPOCH: 1, train_loss: 0.01062050776405109\n",
      "FOLD: 2, EPOCH: 1, valid_loss: 0.004736571787641599\n",
      "FOLD: 2, EPOCH: 2, train_loss: 0.00904130156000925\n",
      "FOLD: 2, EPOCH: 2, valid_loss: 0.0077991226258186195\n",
      "FOLD: 2, EPOCH: 3, train_loss: 0.009703378167909544\n",
      "FOLD: 2, EPOCH: 3, valid_loss: 0.004926392772736458\n",
      "FOLD: 2, EPOCH: 4, train_loss: 0.008427057358612483\n",
      "FOLD: 2, EPOCH: 4, valid_loss: 0.004967633921366472\n",
      "FOLD: 2, EPOCH: 5, train_loss: 0.008322411235673604\n",
      "FOLD: 2, EPOCH: 5, valid_loss: 0.00482615943138416\n",
      "FOLD: 2, EPOCH: 6, train_loss: 0.008128799151981602\n",
      "FOLD: 2, EPOCH: 6, valid_loss: 0.004897693172097206\n",
      "FOLD: 2, EPOCH: 7, train_loss: 0.008019950542901014\n",
      "FOLD: 2, EPOCH: 7, valid_loss: 0.004736467336232846\n",
      "FOLD: 2, EPOCH: 8, train_loss: 0.00800387336671151\n",
      "FOLD: 2, EPOCH: 8, valid_loss: 0.004656427647345341\n",
      "FOLD: 2, EPOCH: 9, train_loss: 0.007906344983525373\n",
      "FOLD: 2, EPOCH: 9, valid_loss: 0.004675996454002766\n",
      "FOLD: 2, EPOCH: 10, train_loss: 0.007892140105517732\n",
      "FOLD: 2, EPOCH: 10, valid_loss: 0.004602983880501527\n",
      "FOLD: 2, EPOCH: 11, train_loss: 0.007866134332190897\n",
      "FOLD: 2, EPOCH: 11, valid_loss: 0.004613581937379562\n",
      "FOLD: 2, EPOCH: 12, train_loss: 0.007821509495025148\n",
      "FOLD: 2, EPOCH: 12, valid_loss: 0.004588091674332435\n",
      "FOLD: 2, EPOCH: 13, train_loss: 0.007799600660045807\n",
      "FOLD: 2, EPOCH: 13, valid_loss: 0.004643599216181498\n",
      "FOLD: 2, EPOCH: 14, train_loss: 0.0077592691381436745\n",
      "FOLD: 2, EPOCH: 14, valid_loss: 0.004586191597179725\n",
      "FOLD: 2, EPOCH: 15, train_loss: 0.007716133882216102\n",
      "FOLD: 2, EPOCH: 15, valid_loss: 0.00460784427391795\n",
      "FOLD: 2, EPOCH: 16, train_loss: 0.007649467760898374\n",
      "FOLD: 2, EPOCH: 16, valid_loss: 0.004624626097770838\n",
      "FOLD: 3, EPOCH: 0, train_loss: 0.5763915834092611\n",
      "FOLD: 3, EPOCH: 0, valid_loss: 0.0233992153348831\n",
      "FOLD: 3, EPOCH: 1, train_loss: 0.011319744916683113\n",
      "FOLD: 3, EPOCH: 1, valid_loss: 0.004775973359266153\n",
      "FOLD: 3, EPOCH: 2, train_loss: 0.009097790943357992\n",
      "FOLD: 3, EPOCH: 2, valid_loss: 0.005320876442755644\n",
      "FOLD: 3, EPOCH: 3, train_loss: 0.009406769578974392\n",
      "FOLD: 3, EPOCH: 3, valid_loss: 0.004858651986488929\n",
      "FOLD: 3, EPOCH: 4, train_loss: 0.008491959542388449\n",
      "FOLD: 3, EPOCH: 4, valid_loss: 0.005009719922852058\n",
      "FOLD: 3, EPOCH: 5, train_loss: 0.008298923469123405\n",
      "FOLD: 3, EPOCH: 5, valid_loss: 0.004759891818349178\n",
      "FOLD: 3, EPOCH: 6, train_loss: 0.008127564923032312\n",
      "FOLD: 3, EPOCH: 6, valid_loss: 0.004751084766422327\n",
      "FOLD: 3, EPOCH: 7, train_loss: 0.008021119975711446\n",
      "FOLD: 3, EPOCH: 7, valid_loss: 0.004630959700219906\n",
      "FOLD: 3, EPOCH: 8, train_loss: 0.007921100266881892\n",
      "FOLD: 3, EPOCH: 8, valid_loss: 0.004588821759590736\n",
      "FOLD: 3, EPOCH: 9, train_loss: 0.007904530112707132\n",
      "FOLD: 3, EPOCH: 9, valid_loss: 0.004756732987096677\n",
      "FOLD: 3, EPOCH: 10, train_loss: 0.007901307396792076\n",
      "FOLD: 3, EPOCH: 10, valid_loss: 0.004728876269207551\n",
      "FOLD: 3, EPOCH: 11, train_loss: 0.007855674421817466\n",
      "FOLD: 3, EPOCH: 11, valid_loss: 0.004712928552180529\n",
      "FOLD: 3, EPOCH: 12, train_loss: 0.007850437859274648\n",
      "FOLD: 3, EPOCH: 12, valid_loss: 0.004614188085095241\n",
      "FOLD: 3, EPOCH: 13, train_loss: 0.007816859111944968\n",
      "FOLD: 3, EPOCH: 13, valid_loss: 0.0045491051860153675\n",
      "FOLD: 3, EPOCH: 14, train_loss: 0.007799475617404725\n",
      "FOLD: 3, EPOCH: 14, valid_loss: 0.004582364685260332\n",
      "FOLD: 3, EPOCH: 15, train_loss: 0.0077372639993759425\n",
      "FOLD: 3, EPOCH: 15, valid_loss: 0.004607115514003313\n",
      "FOLD: 3, EPOCH: 16, train_loss: 0.007684956065605621\n",
      "FOLD: 3, EPOCH: 16, valid_loss: 0.0045416017707723836\n",
      "FOLD: 3, EPOCH: 17, train_loss: 0.0076114915537874445\n",
      "FOLD: 3, EPOCH: 17, valid_loss: 0.004541809455706523\n",
      "FOLD: 4, EPOCH: 0, train_loss: 0.5784239619970322\n",
      "FOLD: 4, EPOCH: 0, valid_loss: 0.03450982673810078\n",
      "FOLD: 4, EPOCH: 1, train_loss: 0.01061026774648879\n",
      "FOLD: 4, EPOCH: 1, valid_loss: 0.004666009022352787\n",
      "FOLD: 4, EPOCH: 2, train_loss: 0.009015326136471453\n",
      "FOLD: 4, EPOCH: 2, valid_loss: 0.005954221965601811\n",
      "FOLD: 4, EPOCH: 3, train_loss: 0.00929316778893809\n",
      "FOLD: 4, EPOCH: 3, valid_loss: 0.004896977164137822\n",
      "FOLD: 4, EPOCH: 4, train_loss: 0.008580852249586905\n",
      "FOLD: 4, EPOCH: 4, valid_loss: 0.004984544518475349\n",
      "FOLD: 4, EPOCH: 5, train_loss: 0.008438987946892912\n",
      "FOLD: 4, EPOCH: 5, valid_loss: 0.005097001719360168\n",
      "FOLD: 4, EPOCH: 6, train_loss: 0.00817463409180778\n",
      "FOLD: 4, EPOCH: 6, valid_loss: 0.004786386011311641\n",
      "FOLD: 4, EPOCH: 7, train_loss: 0.008040364586269937\n",
      "FOLD: 4, EPOCH: 7, valid_loss: 0.004956036555365874\n",
      "FOLD: 4, EPOCH: 8, train_loss: 0.008541967543597156\n",
      "FOLD: 4, EPOCH: 8, valid_loss: 0.004595839060269869\n",
      "FOLD: 4, EPOCH: 9, train_loss: 0.0080827754116743\n",
      "FOLD: 4, EPOCH: 9, valid_loss: 0.004664010010086573\n",
      "FOLD: 4, EPOCH: 10, train_loss: 0.008011669285494733\n",
      "FOLD: 4, EPOCH: 10, valid_loss: 0.004676248770780289\n",
      "FOLD: 4, EPOCH: 11, train_loss: 0.00794955323500609\n",
      "FOLD: 4, EPOCH: 11, valid_loss: 0.004508433541139731\n",
      "FOLD: 4, EPOCH: 12, train_loss: 0.007903796438178097\n",
      "FOLD: 4, EPOCH: 12, valid_loss: 0.004625109669107657\n",
      "FOLD: 4, EPOCH: 13, train_loss: 0.00788256390699865\n",
      "FOLD: 4, EPOCH: 13, valid_loss: 0.004598140322531645\n",
      "FOLD: 5, EPOCH: 0, train_loss: 0.5778182483202702\n",
      "FOLD: 5, EPOCH: 0, valid_loss: 0.031260574236512184\n",
      "FOLD: 5, EPOCH: 1, train_loss: 0.0104021482622704\n",
      "FOLD: 5, EPOCH: 1, valid_loss: 0.004932659069219461\n",
      "FOLD: 5, EPOCH: 2, train_loss: 0.009021265709118263\n",
      "FOLD: 5, EPOCH: 2, valid_loss: 0.005230531669580019\n",
      "FOLD: 5, EPOCH: 3, train_loss: 0.01295417661753458\n",
      "FOLD: 5, EPOCH: 3, valid_loss: 0.0048778260556551125\n",
      "FOLD: 5, EPOCH: 4, train_loss: 0.008805970120168215\n",
      "FOLD: 5, EPOCH: 4, valid_loss: 0.005170849725030935\n",
      "FOLD: 5, EPOCH: 5, train_loss: 0.008503270096372108\n",
      "FOLD: 5, EPOCH: 5, valid_loss: 0.00491246459289239\n",
      "FOLD: 5, EPOCH: 6, train_loss: 0.008368336111055436\n",
      "FOLD: 5, EPOCH: 6, valid_loss: 0.005038061465781469\n",
      "FOLD: 5, EPOCH: 7, train_loss: 0.008285149592100768\n",
      "FOLD: 5, EPOCH: 7, valid_loss: 0.004916575737297535\n",
      "FOLD: 5, EPOCH: 8, train_loss: 0.008191503244578032\n",
      "FOLD: 5, EPOCH: 8, valid_loss: 0.004786986929292862\n",
      "FOLD: 5, EPOCH: 9, train_loss: 0.008090674707263306\n",
      "FOLD: 5, EPOCH: 9, valid_loss: 0.004826677533296438\n",
      "FOLD: 5, EPOCH: 10, train_loss: 0.0080226871965302\n",
      "FOLD: 5, EPOCH: 10, valid_loss: 0.004683694551483943\n",
      "FOLD: 5, EPOCH: 11, train_loss: 0.007978274216372016\n",
      "FOLD: 5, EPOCH: 11, valid_loss: 0.004597827863807862\n",
      "FOLD: 5, EPOCH: 12, train_loss: 0.007908697699423175\n",
      "FOLD: 5, EPOCH: 12, valid_loss: 0.004645322342045032\n",
      "FOLD: 5, EPOCH: 13, train_loss: 0.007865346659830696\n",
      "FOLD: 5, EPOCH: 13, valid_loss: 0.004656743902999621\n",
      "FOLD: 5, EPOCH: 14, train_loss: 0.007823570430077411\n",
      "FOLD: 5, EPOCH: 14, valid_loss: 0.004585732849171529\n",
      "FOLD: 5, EPOCH: 15, train_loss: 0.007759469252935535\n",
      "FOLD: 5, EPOCH: 15, valid_loss: 0.004667015029833867\n",
      "FOLD: 5, EPOCH: 16, train_loss: 0.007697594100357713\n",
      "FOLD: 5, EPOCH: 16, valid_loss: 0.004607601377826471\n",
      "FOLD: 6, EPOCH: 0, train_loss: 0.5786788159528294\n",
      "FOLD: 6, EPOCH: 0, valid_loss: 0.02194207004056527\n",
      "FOLD: 6, EPOCH: 1, train_loss: 0.010262733337947645\n",
      "FOLD: 6, EPOCH: 1, valid_loss: 0.004773464447890337\n",
      "FOLD: 6, EPOCH: 2, train_loss: 0.008936045162782475\n",
      "FOLD: 6, EPOCH: 2, valid_loss: 0.005260978467189348\n",
      "FOLD: 6, EPOCH: 3, train_loss: 0.009825530210258188\n",
      "FOLD: 6, EPOCH: 3, valid_loss: 0.005154126395399754\n",
      "FOLD: 6, EPOCH: 4, train_loss: 0.008591690113314905\n",
      "FOLD: 6, EPOCH: 4, valid_loss: 0.0051881251856684685\n",
      "FOLD: 6, EPOCH: 5, train_loss: 0.008438327771334632\n",
      "FOLD: 6, EPOCH: 5, valid_loss: 0.004819361994472833\n",
      "FOLD: 6, EPOCH: 6, train_loss: 0.008224312404825075\n",
      "FOLD: 6, EPOCH: 6, valid_loss: 0.0047422976662906315\n",
      "FOLD: 6, EPOCH: 7, train_loss: 0.008080147313759537\n",
      "FOLD: 6, EPOCH: 7, valid_loss: 0.004682728662513769\n",
      "FOLD: 6, EPOCH: 8, train_loss: 0.007991684172805902\n",
      "FOLD: 6, EPOCH: 8, valid_loss: 0.004714604896994738\n",
      "FOLD: 6, EPOCH: 9, train_loss: 0.007935964980640926\n",
      "FOLD: 6, EPOCH: 9, valid_loss: 0.00456985834842691\n",
      "FOLD: 6, EPOCH: 10, train_loss: 0.007908191015893544\n",
      "FOLD: 6, EPOCH: 10, valid_loss: 0.004668641405609937\n",
      "FOLD: 6, EPOCH: 11, train_loss: 0.00787642489917375\n",
      "FOLD: 6, EPOCH: 11, valid_loss: 0.004612176965635557\n",
      "FOLD: 6, EPOCH: 12, train_loss: 0.007852950844460645\n",
      "FOLD: 6, EPOCH: 12, valid_loss: 0.004587228911427351\n",
      "FOLD: 6, EPOCH: 13, train_loss: 0.007811935039589534\n",
      "FOLD: 6, EPOCH: 13, valid_loss: 0.004626858836183181\n",
      "FOLD: 6, EPOCH: 14, train_loss: 0.00777482905903378\n",
      "FOLD: 6, EPOCH: 14, valid_loss: 0.004593966278032615\n",
      "FOLD: 0, EPOCH: 0, train_loss: 0.5773002350249806\n",
      "FOLD: 0, EPOCH: 0, valid_loss: 0.02184016701693718\n",
      "FOLD: 0, EPOCH: 1, train_loss: 0.010339164137336853\n",
      "FOLD: 0, EPOCH: 1, valid_loss: 0.004631239598473677\n",
      "FOLD: 0, EPOCH: 2, train_loss: 0.008928024367353803\n",
      "FOLD: 0, EPOCH: 2, valid_loss: 0.0051561660992984586\n",
      "FOLD: 0, EPOCH: 3, train_loss: 0.008776144086811188\n",
      "FOLD: 0, EPOCH: 3, valid_loss: 0.005274407780514314\n",
      "FOLD: 0, EPOCH: 4, train_loss: 0.009492838446906692\n",
      "FOLD: 0, EPOCH: 4, valid_loss: 0.004650694497216206\n",
      "FOLD: 0, EPOCH: 5, train_loss: 0.008374647734485366\n",
      "FOLD: 0, EPOCH: 5, valid_loss: 0.005183640115249615\n",
      "FOLD: 0, EPOCH: 6, train_loss: 0.008197384999712577\n",
      "FOLD: 0, EPOCH: 6, valid_loss: 0.0047331829197131674\n",
      "FOLD: 0, EPOCH: 7, train_loss: 0.008081352174584125\n",
      "FOLD: 0, EPOCH: 7, valid_loss: 0.004645060855322159\n",
      "FOLD: 0, EPOCH: 8, train_loss: 0.008006341415583281\n",
      "FOLD: 0, EPOCH: 8, valid_loss: 0.00464596226811409\n",
      "FOLD: 0, EPOCH: 9, train_loss: 0.007952374437622525\n",
      "FOLD: 0, EPOCH: 9, valid_loss: 0.004617759528068395\n",
      "FOLD: 0, EPOCH: 10, train_loss: 0.007939025961064003\n",
      "FOLD: 0, EPOCH: 10, valid_loss: 0.004659032305845847\n",
      "FOLD: 0, EPOCH: 11, train_loss: 0.007916840586207202\n",
      "FOLD: 0, EPOCH: 11, valid_loss: 0.004482448423424592\n",
      "FOLD: 0, EPOCH: 12, train_loss: 0.00787901146513586\n",
      "FOLD: 0, EPOCH: 12, valid_loss: 0.004615698582850969\n",
      "FOLD: 0, EPOCH: 13, train_loss: 0.00784552571791652\n",
      "FOLD: 0, EPOCH: 13, valid_loss: 0.004704661703167053\n",
      "FOLD: 1, EPOCH: 0, train_loss: 0.5786306573128378\n",
      "FOLD: 1, EPOCH: 0, valid_loss: 0.02528057347696561\n",
      "FOLD: 1, EPOCH: 1, train_loss: 0.010429129432383421\n",
      "FOLD: 1, EPOCH: 1, valid_loss: 0.004659783059301285\n",
      "FOLD: 1, EPOCH: 2, train_loss: 0.008954519292692075\n",
      "FOLD: 1, EPOCH: 2, valid_loss: 0.004890155047178268\n",
      "FOLD: 1, EPOCH: 3, train_loss: 0.022920731757138227\n",
      "FOLD: 1, EPOCH: 3, valid_loss: 0.004811365623027086\n",
      "FOLD: 1, EPOCH: 4, train_loss: 0.00867915091205489\n",
      "FOLD: 1, EPOCH: 4, valid_loss: 0.00491076224268629\n",
      "FOLD: 1, EPOCH: 5, train_loss: 0.00847955360832448\n",
      "FOLD: 1, EPOCH: 5, valid_loss: 0.004834796552761243\n",
      "FOLD: 1, EPOCH: 6, train_loss: 0.008381511632202042\n",
      "FOLD: 1, EPOCH: 6, valid_loss: 0.004819580103055789\n",
      "FOLD: 1, EPOCH: 7, train_loss: 0.008323820647657723\n",
      "FOLD: 1, EPOCH: 7, valid_loss: 0.004814555008824055\n",
      "FOLD: 1, EPOCH: 8, train_loss: 0.008295730310114654\n",
      "FOLD: 1, EPOCH: 8, valid_loss: 0.0048526108193282895\n",
      "FOLD: 1, EPOCH: 9, train_loss: 0.00825016271650187\n",
      "FOLD: 1, EPOCH: 9, valid_loss: 0.004800269272751533\n",
      "FOLD: 1, EPOCH: 10, train_loss: 0.008192021808763212\n",
      "FOLD: 1, EPOCH: 10, valid_loss: 0.004722309442093739\n",
      "FOLD: 1, EPOCH: 11, train_loss: 0.008148163607394373\n",
      "FOLD: 1, EPOCH: 11, valid_loss: 0.004693648957002621\n",
      "FOLD: 2, EPOCH: 0, train_loss: 0.5774105731397867\n",
      "FOLD: 2, EPOCH: 0, valid_loss: 0.020114709694798175\n",
      "FOLD: 2, EPOCH: 1, train_loss: 0.010473817712753205\n",
      "FOLD: 2, EPOCH: 1, valid_loss: 0.004743876616255595\n",
      "FOLD: 2, EPOCH: 2, train_loss: 0.008936498855316156\n",
      "FOLD: 2, EPOCH: 2, valid_loss: 0.005293086708451693\n",
      "FOLD: 2, EPOCH: 3, train_loss: 0.009375201802499391\n",
      "FOLD: 2, EPOCH: 3, valid_loss: 0.00921078148083045\n",
      "FOLD: 2, EPOCH: 4, train_loss: 0.008831980776645848\n",
      "FOLD: 2, EPOCH: 4, valid_loss: 0.005055692082700821\n",
      "FOLD: 2, EPOCH: 5, train_loss: 0.00835513387731201\n",
      "FOLD: 2, EPOCH: 5, valid_loss: 0.004782986755554493\n",
      "FOLD: 2, EPOCH: 6, train_loss: 0.008218475088879868\n",
      "FOLD: 2, EPOCH: 6, valid_loss: 0.004798016116882746\n",
      "FOLD: 2, EPOCH: 7, train_loss: 0.00814343086519354\n",
      "FOLD: 2, EPOCH: 7, valid_loss: 0.005316237560831583\n",
      "FOLD: 2, EPOCH: 8, train_loss: 0.007999225293059607\n",
      "FOLD: 2, EPOCH: 8, valid_loss: 0.004779962930255211\n",
      "FOLD: 2, EPOCH: 9, train_loss: 0.007935064121124309\n",
      "FOLD: 2, EPOCH: 9, valid_loss: 0.004707265358704787\n",
      "FOLD: 2, EPOCH: 10, train_loss: 0.007915934056949776\n",
      "FOLD: 2, EPOCH: 10, valid_loss: 0.004628581174004536\n",
      "FOLD: 2, EPOCH: 11, train_loss: 0.007877906545291882\n",
      "FOLD: 2, EPOCH: 11, valid_loss: 0.004558076293995747\n",
      "FOLD: 2, EPOCH: 12, train_loss: 0.007867492080943004\n",
      "FOLD: 2, EPOCH: 12, valid_loss: 0.004626747507315416\n",
      "FOLD: 2, EPOCH: 13, train_loss: 0.007832601244838254\n",
      "FOLD: 2, EPOCH: 13, valid_loss: 0.00458675311305202\n",
      "FOLD: 2, EPOCH: 14, train_loss: 0.007804450906209044\n",
      "FOLD: 2, EPOCH: 14, valid_loss: 0.0045856434422043655\n",
      "FOLD: 3, EPOCH: 0, train_loss: 0.5782880747338405\n",
      "FOLD: 3, EPOCH: 0, valid_loss: 0.04093692566339786\n",
      "FOLD: 3, EPOCH: 1, train_loss: 0.010759548837872775\n",
      "FOLD: 3, EPOCH: 1, valid_loss: 0.004835203218345459\n",
      "FOLD: 3, EPOCH: 2, train_loss: 0.009035618069606859\n",
      "FOLD: 3, EPOCH: 2, valid_loss: 0.0054463735924890405\n",
      "FOLD: 3, EPOCH: 3, train_loss: 0.00909124470844462\n",
      "FOLD: 3, EPOCH: 3, valid_loss: 0.005371725294165886\n",
      "FOLD: 3, EPOCH: 4, train_loss: 0.00885268545558525\n",
      "FOLD: 3, EPOCH: 4, valid_loss: 0.004859121301426337\n",
      "FOLD: 3, EPOCH: 5, train_loss: 0.00846477215354507\n",
      "FOLD: 3, EPOCH: 5, valid_loss: 0.004789014024516711\n",
      "FOLD: 3, EPOCH: 6, train_loss: 0.008857985020841699\n",
      "FOLD: 3, EPOCH: 6, valid_loss: 0.004848579374643473\n",
      "FOLD: 3, EPOCH: 7, train_loss: 0.00835269020014518\n",
      "FOLD: 3, EPOCH: 7, valid_loss: 0.004666005404522786\n",
      "FOLD: 3, EPOCH: 8, train_loss: 0.008173415147875613\n",
      "FOLD: 3, EPOCH: 8, valid_loss: 0.004725729831709311\n",
      "FOLD: 3, EPOCH: 9, train_loss: 0.008095875067787396\n",
      "FOLD: 3, EPOCH: 9, valid_loss: 0.00476566763021625\n",
      "FOLD: 3, EPOCH: 10, train_loss: 0.008046611375804688\n",
      "FOLD: 3, EPOCH: 10, valid_loss: 0.004639625298575713\n",
      "FOLD: 3, EPOCH: 11, train_loss: 0.008003069893331142\n",
      "FOLD: 3, EPOCH: 11, valid_loss: 0.004690389184711071\n",
      "FOLD: 3, EPOCH: 12, train_loss: 0.007952707630859033\n",
      "FOLD: 3, EPOCH: 12, valid_loss: 0.004696925385640218\n",
      "FOLD: 3, EPOCH: 13, train_loss: 0.00791193452361669\n",
      "FOLD: 3, EPOCH: 13, valid_loss: 0.004691807696452508\n",
      "FOLD: 3, EPOCH: 14, train_loss: 0.007886477368506225\n",
      "FOLD: 3, EPOCH: 14, valid_loss: 0.004616148053453519\n",
      "FOLD: 3, EPOCH: 15, train_loss: 0.007845196413581033\n",
      "FOLD: 3, EPOCH: 15, valid_loss: 0.004647179900740202\n",
      "FOLD: 4, EPOCH: 0, train_loss: 0.5765911675234502\n",
      "FOLD: 4, EPOCH: 0, valid_loss: 0.03412948835354585\n",
      "FOLD: 4, EPOCH: 1, train_loss: 0.010348803011348119\n",
      "FOLD: 4, EPOCH: 1, valid_loss: 0.004800629121466325\n",
      "FOLD: 4, EPOCH: 2, train_loss: 0.010603302731052847\n",
      "FOLD: 4, EPOCH: 2, valid_loss: 0.0061182474645857625\n",
      "FOLD: 4, EPOCH: 3, train_loss: 0.009256446117384208\n",
      "FOLD: 4, EPOCH: 3, valid_loss: 0.004919044136141355\n",
      "FOLD: 4, EPOCH: 4, train_loss: 0.008568985878515083\n",
      "FOLD: 4, EPOCH: 4, valid_loss: 0.005050997751263471\n",
      "FOLD: 4, EPOCH: 5, train_loss: 0.008407715305283264\n",
      "FOLD: 4, EPOCH: 5, valid_loss: 0.005025872351745\n",
      "FOLD: 4, EPOCH: 6, train_loss: 0.008216215209481684\n",
      "FOLD: 4, EPOCH: 6, valid_loss: 0.004695842723147227\n",
      "FOLD: 4, EPOCH: 7, train_loss: 0.008118043691423294\n",
      "FOLD: 4, EPOCH: 7, valid_loss: 0.004655696988965456\n",
      "FOLD: 4, EPOCH: 8, train_loss: 0.008023657389236865\n",
      "FOLD: 4, EPOCH: 8, valid_loss: 0.004745160229504108\n",
      "FOLD: 4, EPOCH: 9, train_loss: 0.00796848680270282\n",
      "FOLD: 4, EPOCH: 9, valid_loss: 0.004568912948553379\n",
      "FOLD: 4, EPOCH: 10, train_loss: 0.007917735958471894\n",
      "FOLD: 4, EPOCH: 10, valid_loss: 0.00457488985445637\n",
      "FOLD: 4, EPOCH: 11, train_loss: 0.007887931848951691\n",
      "FOLD: 4, EPOCH: 11, valid_loss: 0.00475263069025599\n",
      "FOLD: 4, EPOCH: 12, train_loss: 0.007858037180896546\n",
      "FOLD: 4, EPOCH: 12, valid_loss: 0.004495496360155253\n",
      "FOLD: 4, EPOCH: 13, train_loss: 0.007820480780021564\n",
      "FOLD: 4, EPOCH: 13, valid_loss: 0.004525977258498852\n",
      "FOLD: 4, EPOCH: 14, train_loss: 0.007781828772528349\n",
      "FOLD: 4, EPOCH: 14, valid_loss: 0.0045596151254498046\n",
      "FOLD: 4, EPOCH: 15, train_loss: 0.007735238813266561\n",
      "FOLD: 4, EPOCH: 15, valid_loss: 0.004437104404832308\n",
      "FOLD: 4, EPOCH: 16, train_loss: 0.007686992326902377\n",
      "FOLD: 4, EPOCH: 16, valid_loss: 0.004751438418259988\n",
      "FOLD: 5, EPOCH: 0, train_loss: 0.5767426274062412\n",
      "FOLD: 5, EPOCH: 0, valid_loss: 0.018797203038747493\n",
      "FOLD: 5, EPOCH: 1, train_loss: 0.010345214210148598\n",
      "FOLD: 5, EPOCH: 1, valid_loss: 0.004922069824085786\n",
      "FOLD: 5, EPOCH: 2, train_loss: 0.00895643196496609\n",
      "FOLD: 5, EPOCH: 2, valid_loss: 0.005408896169123741\n",
      "FOLD: 5, EPOCH: 3, train_loss: 0.01451469271922031\n",
      "FOLD: 5, EPOCH: 3, valid_loss: 0.004928170524251003\n",
      "FOLD: 5, EPOCH: 4, train_loss: 0.008934905645563393\n",
      "FOLD: 5, EPOCH: 4, valid_loss: 0.005014372129852955\n",
      "FOLD: 5, EPOCH: 5, train_loss: 0.008434246841667069\n",
      "FOLD: 5, EPOCH: 5, valid_loss: 0.004936804493459372\n",
      "FOLD: 5, EPOCH: 6, train_loss: 0.008326928382991133\n",
      "FOLD: 5, EPOCH: 6, valid_loss: 0.004888302001815576\n",
      "FOLD: 5, EPOCH: 7, train_loss: 0.008262693063934913\n",
      "FOLD: 5, EPOCH: 7, valid_loss: 0.004880447334681566\n",
      "FOLD: 5, EPOCH: 8, train_loss: 0.008206020927409062\n",
      "FOLD: 5, EPOCH: 8, valid_loss: 0.004708667679761465\n",
      "FOLD: 5, EPOCH: 9, train_loss: 0.008113618279379365\n",
      "FOLD: 5, EPOCH: 9, valid_loss: 0.004723784764512227\n",
      "FOLD: 5, EPOCH: 10, train_loss: 0.008036111726903834\n",
      "FOLD: 5, EPOCH: 10, valid_loss: 0.004655882322157805\n",
      "FOLD: 5, EPOCH: 11, train_loss: 0.007967869631593695\n",
      "FOLD: 5, EPOCH: 11, valid_loss: 0.004640456145772567\n",
      "FOLD: 5, EPOCH: 12, train_loss: 0.007912592175794212\n",
      "FOLD: 5, EPOCH: 12, valid_loss: 0.004687801898958592\n",
      "FOLD: 5, EPOCH: 13, train_loss: 0.007849754753044329\n",
      "FOLD: 5, EPOCH: 13, valid_loss: 0.004613282875372813\n",
      "FOLD: 5, EPOCH: 14, train_loss: 0.007801448605400887\n",
      "FOLD: 5, EPOCH: 14, valid_loss: 0.004604952982985056\n",
      "FOLD: 5, EPOCH: 15, train_loss: 0.007723964190714665\n",
      "FOLD: 5, EPOCH: 15, valid_loss: 0.004620153098725355\n",
      "FOLD: 5, EPOCH: 16, train_loss: 0.00766287201612785\n",
      "FOLD: 5, EPOCH: 16, valid_loss: 0.004588079925339956\n",
      "FOLD: 5, EPOCH: 17, train_loss: 0.0075652665785841035\n",
      "FOLD: 5, EPOCH: 17, valid_loss: 0.004571093604541742\n",
      "FOLD: 5, EPOCH: 18, train_loss: 0.007471174442184133\n",
      "FOLD: 5, EPOCH: 18, valid_loss: 0.004518212786374183\n",
      "FOLD: 5, EPOCH: 19, train_loss: 0.007337916900428968\n",
      "FOLD: 5, EPOCH: 19, valid_loss: 0.004514279739501385\n",
      "FOLD: 5, EPOCH: 20, train_loss: 0.007195145942623148\n",
      "FOLD: 5, EPOCH: 20, valid_loss: 0.00448791877939724\n",
      "FOLD: 5, EPOCH: 21, train_loss: 0.007027433769827759\n",
      "FOLD: 5, EPOCH: 21, valid_loss: 0.004499000998643728\n",
      "FOLD: 5, EPOCH: 22, train_loss: 0.006851639233630251\n",
      "FOLD: 5, EPOCH: 22, valid_loss: 0.004480616941761512\n",
      "FOLD: 5, EPOCH: 23, train_loss: 0.006679868879350456\n",
      "FOLD: 5, EPOCH: 23, valid_loss: 0.004497277980240492\n",
      "FOLD: 5, EPOCH: 24, train_loss: 0.006576025644568978\n",
      "FOLD: 5, EPOCH: 24, valid_loss: 0.004486344324854704\n",
      "FOLD: 6, EPOCH: 0, train_loss: 0.5779183172192928\n",
      "FOLD: 6, EPOCH: 0, valid_loss: 0.028476828136123143\n",
      "FOLD: 6, EPOCH: 1, train_loss: 0.010460554546601063\n",
      "FOLD: 6, EPOCH: 1, valid_loss: 0.004749818740842434\n",
      "FOLD: 6, EPOCH: 2, train_loss: 0.008942299956657193\n",
      "FOLD: 6, EPOCH: 2, valid_loss: 0.005135606580342238\n",
      "FOLD: 6, EPOCH: 3, train_loss: 0.02247871970757842\n",
      "FOLD: 6, EPOCH: 3, valid_loss: 0.005151296285195992\n",
      "FOLD: 6, EPOCH: 4, train_loss: 0.009150994840908694\n",
      "FOLD: 6, EPOCH: 4, valid_loss: 0.005025625945283816\n",
      "FOLD: 6, EPOCH: 5, train_loss: 0.008711963206076541\n",
      "FOLD: 6, EPOCH: 5, valid_loss: 0.005261737960748947\n",
      "FOLD: 6, EPOCH: 6, train_loss: 0.008612635419578166\n",
      "FOLD: 6, EPOCH: 6, valid_loss: 0.004956232956968821\n",
      "FOLD: 6, EPOCH: 7, train_loss: 0.00847540154574892\n",
      "FOLD: 6, EPOCH: 7, valid_loss: 0.004962286338783228\n",
      "FOLD: 6, EPOCH: 8, train_loss: 0.008404951983106297\n",
      "FOLD: 6, EPOCH: 8, valid_loss: 0.004860959051606746\n",
      "FOLD: 6, EPOCH: 9, train_loss: 0.008276216383721377\n",
      "FOLD: 6, EPOCH: 9, valid_loss: 0.0048203219731266685\n",
      "FOLD: 6, EPOCH: 10, train_loss: 0.008198373856627056\n",
      "FOLD: 6, EPOCH: 10, valid_loss: 0.004710475090318001\n",
      "FOLD: 6, EPOCH: 11, train_loss: 0.008139351244411758\n",
      "FOLD: 6, EPOCH: 11, valid_loss: 0.004708591633691237\n",
      "FOLD: 6, EPOCH: 12, train_loss: 0.008047896582079498\n",
      "FOLD: 6, EPOCH: 12, valid_loss: 0.004693724071750274\n",
      "FOLD: 6, EPOCH: 13, train_loss: 0.008000688621069531\n",
      "FOLD: 6, EPOCH: 13, valid_loss: 0.004720848949196247\n",
      "FOLD: 6, EPOCH: 14, train_loss: 0.00793366920127458\n",
      "FOLD: 6, EPOCH: 14, valid_loss: 0.004673408917509592\n",
      "FOLD: 6, EPOCH: 15, train_loss: 0.007850718143320567\n",
      "FOLD: 6, EPOCH: 15, valid_loss: 0.004625700127619963\n",
      "FOLD: 6, EPOCH: 16, train_loss: 0.0077759439968881575\n",
      "FOLD: 6, EPOCH: 16, valid_loss: 0.004551445599645376\n",
      "FOLD: 6, EPOCH: 17, train_loss: 0.007696183366902374\n",
      "FOLD: 6, EPOCH: 17, valid_loss: 0.004553685484167475\n",
      "FOLD: 0, EPOCH: 0, train_loss: 0.5786345867389763\n",
      "FOLD: 0, EPOCH: 0, valid_loss: 0.02378783690241667\n",
      "FOLD: 0, EPOCH: 1, train_loss: 0.010586782547368391\n",
      "FOLD: 0, EPOCH: 1, valid_loss: 0.004849618945557337\n",
      "FOLD: 0, EPOCH: 2, train_loss: 0.009034086509632904\n",
      "FOLD: 0, EPOCH: 2, valid_loss: 0.004928860490998397\n",
      "FOLD: 0, EPOCH: 3, train_loss: 0.010571053427820271\n",
      "FOLD: 0, EPOCH: 3, valid_loss: 0.004773967362080629\n",
      "FOLD: 0, EPOCH: 4, train_loss: 0.008652042805192035\n",
      "FOLD: 0, EPOCH: 4, valid_loss: 0.004746811142048011\n",
      "FOLD: 0, EPOCH: 5, train_loss: 0.008544880991197518\n",
      "FOLD: 0, EPOCH: 5, valid_loss: 0.004910675199845662\n",
      "FOLD: 0, EPOCH: 6, train_loss: 0.008294403716619755\n",
      "FOLD: 0, EPOCH: 6, valid_loss: 0.004761596067020526\n",
      "FOLD: 0, EPOCH: 7, train_loss: 0.00814793528863103\n",
      "FOLD: 0, EPOCH: 7, valid_loss: 0.004745493069864237\n",
      "FOLD: 0, EPOCH: 8, train_loss: 0.008066800315990238\n",
      "FOLD: 0, EPOCH: 8, valid_loss: 0.004623958052924046\n",
      "FOLD: 0, EPOCH: 9, train_loss: 0.007991719122573331\n",
      "FOLD: 0, EPOCH: 9, valid_loss: 0.004705502651631832\n",
      "FOLD: 0, EPOCH: 10, train_loss: 0.007950334237082987\n",
      "FOLD: 0, EPOCH: 10, valid_loss: 0.004551891130037033\n",
      "FOLD: 0, EPOCH: 11, train_loss: 0.007903101872904477\n",
      "FOLD: 0, EPOCH: 11, valid_loss: 0.004607584434919632\n",
      "FOLD: 0, EPOCH: 12, train_loss: 0.007881704145236998\n",
      "FOLD: 0, EPOCH: 12, valid_loss: 0.004564401908562734\n",
      "FOLD: 0, EPOCH: 13, train_loss: 0.00784278244434579\n",
      "FOLD: 0, EPOCH: 13, valid_loss: 0.004576079368304748\n",
      "FOLD: 0, EPOCH: 14, train_loss: 0.007821441816820486\n",
      "FOLD: 0, EPOCH: 14, valid_loss: 0.004575218074023724\n",
      "FOLD: 0, EPOCH: 15, train_loss: 0.007765615579193911\n",
      "FOLD: 0, EPOCH: 15, valid_loss: 0.004536639970655625\n",
      "FOLD: 0, EPOCH: 16, train_loss: 0.0077018943250279975\n",
      "FOLD: 0, EPOCH: 16, valid_loss: 0.004534017402105606\n",
      "FOLD: 0, EPOCH: 17, train_loss: 0.007640980335103499\n",
      "FOLD: 0, EPOCH: 17, valid_loss: 0.0045262769652673835\n",
      "FOLD: 0, EPOCH: 18, train_loss: 0.007575224279551892\n",
      "FOLD: 0, EPOCH: 18, valid_loss: 0.0044581272925895\n",
      "FOLD: 0, EPOCH: 19, train_loss: 0.007454685539611288\n",
      "FOLD: 0, EPOCH: 19, valid_loss: 0.004548428508524711\n",
      "FOLD: 0, EPOCH: 20, train_loss: 0.007321876612164684\n",
      "FOLD: 0, EPOCH: 20, valid_loss: 0.004484667657659604\n",
      "FOLD: 1, EPOCH: 0, train_loss: 0.577879453782697\n",
      "FOLD: 1, EPOCH: 0, valid_loss: 0.03601634029585581\n",
      "FOLD: 1, EPOCH: 1, train_loss: 0.01044691471080925\n",
      "FOLD: 1, EPOCH: 1, valid_loss: 0.00460918047107183\n",
      "FOLD: 1, EPOCH: 2, train_loss: 0.008954128093161696\n",
      "FOLD: 1, EPOCH: 2, valid_loss: 0.004861513976580822\n",
      "FOLD: 1, EPOCH: 3, train_loss: 0.009142203873174416\n",
      "FOLD: 1, EPOCH: 3, valid_loss: 0.004896096240442533\n",
      "FOLD: 1, EPOCH: 4, train_loss: 0.008461854269577039\n",
      "FOLD: 1, EPOCH: 4, valid_loss: 0.004881607082027655\n",
      "FOLD: 1, EPOCH: 5, train_loss: 0.008189439251263803\n",
      "FOLD: 1, EPOCH: 5, valid_loss: 0.004791910151162973\n",
      "FOLD: 1, EPOCH: 6, train_loss: 0.008047679325918088\n",
      "FOLD: 1, EPOCH: 6, valid_loss: 0.0050013771352286525\n",
      "FOLD: 1, EPOCH: 7, train_loss: 0.008039089303614723\n",
      "FOLD: 1, EPOCH: 7, valid_loss: 0.004553812949989851\n",
      "FOLD: 1, EPOCH: 8, train_loss: 0.007935708149562817\n",
      "FOLD: 1, EPOCH: 8, valid_loss: 0.004545091812570508\n",
      "FOLD: 1, EPOCH: 9, train_loss: 0.007894240005092847\n",
      "FOLD: 1, EPOCH: 9, valid_loss: 0.004684451286895917\n",
      "FOLD: 1, EPOCH: 10, train_loss: 0.007885606166579434\n",
      "FOLD: 1, EPOCH: 10, valid_loss: 0.004660130335161319\n",
      "FOLD: 1, EPOCH: 11, train_loss: 0.007858135347330087\n",
      "FOLD: 1, EPOCH: 11, valid_loss: 0.004530784476978274\n",
      "FOLD: 1, EPOCH: 12, train_loss: 0.007847535153347495\n",
      "FOLD: 1, EPOCH: 12, valid_loss: 0.004501645901025488\n",
      "FOLD: 1, EPOCH: 13, train_loss: 0.007799369226386015\n",
      "FOLD: 1, EPOCH: 13, valid_loss: 0.004869196313218429\n",
      "FOLD: 1, EPOCH: 14, train_loss: 0.007775054936221725\n",
      "FOLD: 1, EPOCH: 14, valid_loss: 0.004591025985204256\n",
      "FOLD: 1, EPOCH: 15, train_loss: 0.0077227875149834\n",
      "FOLD: 1, EPOCH: 15, valid_loss: 0.004575022675383549\n",
      "FOLD: 2, EPOCH: 0, train_loss: 0.5799302838339999\n",
      "FOLD: 2, EPOCH: 0, valid_loss: 0.020383524493529245\n",
      "FOLD: 2, EPOCH: 1, train_loss: 0.01056382615068877\n",
      "FOLD: 2, EPOCH: 1, valid_loss: 0.004740731539921119\n",
      "FOLD: 2, EPOCH: 2, train_loss: 0.009003320350185843\n",
      "FOLD: 2, EPOCH: 2, valid_loss: 0.005026933056517289\n",
      "FOLD: 2, EPOCH: 3, train_loss: 0.009334859098433642\n",
      "FOLD: 2, EPOCH: 3, valid_loss: 0.005918376685048525\n",
      "FOLD: 2, EPOCH: 4, train_loss: 0.009171883437178424\n",
      "FOLD: 2, EPOCH: 4, valid_loss: 0.005311097090060894\n",
      "FOLD: 2, EPOCH: 5, train_loss: 0.008422754767879442\n",
      "FOLD: 2, EPOCH: 5, valid_loss: 0.005002136557148053\n",
      "FOLD: 2, EPOCH: 6, train_loss: 0.00919012720948337\n",
      "FOLD: 2, EPOCH: 6, valid_loss: 0.005219548224256589\n",
      "FOLD: 2, EPOCH: 7, train_loss: 0.008319646812270622\n",
      "FOLD: 2, EPOCH: 7, valid_loss: 0.005145544007133979\n",
      "FOLD: 2, EPOCH: 8, train_loss: 0.008233079844078905\n",
      "FOLD: 2, EPOCH: 8, valid_loss: 0.004989731698655165\n",
      "FOLD: 2, EPOCH: 9, train_loss: 0.008164804649061046\n",
      "FOLD: 2, EPOCH: 9, valid_loss: 0.004791482745741422\n",
      "FOLD: 2, EPOCH: 10, train_loss: 0.008110289002542157\n",
      "FOLD: 2, EPOCH: 10, valid_loss: 0.004856753771981368\n",
      "FOLD: 2, EPOCH: 11, train_loss: 0.00806666784793944\n",
      "FOLD: 2, EPOCH: 11, valid_loss: 0.00472415410555326\n",
      "FOLD: 2, EPOCH: 12, train_loss: 0.008013910978931832\n",
      "FOLD: 2, EPOCH: 12, valid_loss: 0.004664086342717593\n",
      "FOLD: 2, EPOCH: 13, train_loss: 0.007964804818904077\n",
      "FOLD: 2, EPOCH: 13, valid_loss: 0.004647291301248165\n",
      "FOLD: 2, EPOCH: 14, train_loss: 0.00793335129934791\n",
      "FOLD: 2, EPOCH: 14, valid_loss: 0.004689216219748442\n",
      "FOLD: 3, EPOCH: 0, train_loss: 0.5768806634823213\n",
      "FOLD: 3, EPOCH: 0, valid_loss: 0.02413751929998398\n",
      "FOLD: 3, EPOCH: 1, train_loss: 0.010403918089798174\n",
      "FOLD: 3, EPOCH: 1, valid_loss: 0.005013166210399224\n",
      "FOLD: 3, EPOCH: 2, train_loss: 0.009015119766715813\n",
      "FOLD: 3, EPOCH: 2, valid_loss: 0.00509915819678169\n",
      "FOLD: 3, EPOCH: 3, train_loss: 0.008924419689621474\n",
      "FOLD: 3, EPOCH: 3, valid_loss: 0.004820967415490976\n",
      "FOLD: 3, EPOCH: 4, train_loss: 0.008405985556089797\n",
      "FOLD: 3, EPOCH: 4, valid_loss: 0.004961113481280895\n",
      "FOLD: 3, EPOCH: 5, train_loss: 0.008214234330414518\n",
      "FOLD: 3, EPOCH: 5, valid_loss: 0.004981125740764232\n",
      "FOLD: 3, EPOCH: 6, train_loss: 0.008086338267988852\n",
      "FOLD: 3, EPOCH: 6, valid_loss: 0.004825894470111682\n",
      "FOLD: 3, EPOCH: 7, train_loss: 0.007945972362633896\n",
      "FOLD: 3, EPOCH: 7, valid_loss: 0.004528180409509402\n",
      "FOLD: 3, EPOCH: 8, train_loss: 0.007922953063924168\n",
      "FOLD: 3, EPOCH: 8, valid_loss: 0.004816995933651924\n",
      "FOLD: 3, EPOCH: 9, train_loss: 0.007878569307158122\n",
      "FOLD: 3, EPOCH: 9, valid_loss: 0.0046492763436757605\n",
      "FOLD: 3, EPOCH: 10, train_loss: 0.007870242440116566\n",
      "FOLD: 3, EPOCH: 10, valid_loss: 0.0046511726955381725\n",
      "FOLD: 3, EPOCH: 11, train_loss: 0.007847447936246926\n",
      "FOLD: 3, EPOCH: 11, valid_loss: 0.004558550981948009\n",
      "FOLD: 3, EPOCH: 12, train_loss: 0.007821085585935696\n",
      "FOLD: 3, EPOCH: 12, valid_loss: 0.004594157843922193\n",
      "FOLD: 3, EPOCH: 13, train_loss: 0.007789892717138739\n",
      "FOLD: 3, EPOCH: 13, valid_loss: 0.004649341751176577\n",
      "FOLD: 4, EPOCH: 0, train_loss: 0.5779965991859097\n",
      "FOLD: 4, EPOCH: 0, valid_loss: 0.04010038593640694\n",
      "FOLD: 4, EPOCH: 1, train_loss: 0.010432992810131731\n",
      "FOLD: 4, EPOCH: 1, valid_loss: 0.004615409281821205\n",
      "FOLD: 4, EPOCH: 2, train_loss: 0.009012690298510966\n",
      "FOLD: 4, EPOCH: 2, valid_loss: 0.005285557896758501\n",
      "FOLD: 4, EPOCH: 3, train_loss: 0.011253557595852259\n",
      "FOLD: 4, EPOCH: 3, valid_loss: 0.004852741634329924\n",
      "FOLD: 4, EPOCH: 4, train_loss: 0.008741690796120343\n",
      "FOLD: 4, EPOCH: 4, valid_loss: 0.004995692127312605\n",
      "FOLD: 4, EPOCH: 5, train_loss: 0.00895815109204803\n",
      "FOLD: 4, EPOCH: 5, valid_loss: 0.005701384399659359\n",
      "FOLD: 4, EPOCH: 6, train_loss: 0.008665413551686986\n",
      "FOLD: 4, EPOCH: 6, valid_loss: 0.00478424271568656\n",
      "FOLD: 4, EPOCH: 7, train_loss: 0.008239104953670019\n",
      "FOLD: 4, EPOCH: 7, valid_loss: 0.004813925434763615\n",
      "FOLD: 4, EPOCH: 8, train_loss: 0.008144887145356956\n",
      "FOLD: 4, EPOCH: 8, valid_loss: 0.004705998974923904\n",
      "FOLD: 4, EPOCH: 9, train_loss: 0.008073816742949389\n",
      "FOLD: 4, EPOCH: 9, valid_loss: 0.004616900741194303\n",
      "FOLD: 4, EPOCH: 10, train_loss: 0.007994600810815353\n",
      "FOLD: 4, EPOCH: 10, valid_loss: 0.004639985183110604\n",
      "FOLD: 4, EPOCH: 11, train_loss: 0.00794660734843362\n",
      "FOLD: 4, EPOCH: 11, valid_loss: 0.004563978335891779\n",
      "FOLD: 4, EPOCH: 12, train_loss: 0.007892247276833735\n",
      "FOLD: 4, EPOCH: 12, valid_loss: 0.004624720125530775\n",
      "FOLD: 5, EPOCH: 0, train_loss: 0.5779049762751203\n",
      "FOLD: 5, EPOCH: 0, valid_loss: 0.029903155250044968\n",
      "FOLD: 5, EPOCH: 1, train_loss: 0.010457740165293217\n",
      "FOLD: 5, EPOCH: 1, valid_loss: 0.0048024666567261405\n",
      "FOLD: 5, EPOCH: 2, train_loss: 0.008894528438513344\n",
      "FOLD: 5, EPOCH: 2, valid_loss: 0.005238465284212277\n",
      "FOLD: 5, EPOCH: 3, train_loss: 0.008922174371577598\n",
      "FOLD: 5, EPOCH: 3, valid_loss: 0.00510216486425354\n",
      "FOLD: 5, EPOCH: 4, train_loss: 0.008487892173532699\n",
      "FOLD: 5, EPOCH: 4, valid_loss: 0.005359887360380246\n",
      "FOLD: 5, EPOCH: 5, train_loss: 0.008276846373101344\n",
      "FOLD: 5, EPOCH: 5, valid_loss: 0.005076408099669676\n",
      "FOLD: 5, EPOCH: 6, train_loss: 0.008158406085410231\n",
      "FOLD: 5, EPOCH: 6, valid_loss: 0.004756851444164148\n",
      "FOLD: 5, EPOCH: 7, train_loss: 0.008013526342708516\n",
      "FOLD: 5, EPOCH: 7, valid_loss: 0.004676570578549917\n",
      "FOLD: 5, EPOCH: 8, train_loss: 0.007943222903319308\n",
      "FOLD: 5, EPOCH: 8, valid_loss: 0.004757875218414343\n",
      "FOLD: 5, EPOCH: 9, train_loss: 0.007927452396551097\n",
      "FOLD: 5, EPOCH: 9, valid_loss: 0.004739911295473576\n",
      "FOLD: 5, EPOCH: 10, train_loss: 0.007968896358097726\n",
      "FOLD: 5, EPOCH: 10, valid_loss: 0.006124569174761956\n",
      "FOLD: 5, EPOCH: 11, train_loss: 0.008000207895010308\n",
      "FOLD: 5, EPOCH: 11, valid_loss: 0.00461492737611899\n",
      "FOLD: 5, EPOCH: 12, train_loss: 0.007889053538894734\n",
      "FOLD: 5, EPOCH: 12, valid_loss: 0.004658867891591329\n",
      "FOLD: 5, EPOCH: 13, train_loss: 0.007856472552678472\n",
      "FOLD: 5, EPOCH: 13, valid_loss: 0.0046121387814099975\n",
      "FOLD: 5, EPOCH: 14, train_loss: 0.007834304841486988\n",
      "FOLD: 5, EPOCH: 14, valid_loss: 0.004583594102699023\n",
      "FOLD: 5, EPOCH: 15, train_loss: 0.007776593210528026\n",
      "FOLD: 5, EPOCH: 15, valid_loss: 0.0046445346222474026\n",
      "FOLD: 5, EPOCH: 16, train_loss: 0.007717733686739528\n",
      "FOLD: 5, EPOCH: 16, valid_loss: 0.004612127283158211\n",
      "FOLD: 6, EPOCH: 0, train_loss: 0.5772263179407329\n",
      "FOLD: 6, EPOCH: 0, valid_loss: 0.021943516599444244\n",
      "FOLD: 6, EPOCH: 1, train_loss: 0.010966077333668599\n",
      "FOLD: 6, EPOCH: 1, valid_loss: 0.004900557060654347\n",
      "FOLD: 6, EPOCH: 2, train_loss: 0.00911114559936765\n",
      "FOLD: 6, EPOCH: 2, valid_loss: 0.004956043146264095\n",
      "FOLD: 6, EPOCH: 3, train_loss: 0.009427280077156989\n",
      "FOLD: 6, EPOCH: 3, valid_loss: 0.0047768585097331265\n",
      "FOLD: 6, EPOCH: 4, train_loss: 0.008545606736899228\n",
      "FOLD: 6, EPOCH: 4, valid_loss: 0.004917203484532924\n",
      "FOLD: 6, EPOCH: 5, train_loss: 0.008240730998836257\n",
      "FOLD: 6, EPOCH: 5, valid_loss: 0.0047124568731165845\n",
      "FOLD: 6, EPOCH: 6, train_loss: 0.008158773441824156\n",
      "FOLD: 6, EPOCH: 6, valid_loss: 0.004775036627856584\n",
      "FOLD: 6, EPOCH: 7, train_loss: 0.008057447206984097\n",
      "FOLD: 6, EPOCH: 7, valid_loss: 0.004739887439287626\n",
      "FOLD: 6, EPOCH: 8, train_loss: 0.007922588318989083\n",
      "FOLD: 6, EPOCH: 8, valid_loss: 0.0046423436142504215\n",
      "FOLD: 6, EPOCH: 9, train_loss: 0.007893434360724044\n",
      "FOLD: 6, EPOCH: 9, valid_loss: 0.0047479306634228965\n",
      "FOLD: 6, EPOCH: 10, train_loss: 0.00789492716383491\n",
      "FOLD: 6, EPOCH: 10, valid_loss: 0.00473927312458937\n",
      "FOLD: 6, EPOCH: 11, train_loss: 0.00785588175435928\n",
      "FOLD: 6, EPOCH: 11, valid_loss: 0.004540698155044363\n",
      "FOLD: 6, EPOCH: 12, train_loss: 0.007817994973093673\n",
      "FOLD: 6, EPOCH: 12, valid_loss: 0.004730786483448286\n",
      "FOLD: 6, EPOCH: 13, train_loss: 0.0078003211198626335\n",
      "FOLD: 6, EPOCH: 13, valid_loss: 0.004622241876159723\n",
      "FOLD: 6, EPOCH: 14, train_loss: 0.007753753971711204\n",
      "FOLD: 6, EPOCH: 14, valid_loss: 0.004646495378647859\n",
      "FOLD: 6, EPOCH: 15, train_loss: 0.007726015195854612\n",
      "FOLD: 6, EPOCH: 15, valid_loss: 0.004556706390128686\n",
      "FOLD: 0, EPOCH: 0, train_loss: 0.5779975464919934\n",
      "FOLD: 0, EPOCH: 0, valid_loss: 0.023835001656642325\n",
      "FOLD: 0, EPOCH: 1, train_loss: 0.010437929033729676\n",
      "FOLD: 0, EPOCH: 1, valid_loss: 0.00464683033239383\n",
      "FOLD: 0, EPOCH: 2, train_loss: 0.009039861124915045\n",
      "FOLD: 0, EPOCH: 2, valid_loss: 0.004895195078391295\n",
      "FOLD: 0, EPOCH: 3, train_loss: 0.00882404502732931\n",
      "FOLD: 0, EPOCH: 3, valid_loss: 0.005452453051335537\n",
      "FOLD: 0, EPOCH: 4, train_loss: 0.014480597540937565\n",
      "FOLD: 0, EPOCH: 4, valid_loss: 0.004959475678893236\n",
      "FOLD: 0, EPOCH: 5, train_loss: 0.008784432568260142\n",
      "FOLD: 0, EPOCH: 5, valid_loss: 0.005088857554185849\n",
      "FOLD: 0, EPOCH: 6, train_loss: 0.008422419963706587\n",
      "FOLD: 0, EPOCH: 6, valid_loss: 0.004893729606500039\n",
      "FOLD: 0, EPOCH: 7, train_loss: 0.008321264972658577\n",
      "FOLD: 0, EPOCH: 7, valid_loss: 0.0048224965396981975\n",
      "FOLD: 0, EPOCH: 8, train_loss: 0.008251522718047773\n",
      "FOLD: 0, EPOCH: 8, valid_loss: 0.004862536962788839\n",
      "FOLD: 0, EPOCH: 9, train_loss: 0.008240669865060496\n",
      "FOLD: 0, EPOCH: 9, valid_loss: 0.004724226103952298\n",
      "FOLD: 0, EPOCH: 10, train_loss: 0.008171032887656946\n",
      "FOLD: 0, EPOCH: 10, valid_loss: 0.004715765324922709\n",
      "FOLD: 0, EPOCH: 11, train_loss: 0.008128077251131873\n",
      "FOLD: 0, EPOCH: 11, valid_loss: 0.004710912919388368\n",
      "FOLD: 1, EPOCH: 0, train_loss: 0.5769613307674188\n",
      "FOLD: 1, EPOCH: 0, valid_loss: 0.03076233772131113\n",
      "FOLD: 1, EPOCH: 1, train_loss: 0.010396270421207757\n",
      "FOLD: 1, EPOCH: 1, valid_loss: 0.004849075626295347\n",
      "FOLD: 1, EPOCH: 2, train_loss: 0.009076710884786537\n",
      "FOLD: 1, EPOCH: 2, valid_loss: 0.005639656160313349\n",
      "FOLD: 1, EPOCH: 3, train_loss: 0.009446678123109647\n",
      "FOLD: 1, EPOCH: 3, valid_loss: 0.004765906980117926\n",
      "FOLD: 1, EPOCH: 4, train_loss: 0.008570408215746284\n",
      "FOLD: 1, EPOCH: 4, valid_loss: 0.004966614696268852\n",
      "FOLD: 1, EPOCH: 5, train_loss: 0.008378583119829764\n",
      "FOLD: 1, EPOCH: 5, valid_loss: 0.005475940469365854\n",
      "FOLD: 1, EPOCH: 6, train_loss: 0.008284285966608976\n",
      "FOLD: 1, EPOCH: 6, valid_loss: 0.004833980893286375\n",
      "FOLD: 1, EPOCH: 7, train_loss: 0.008070747430964902\n",
      "FOLD: 1, EPOCH: 7, valid_loss: 0.004649063751388054\n",
      "FOLD: 1, EPOCH: 8, train_loss: 0.0079773071070982\n",
      "FOLD: 1, EPOCH: 8, valid_loss: 0.0051251699646505024\n",
      "FOLD: 1, EPOCH: 9, train_loss: 0.007934380026936933\n",
      "FOLD: 1, EPOCH: 9, valid_loss: 0.004539498468287862\n",
      "FOLD: 1, EPOCH: 10, train_loss: 0.007899087463581079\n",
      "FOLD: 1, EPOCH: 10, valid_loss: 0.004509720790128295\n",
      "FOLD: 1, EPOCH: 11, train_loss: 0.007857313065009343\n",
      "FOLD: 1, EPOCH: 11, valid_loss: 0.004878854987999568\n",
      "FOLD: 1, EPOCH: 12, train_loss: 0.007840939986242636\n",
      "FOLD: 1, EPOCH: 12, valid_loss: 0.004785767004180413\n",
      "FOLD: 1, EPOCH: 13, train_loss: 0.007819766952731722\n",
      "FOLD: 1, EPOCH: 13, valid_loss: 0.004510048400753966\n",
      "FOLD: 1, EPOCH: 14, train_loss: 0.007777440393142201\n",
      "FOLD: 1, EPOCH: 14, valid_loss: 0.004588808918085236\n",
      "FOLD: 1, EPOCH: 15, train_loss: 0.007738698632582216\n",
      "FOLD: 1, EPOCH: 15, valid_loss: 0.004489245645415325\n",
      "FOLD: 1, EPOCH: 16, train_loss: 0.007689378079580697\n",
      "FOLD: 1, EPOCH: 16, valid_loss: 0.004579792981250928\n",
      "FOLD: 2, EPOCH: 0, train_loss: 0.5776838925037835\n",
      "FOLD: 2, EPOCH: 0, valid_loss: 0.027345561923889015\n",
      "FOLD: 2, EPOCH: 1, train_loss: 0.010835316170611092\n",
      "FOLD: 2, EPOCH: 1, valid_loss: 0.004977119620889425\n",
      "FOLD: 2, EPOCH: 2, train_loss: 0.01067245234357747\n",
      "FOLD: 2, EPOCH: 2, valid_loss: 0.005754889633793097\n",
      "FOLD: 2, EPOCH: 3, train_loss: 0.00924154936109443\n",
      "FOLD: 2, EPOCH: 3, valid_loss: 0.004975465663637106\n",
      "FOLD: 2, EPOCH: 4, train_loss: 0.008669240179949918\n",
      "FOLD: 2, EPOCH: 4, valid_loss: 0.005180906934233813\n",
      "FOLD: 2, EPOCH: 5, train_loss: 0.00846483141209024\n",
      "FOLD: 2, EPOCH: 5, valid_loss: 0.004963241911564882\n",
      "FOLD: 2, EPOCH: 6, train_loss: 0.008339852088357549\n",
      "FOLD: 2, EPOCH: 6, valid_loss: 0.004789605629272186\n",
      "FOLD: 2, EPOCH: 7, train_loss: 0.008188605440679836\n",
      "FOLD: 2, EPOCH: 7, valid_loss: 0.004850376254090896\n",
      "FOLD: 2, EPOCH: 8, train_loss: 0.008082169749950236\n",
      "FOLD: 2, EPOCH: 8, valid_loss: 0.004711023890055143\n",
      "FOLD: 2, EPOCH: 9, train_loss: 0.007989876532323054\n",
      "FOLD: 2, EPOCH: 9, valid_loss: 0.004696208589638655\n",
      "FOLD: 2, EPOCH: 10, train_loss: 0.007930744716243164\n",
      "FOLD: 2, EPOCH: 10, valid_loss: 0.004627846718694155\n",
      "FOLD: 2, EPOCH: 11, train_loss: 0.00789110190738496\n",
      "FOLD: 2, EPOCH: 11, valid_loss: 0.004640240258035751\n",
      "FOLD: 2, EPOCH: 12, train_loss: 0.007855960488873156\n",
      "FOLD: 2, EPOCH: 12, valid_loss: 0.004698583426383825\n",
      "FOLD: 2, EPOCH: 13, train_loss: 0.007839856713355796\n",
      "FOLD: 2, EPOCH: 13, valid_loss: 0.004583977162837982\n",
      "FOLD: 2, EPOCH: 14, train_loss: 0.007785713256059869\n",
      "FOLD: 2, EPOCH: 14, valid_loss: 0.004593170892733794\n",
      "FOLD: 2, EPOCH: 15, train_loss: 0.007735410692623338\n",
      "FOLD: 2, EPOCH: 15, valid_loss: 0.004591664191908562\n",
      "FOLD: 2, EPOCH: 16, train_loss: 0.0077081469542070015\n",
      "FOLD: 2, EPOCH: 16, valid_loss: 0.004535614441220577\n",
      "FOLD: 2, EPOCH: 17, train_loss: 0.007634540623355959\n",
      "FOLD: 2, EPOCH: 17, valid_loss: 0.00459067437511224\n",
      "FOLD: 2, EPOCH: 18, train_loss: 0.007547969105527611\n",
      "FOLD: 2, EPOCH: 18, valid_loss: 0.004607889263962324\n",
      "FOLD: 2, EPOCH: 19, train_loss: 0.0074256532825529575\n",
      "FOLD: 2, EPOCH: 19, valid_loss: 0.004540183957522878\n",
      "FOLD: 3, EPOCH: 0, train_loss: 0.5765325667688975\n",
      "FOLD: 3, EPOCH: 0, valid_loss: 0.022971239514075793\n",
      "FOLD: 3, EPOCH: 1, train_loss: 0.010416674125637557\n",
      "FOLD: 3, EPOCH: 1, valid_loss: 0.00473837095957536\n",
      "FOLD: 3, EPOCH: 2, train_loss: 0.010471787951836313\n",
      "FOLD: 3, EPOCH: 2, valid_loss: 0.6777981152901282\n",
      "FOLD: 3, EPOCH: 3, train_loss: 0.010436725525839909\n",
      "FOLD: 3, EPOCH: 3, valid_loss: 0.00503140390635683\n",
      "FOLD: 3, EPOCH: 4, train_loss: 0.008726383011939155\n",
      "FOLD: 3, EPOCH: 4, valid_loss: 0.005064371758355544\n",
      "FOLD: 3, EPOCH: 5, train_loss: 0.008573850459494704\n",
      "FOLD: 3, EPOCH: 5, valid_loss: 0.004861168635006134\n",
      "FOLD: 3, EPOCH: 6, train_loss: 0.008376435685047024\n",
      "FOLD: 3, EPOCH: 6, valid_loss: 0.0048659190248984555\n",
      "FOLD: 3, EPOCH: 7, train_loss: 0.008258338690408179\n",
      "FOLD: 3, EPOCH: 7, valid_loss: 0.004852250719872804\n",
      "FOLD: 3, EPOCH: 8, train_loss: 0.008149750247547353\n",
      "FOLD: 3, EPOCH: 8, valid_loss: 0.004702219381355322\n",
      "FOLD: 3, EPOCH: 9, train_loss: 0.008046645022979056\n",
      "FOLD: 3, EPOCH: 9, valid_loss: 0.0046824959035103135\n",
      "FOLD: 3, EPOCH: 10, train_loss: 0.007963349293867076\n",
      "FOLD: 3, EPOCH: 10, valid_loss: 0.0047083251679746006\n",
      "FOLD: 3, EPOCH: 11, train_loss: 0.007933152273196626\n",
      "FOLD: 3, EPOCH: 11, valid_loss: 0.004713367348393569\n",
      "FOLD: 3, EPOCH: 12, train_loss: 0.007860831670916162\n",
      "FOLD: 3, EPOCH: 12, valid_loss: 0.004601300694048405\n",
      "FOLD: 3, EPOCH: 13, train_loss: 0.007809648088909485\n",
      "FOLD: 3, EPOCH: 13, valid_loss: 0.0046061062468932224\n",
      "FOLD: 3, EPOCH: 14, train_loss: 0.007744773511296591\n",
      "FOLD: 3, EPOCH: 14, valid_loss: 0.004606895041293823\n",
      "FOLD: 4, EPOCH: 0, train_loss: 0.5797941871490833\n",
      "FOLD: 4, EPOCH: 0, valid_loss: 0.04209343458597477\n",
      "FOLD: 4, EPOCH: 1, train_loss: 0.010613364784198033\n",
      "FOLD: 4, EPOCH: 1, valid_loss: 0.00466138468338893\n",
      "FOLD: 4, EPOCH: 2, train_loss: 0.0089905874023365\n",
      "FOLD: 4, EPOCH: 2, valid_loss: 0.005023666370946627\n",
      "FOLD: 4, EPOCH: 3, train_loss: 0.00878377170679537\n",
      "FOLD: 4, EPOCH: 3, valid_loss: 0.005003364004481297\n",
      "FOLD: 4, EPOCH: 4, train_loss: 0.008668632246553898\n",
      "FOLD: 4, EPOCH: 4, valid_loss: 0.0047886712978092525\n",
      "FOLD: 4, EPOCH: 5, train_loss: 0.009272494573599181\n",
      "FOLD: 4, EPOCH: 5, valid_loss: 0.0046567217661784245\n",
      "FOLD: 4, EPOCH: 6, train_loss: 0.008330767294643698\n",
      "FOLD: 4, EPOCH: 6, valid_loss: 0.005716135546278495\n",
      "FOLD: 4, EPOCH: 7, train_loss: 0.008241791800419623\n",
      "FOLD: 4, EPOCH: 7, valid_loss: 0.0049921410659757946\n",
      "FOLD: 4, EPOCH: 8, train_loss: 0.008433529049963565\n",
      "FOLD: 4, EPOCH: 8, valid_loss: 0.004702245816588402\n",
      "FOLD: 4, EPOCH: 9, train_loss: 0.008100724017650291\n",
      "FOLD: 4, EPOCH: 9, valid_loss: 0.0047543548190822965\n",
      "FOLD: 4, EPOCH: 10, train_loss: 0.00802126996898772\n",
      "FOLD: 4, EPOCH: 10, valid_loss: 0.004637246414159353\n",
      "FOLD: 4, EPOCH: 11, train_loss: 0.007975491323835543\n",
      "FOLD: 4, EPOCH: 11, valid_loss: 0.004588077167192331\n",
      "FOLD: 4, EPOCH: 12, train_loss: 0.007939194536742729\n",
      "FOLD: 4, EPOCH: 12, valid_loss: 0.004498081639982187\n",
      "FOLD: 4, EPOCH: 13, train_loss: 0.007900009045024982\n",
      "FOLD: 4, EPOCH: 13, valid_loss: 0.004529483867092774\n",
      "FOLD: 4, EPOCH: 14, train_loss: 0.007859463086100044\n",
      "FOLD: 4, EPOCH: 14, valid_loss: 0.004506963018614512\n",
      "FOLD: 4, EPOCH: 15, train_loss: 0.007822636477145794\n",
      "FOLD: 4, EPOCH: 15, valid_loss: 0.004586460033001808\n",
      "FOLD: 5, EPOCH: 0, train_loss: 0.5777798535151256\n",
      "FOLD: 5, EPOCH: 0, valid_loss: 0.023268885767230622\n",
      "FOLD: 5, EPOCH: 1, train_loss: 0.011240385888094033\n",
      "FOLD: 5, EPOCH: 1, valid_loss: 0.00490345096645447\n",
      "FOLD: 5, EPOCH: 2, train_loss: 0.009203784885136661\n",
      "FOLD: 5, EPOCH: 2, valid_loss: 0.006309567305904169\n",
      "FOLD: 5, EPOCH: 3, train_loss: 0.009531028933722424\n",
      "FOLD: 5, EPOCH: 3, valid_loss: 0.005033838276106577\n",
      "FOLD: 5, EPOCH: 4, train_loss: 0.008665345407821037\n",
      "FOLD: 5, EPOCH: 4, valid_loss: 0.005744294263422489\n",
      "FOLD: 5, EPOCH: 5, train_loss: 0.008382340710660493\n",
      "FOLD: 5, EPOCH: 5, valid_loss: 0.005062282085418701\n",
      "FOLD: 5, EPOCH: 6, train_loss: 0.008252851979655994\n",
      "FOLD: 5, EPOCH: 6, valid_loss: 0.0047995074867055966\n",
      "FOLD: 5, EPOCH: 7, train_loss: 0.00803613117770166\n",
      "FOLD: 5, EPOCH: 7, valid_loss: 0.00474747596308589\n",
      "FOLD: 5, EPOCH: 8, train_loss: 0.007995351538615855\n",
      "FOLD: 5, EPOCH: 8, valid_loss: 0.004843758705716867\n",
      "FOLD: 5, EPOCH: 9, train_loss: 0.00794137071037816\n",
      "FOLD: 5, EPOCH: 9, valid_loss: 0.0046656405051740315\n",
      "FOLD: 5, EPOCH: 10, train_loss: 0.00790713246710397\n",
      "FOLD: 5, EPOCH: 10, valid_loss: 0.004732673414624655\n",
      "FOLD: 5, EPOCH: 11, train_loss: 0.00787565843328028\n",
      "FOLD: 5, EPOCH: 11, valid_loss: 0.0047182339386871225\n",
      "FOLD: 5, EPOCH: 12, train_loss: 0.00786265589900919\n",
      "FOLD: 5, EPOCH: 12, valid_loss: 0.004648098005698278\n",
      "FOLD: 5, EPOCH: 13, train_loss: 0.007817282674934816\n",
      "FOLD: 5, EPOCH: 13, valid_loss: 0.0046820525939647965\n",
      "FOLD: 5, EPOCH: 14, train_loss: 0.0077792492984617885\n",
      "FOLD: 5, EPOCH: 14, valid_loss: 0.004522175778849767\n",
      "FOLD: 5, EPOCH: 15, train_loss: 0.007735637620695539\n",
      "FOLD: 5, EPOCH: 15, valid_loss: 0.004636747762560844\n",
      "FOLD: 5, EPOCH: 16, train_loss: 0.007685524147205256\n",
      "FOLD: 5, EPOCH: 16, valid_loss: 0.004672310279252438\n",
      "FOLD: 6, EPOCH: 0, train_loss: 0.5783209609924942\n",
      "FOLD: 6, EPOCH: 0, valid_loss: 0.024867588510880105\n",
      "FOLD: 6, EPOCH: 1, train_loss: 0.010322116390877479\n",
      "FOLD: 6, EPOCH: 1, valid_loss: 0.004677833469871145\n",
      "FOLD: 6, EPOCH: 2, train_loss: 0.00903442908531508\n",
      "FOLD: 6, EPOCH: 2, valid_loss: 0.005165006643017897\n",
      "FOLD: 6, EPOCH: 3, train_loss: 0.009420365497872635\n",
      "FOLD: 6, EPOCH: 3, valid_loss: 2.278445766522334\n",
      "FOLD: 6, EPOCH: 4, train_loss: 0.012795074238769105\n",
      "FOLD: 6, EPOCH: 4, valid_loss: 0.004964854998084215\n",
      "FOLD: 6, EPOCH: 5, train_loss: 0.00853337928954814\n",
      "FOLD: 6, EPOCH: 5, valid_loss: 0.004911594630147402\n",
      "FOLD: 6, EPOCH: 6, train_loss: 0.008377665616068486\n",
      "FOLD: 6, EPOCH: 6, valid_loss: 0.00477373399413549\n",
      "FOLD: 6, EPOCH: 7, train_loss: 0.008293591370504047\n",
      "FOLD: 6, EPOCH: 7, valid_loss: 0.0048722377978265285\n",
      "FOLD: 6, EPOCH: 8, train_loss: 0.008244365095035048\n",
      "FOLD: 6, EPOCH: 8, valid_loss: 0.004751721074661383\n",
      "FOLD: 6, EPOCH: 9, train_loss: 0.008196160008476392\n",
      "FOLD: 6, EPOCH: 9, valid_loss: 0.0047448919011423224\n",
      "FOLD: 6, EPOCH: 10, train_loss: 0.008125993838483418\n",
      "FOLD: 6, EPOCH: 10, valid_loss: 0.004765146197034762\n",
      "FOLD: 6, EPOCH: 11, train_loss: 0.008060671741495261\n",
      "FOLD: 6, EPOCH: 11, valid_loss: 0.00467140983360318\n",
      "FOLD: 6, EPOCH: 12, train_loss: 0.008011561415686801\n",
      "FOLD: 6, EPOCH: 12, valid_loss: 0.004580816486850381\n",
      "FOLD: 6, EPOCH: 13, train_loss: 0.007951122167444712\n",
      "FOLD: 6, EPOCH: 13, valid_loss: 0.004662409639702394\n"
     ]
    }
   ],
   "source": [
    "SEED = [0,1,2,3,4,5,6]\n",
    "# SEED = [14,16,77,76,34]\n",
    "# SEED = [34]\n",
    "oof = np.zeros((len(train), len(target_cols)))\n",
    "predictions = np.zeros((len(test), len(target_cols)))\n",
    "flag = True\n",
    "for seed in SEED: \n",
    "    oof_, predictions_ = run_k_fold(NFOLDS, seed)\n",
    "    oof += oof_ / len(SEED)\n",
    "    predictions += predictions_ / len(SEED)\n",
    "\n",
    "train[target_cols] = oof\n",
    "test[target_cols] = predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-20T23:44:13.950610Z",
     "iopub.status.busy": "2020-11-20T23:44:13.949619Z",
     "iopub.status.idle": "2020-11-20T23:44:14.267879Z",
     "shell.execute_reply": "2020-11-20T23:44:14.266626Z"
    },
    "papermill": {
     "duration": 0.641148,
     "end_time": "2020-11-20T23:44:14.268009",
     "exception": false,
     "start_time": "2020-11-20T23:44:13.626861",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_targets_scored = pd.read_csv('../input/lish-moa/train_targets_scored.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-20T23:44:14.913401Z",
     "iopub.status.busy": "2020-11-20T23:44:14.912028Z",
     "iopub.status.idle": "2020-11-20T23:44:15.352635Z",
     "shell.execute_reply": "2020-11-20T23:44:15.352073Z"
    },
    "papermill": {
     "duration": 0.76774,
     "end_time": "2020-11-20T23:44:15.352776",
     "exception": false,
     "start_time": "2020-11-20T23:44:14.585036",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "train = train.merge(train_targets_scored, on='sig_id')\n",
    "target = train[train_targets_scored.columns]\n",
    "target_cols = target.drop('sig_id', axis=1).columns.values.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-20T23:44:16.009432Z",
     "iopub.status.busy": "2020-11-20T23:44:16.008619Z",
     "iopub.status.idle": "2020-11-20T23:44:16.013378Z",
     "shell.execute_reply": "2020-11-20T23:44:16.012867Z"
    },
    "papermill": {
     "duration": 0.335928,
     "end_time": "2020-11-20T23:44:16.013485",
     "exception": false,
     "start_time": "2020-11-20T23:44:15.677557",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# feature_cols = [c for c in train.columns if c not in target_cols]\n",
    "# feature_cols = [c for c in feature_cols if c not in ['sig_id','kfold']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-20T23:44:16.647882Z",
     "iopub.status.busy": "2020-11-20T23:44:16.646605Z",
     "iopub.status.idle": "2020-11-20T23:44:16.833988Z",
     "shell.execute_reply": "2020-11-20T23:44:16.834513Z"
    },
    "papermill": {
     "duration": 0.506339,
     "end_time": "2020-11-20T23:44:16.834664",
     "exception": false,
     "start_time": "2020-11-20T23:44:16.328325",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1443"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feature_cols = [c for c in process_data(folds).columns if c not in target_cols]\n",
    "feature_cols = [c for c in feature_cols if c not in ['kfold','sig_id']]\n",
    "len(feature_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-20T23:44:17.490828Z",
     "iopub.status.busy": "2020-11-20T23:44:17.489480Z",
     "iopub.status.idle": "2020-11-20T23:44:20.552805Z",
     "shell.execute_reply": "2020-11-20T23:44:20.552139Z"
    },
    "papermill": {
     "duration": 3.385588,
     "end_time": "2020-11-20T23:44:20.552940",
     "exception": false,
     "start_time": "2020-11-20T23:44:17.167352",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sig_id</th>\n",
       "      <th>cp_time</th>\n",
       "      <th>cp_dose</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>...</th>\n",
       "      <th>trpv_agonist</th>\n",
       "      <th>trpv_antagonist</th>\n",
       "      <th>tubulin_inhibitor</th>\n",
       "      <th>tyrosine_kinase_inhibitor</th>\n",
       "      <th>ubiquitin_specific_protease_inhibitor</th>\n",
       "      <th>vegfr_inhibitor</th>\n",
       "      <th>vitamin_b</th>\n",
       "      <th>vitamin_d_receptor_agonist</th>\n",
       "      <th>wnt_inhibitor</th>\n",
       "      <th>kfold</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>id_000644bb2</td>\n",
       "      <td>24</td>\n",
       "      <td>D1</td>\n",
       "      <td>1.134849</td>\n",
       "      <td>0.907687</td>\n",
       "      <td>-0.416385</td>\n",
       "      <td>-0.966814</td>\n",
       "      <td>-0.254723</td>\n",
       "      <td>-1.017473</td>\n",
       "      <td>-1.364787</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>id_000779bfc</td>\n",
       "      <td>72</td>\n",
       "      <td>D1</td>\n",
       "      <td>0.119282</td>\n",
       "      <td>0.681738</td>\n",
       "      <td>0.272399</td>\n",
       "      <td>0.080113</td>\n",
       "      <td>1.205169</td>\n",
       "      <td>0.686517</td>\n",
       "      <td>0.313396</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>id_000a6266a</td>\n",
       "      <td>48</td>\n",
       "      <td>D1</td>\n",
       "      <td>0.779973</td>\n",
       "      <td>0.946463</td>\n",
       "      <td>1.425350</td>\n",
       "      <td>-0.132928</td>\n",
       "      <td>-0.006122</td>\n",
       "      <td>1.492493</td>\n",
       "      <td>0.235577</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>id_0015fd391</td>\n",
       "      <td>48</td>\n",
       "      <td>D1</td>\n",
       "      <td>-0.734910</td>\n",
       "      <td>-0.274641</td>\n",
       "      <td>-0.438509</td>\n",
       "      <td>0.759097</td>\n",
       "      <td>2.346330</td>\n",
       "      <td>-0.858153</td>\n",
       "      <td>-2.288417</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>id_001626bd3</td>\n",
       "      <td>72</td>\n",
       "      <td>D2</td>\n",
       "      <td>-0.452718</td>\n",
       "      <td>-0.477513</td>\n",
       "      <td>0.972316</td>\n",
       "      <td>0.970731</td>\n",
       "      <td>1.463427</td>\n",
       "      <td>-0.869555</td>\n",
       "      <td>-0.375501</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21943</th>\n",
       "      <td>id_fff8c2444</td>\n",
       "      <td>72</td>\n",
       "      <td>D1</td>\n",
       "      <td>0.237856</td>\n",
       "      <td>-1.228203</td>\n",
       "      <td>0.218376</td>\n",
       "      <td>-0.365976</td>\n",
       "      <td>-0.330177</td>\n",
       "      <td>0.569243</td>\n",
       "      <td>-0.150978</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21944</th>\n",
       "      <td>id_fffb1ceed</td>\n",
       "      <td>24</td>\n",
       "      <td>D2</td>\n",
       "      <td>0.209361</td>\n",
       "      <td>-0.022389</td>\n",
       "      <td>-0.235888</td>\n",
       "      <td>-0.796989</td>\n",
       "      <td>-0.674009</td>\n",
       "      <td>0.919312</td>\n",
       "      <td>0.735603</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21945</th>\n",
       "      <td>id_fffb70c0c</td>\n",
       "      <td>24</td>\n",
       "      <td>D2</td>\n",
       "      <td>-1.911021</td>\n",
       "      <td>0.587228</td>\n",
       "      <td>-0.588417</td>\n",
       "      <td>1.296405</td>\n",
       "      <td>-1.002640</td>\n",
       "      <td>0.850589</td>\n",
       "      <td>-0.304313</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21946</th>\n",
       "      <td>id_fffcb9e7c</td>\n",
       "      <td>24</td>\n",
       "      <td>D1</td>\n",
       "      <td>0.816407</td>\n",
       "      <td>0.417618</td>\n",
       "      <td>0.431631</td>\n",
       "      <td>0.300617</td>\n",
       "      <td>1.070346</td>\n",
       "      <td>-0.024189</td>\n",
       "      <td>0.048942</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21947</th>\n",
       "      <td>id_ffffdd77b</td>\n",
       "      <td>72</td>\n",
       "      <td>D1</td>\n",
       "      <td>-1.243096</td>\n",
       "      <td>1.567730</td>\n",
       "      <td>-0.269573</td>\n",
       "      <td>1.083636</td>\n",
       "      <td>-0.511235</td>\n",
       "      <td>-2.099634</td>\n",
       "      <td>-1.622462</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>21948 rows Ã— 1648 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             sig_id cp_time cp_dose         0         1         2         3  \\\n",
       "0      id_000644bb2      24      D1  1.134849  0.907687 -0.416385 -0.966814   \n",
       "1      id_000779bfc      72      D1  0.119282  0.681738  0.272399  0.080113   \n",
       "2      id_000a6266a      48      D1  0.779973  0.946463  1.425350 -0.132928   \n",
       "3      id_0015fd391      48      D1 -0.734910 -0.274641 -0.438509  0.759097   \n",
       "4      id_001626bd3      72      D2 -0.452718 -0.477513  0.972316  0.970731   \n",
       "...             ...     ...     ...       ...       ...       ...       ...   \n",
       "21943  id_fff8c2444      72      D1  0.237856 -1.228203  0.218376 -0.365976   \n",
       "21944  id_fffb1ceed      24      D2  0.209361 -0.022389 -0.235888 -0.796989   \n",
       "21945  id_fffb70c0c      24      D2 -1.911021  0.587228 -0.588417  1.296405   \n",
       "21946  id_fffcb9e7c      24      D1  0.816407  0.417618  0.431631  0.300617   \n",
       "21947  id_ffffdd77b      72      D1 -1.243096  1.567730 -0.269573  1.083636   \n",
       "\n",
       "              4         5         6  ...  trpv_agonist  trpv_antagonist  \\\n",
       "0     -0.254723 -1.017473 -1.364787  ...             0                0   \n",
       "1      1.205169  0.686517  0.313396  ...             0                0   \n",
       "2     -0.006122  1.492493  0.235577  ...             0                0   \n",
       "3      2.346330 -0.858153 -2.288417  ...             0                0   \n",
       "4      1.463427 -0.869555 -0.375501  ...             0                0   \n",
       "...         ...       ...       ...  ...           ...              ...   \n",
       "21943 -0.330177  0.569243 -0.150978  ...             0                0   \n",
       "21944 -0.674009  0.919312  0.735603  ...             0                0   \n",
       "21945 -1.002640  0.850589 -0.304313  ...             0                0   \n",
       "21946  1.070346 -0.024189  0.048942  ...             0                0   \n",
       "21947 -0.511235 -2.099634 -1.622462  ...             0                0   \n",
       "\n",
       "       tubulin_inhibitor  tyrosine_kinase_inhibitor  \\\n",
       "0                      0                          0   \n",
       "1                      0                          0   \n",
       "2                      0                          0   \n",
       "3                      0                          0   \n",
       "4                      0                          0   \n",
       "...                  ...                        ...   \n",
       "21943                  0                          0   \n",
       "21944                  0                          0   \n",
       "21945                  0                          0   \n",
       "21946                  0                          0   \n",
       "21947                  0                          0   \n",
       "\n",
       "       ubiquitin_specific_protease_inhibitor  vegfr_inhibitor  vitamin_b  \\\n",
       "0                                          0                0          0   \n",
       "1                                          0                0          0   \n",
       "2                                          0                0          0   \n",
       "3                                          0                0          0   \n",
       "4                                          0                0          0   \n",
       "...                                      ...              ...        ...   \n",
       "21943                                      0                0          0   \n",
       "21944                                      0                0          0   \n",
       "21945                                      0                0          0   \n",
       "21946                                      0                0          0   \n",
       "21947                                      0                0          0   \n",
       "\n",
       "       vitamin_d_receptor_agonist  wnt_inhibitor  kfold  \n",
       "0                               0              0      6  \n",
       "1                               0              0      5  \n",
       "2                               0              0      5  \n",
       "3                               0              0      0  \n",
       "4                               0              0      1  \n",
       "...                           ...            ...    ...  \n",
       "21943                           0              0      0  \n",
       "21944                           0              0      4  \n",
       "21945                           0              0      4  \n",
       "21946                           0              0      1  \n",
       "21947                           0              0      0  \n",
       "\n",
       "[21948 rows x 1648 columns]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "folds = train.copy()\n",
    "\n",
    "mskf = MultilabelStratifiedKFold(n_splits=7)\n",
    "\n",
    "for f, (t_idx, v_idx) in enumerate(mskf.split(X=train, y=target)):\n",
    "    folds.loc[v_idx, 'kfold'] = int(f)\n",
    "\n",
    "folds['kfold'] = folds['kfold'].astype(int)\n",
    "folds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-20T23:44:21.257995Z",
     "iopub.status.busy": "2020-11-20T23:44:21.256977Z",
     "iopub.status.idle": "2020-11-20T23:44:21.260106Z",
     "shell.execute_reply": "2020-11-20T23:44:21.259534Z"
    },
    "papermill": {
     "duration": 0.341885,
     "end_time": "2020-11-20T23:44:21.260213",
     "exception": false,
     "start_time": "2020-11-20T23:44:20.918328",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "EPOCHS = 26\n",
    "BATCH_SIZE = 256\n",
    "LEARNING_RATE = 6e-4\n",
    "WEIGHT_DECAY = 1e-5\n",
    "NFOLDS = 7\n",
    "EARLY_STOPPING_STEPS = 10\n",
    "EARLY_STOP = True\n",
    "\n",
    "num_features=len(feature_cols)\n",
    "num_targets=len(target_cols)\n",
    "hidden_size=2048"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-20T23:44:21.986006Z",
     "iopub.status.busy": "2020-11-20T23:44:21.984985Z",
     "iopub.status.idle": "2020-11-20T23:44:22.029373Z",
     "shell.execute_reply": "2020-11-20T23:44:22.028157Z"
    },
    "papermill": {
     "duration": 0.449235,
     "end_time": "2020-11-20T23:44:22.029539",
     "exception": false,
     "start_time": "2020-11-20T23:44:21.580304",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def run_training(fold, seed):\n",
    "    \n",
    "    seed_everything(seed)\n",
    "    \n",
    "    train = process_data(folds)\n",
    "    test_ = process_data(test)\n",
    "\n",
    "    \n",
    "    \n",
    "    trn_idx = train[train['kfold'] != fold].index\n",
    "    val_idx = train[train['kfold'] == fold].index\n",
    "    \n",
    "    train_df = train[train['kfold'] != fold].reset_index(drop=True)\n",
    "    valid_df = train[train['kfold'] == fold].reset_index(drop=True)\n",
    "    \n",
    "    x_train, y_train  = train_df[feature_cols].values, train_df[target_cols].values\n",
    "    x_valid, y_valid =  valid_df[feature_cols].values, valid_df[target_cols].values\n",
    "    \n",
    "    train_dataset = MoADataset(x_train, y_train)\n",
    "    valid_dataset = MoADataset(x_valid, y_valid)\n",
    "    trainloader = torch.utils.data.DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True)\n",
    "    validloader = torch.utils.data.DataLoader(valid_dataset, batch_size=BATCH_SIZE, shuffle=False)\n",
    "    \n",
    "    model = Model(\n",
    "        num_features=num_features,\n",
    "        num_targets=num_targets,\n",
    "        hidden_size=hidden_size,\n",
    "    )\n",
    "    \n",
    "    model.to(DEVICE)\n",
    "    \n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=LEARNING_RATE, weight_decay=WEIGHT_DECAY)\n",
    "    scheduler = optim.lr_scheduler.OneCycleLR(optimizer=optimizer, pct_start=0.1, div_factor=1e3, \n",
    "                                              max_lr=1e-2, epochs=EPOCHS, steps_per_epoch=len(trainloader))\n",
    "    \n",
    "    loss_fn = nn.BCEWithLogitsLoss()\n",
    "    loss_tr = SmoothBCEwLogits(smoothing =0.001)\n",
    "    \n",
    "    early_stopping_steps = EARLY_STOPPING_STEPS\n",
    "    early_step = 0\n",
    "   \n",
    "    oof = np.zeros((len(train), target.iloc[:, 1:].shape[1]))\n",
    "    best_loss = np.inf\n",
    "    \n",
    "    for epoch in range(EPOCHS):\n",
    "        \n",
    "        train_loss = train_fn(model, optimizer,scheduler, loss_tr, trainloader, DEVICE)\n",
    "        print(f\"FOLD: {fold}, EPOCH: {epoch}, train_loss: {train_loss}\")\n",
    "        valid_loss, valid_preds = valid_fn(model, loss_fn, validloader, DEVICE)\n",
    "        print(f\"FOLD: {fold}, EPOCH: {epoch}, valid_loss: {valid_loss}\")\n",
    "        \n",
    "        if valid_loss < best_loss:\n",
    "            \n",
    "            best_loss = valid_loss\n",
    "            oof[val_idx] = valid_preds\n",
    "            torch.save(model.state_dict(), f\"FOLD{fold}_scored.pth\")\n",
    "        \n",
    "        elif(EARLY_STOP == True):\n",
    "            \n",
    "            early_step += 1\n",
    "            if (early_step >= early_stopping_steps):\n",
    "                break\n",
    "            \n",
    "    \n",
    "    #--------------------- PREDICTION---------------------\n",
    "    x_test = test_[feature_cols].values\n",
    "    testdataset = TestDataset(x_test)\n",
    "    testloader = torch.utils.data.DataLoader(testdataset, batch_size=BATCH_SIZE, shuffle=False)\n",
    "    \n",
    "    model = Model(\n",
    "        num_features=num_features,\n",
    "        num_targets=num_targets,\n",
    "        hidden_size=hidden_size,\n",
    "\n",
    "    )\n",
    "    \n",
    "    model.load_state_dict(torch.load(f\"FOLD{fold}_scored.pth\"))\n",
    "    model.to(DEVICE)\n",
    "    \n",
    "    predictions = np.zeros((len(test_), target.iloc[:, 1:].shape[1]))\n",
    "    predictions = inference_fn(model, testloader, DEVICE)\n",
    "    \n",
    "    return oof, predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-20T23:44:22.820382Z",
     "iopub.status.busy": "2020-11-20T23:44:22.819385Z",
     "iopub.status.idle": "2020-11-20T23:44:22.822465Z",
     "shell.execute_reply": "2020-11-20T23:44:22.821965Z"
    },
    "papermill": {
     "duration": 0.328413,
     "end_time": "2020-11-20T23:44:22.822568",
     "exception": false,
     "start_time": "2020-11-20T23:44:22.494155",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def run_k_fold(NFOLDS, seed):\n",
    "    oof = np.zeros((len(train), len(target_cols)))\n",
    "    predictions = np.zeros((len(test), len(target_cols)))\n",
    "\n",
    "    \n",
    "    for fold in range(NFOLDS):\n",
    "        oof_, pred_ = run_training(fold, seed)\n",
    "        \n",
    "        predictions += pred_ / NFOLDS\n",
    "        oof += oof_\n",
    "        \n",
    "    return oof, predictions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-20T23:44:23.497857Z",
     "iopub.status.busy": "2020-11-20T23:44:23.496779Z",
     "iopub.status.idle": "2020-11-21T00:11:03.912229Z",
     "shell.execute_reply": "2020-11-21T00:11:03.911631Z"
    },
    "papermill": {
     "duration": 1600.763622,
     "end_time": "2020-11-21T00:11:03.912351",
     "exception": false,
     "start_time": "2020-11-20T23:44:23.148729",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FOLD: 0, EPOCH: 0, train_loss: 0.5769545289410932\n",
      "FOLD: 0, EPOCH: 0, valid_loss: 0.03793191393980613\n",
      "FOLD: 0, EPOCH: 1, train_loss: 0.027597479874620568\n",
      "FOLD: 0, EPOCH: 1, valid_loss: 0.019873496145009995\n",
      "FOLD: 0, EPOCH: 2, train_loss: 0.02327123566253765\n",
      "FOLD: 0, EPOCH: 2, valid_loss: 0.018654094006006535\n",
      "FOLD: 0, EPOCH: 3, train_loss: 0.021460763808037783\n",
      "FOLD: 0, EPOCH: 3, valid_loss: 0.02497602956226239\n",
      "FOLD: 0, EPOCH: 4, train_loss: 0.021783473121153342\n",
      "FOLD: 0, EPOCH: 4, valid_loss: 0.016866533945386227\n",
      "FOLD: 0, EPOCH: 5, train_loss: 0.019703793918361533\n",
      "FOLD: 0, EPOCH: 5, valid_loss: 0.016830157560224716\n",
      "FOLD: 0, EPOCH: 6, train_loss: 0.019026859764110397\n",
      "FOLD: 0, EPOCH: 6, valid_loss: 0.01664232870993706\n",
      "FOLD: 0, EPOCH: 7, train_loss: 0.01893255494635653\n",
      "FOLD: 0, EPOCH: 7, valid_loss: 0.01643383438484027\n",
      "FOLD: 0, EPOCH: 8, train_loss: 0.018460696487612015\n",
      "FOLD: 0, EPOCH: 8, valid_loss: 0.016744331886562016\n",
      "FOLD: 0, EPOCH: 9, train_loss: 0.018382954562233912\n",
      "FOLD: 0, EPOCH: 9, valid_loss: 0.016833019013015125\n",
      "FOLD: 0, EPOCH: 10, train_loss: 0.018218591003804595\n",
      "FOLD: 0, EPOCH: 10, valid_loss: 0.01672087495143597\n",
      "FOLD: 0, EPOCH: 11, train_loss: 0.01784739804428977\n",
      "FOLD: 0, EPOCH: 11, valid_loss: 0.016542195843962524\n",
      "FOLD: 0, EPOCH: 12, train_loss: 0.017498704579633637\n",
      "FOLD: 0, EPOCH: 12, valid_loss: 0.01679581654472993\n",
      "FOLD: 0, EPOCH: 13, train_loss: 0.01711088342189386\n",
      "FOLD: 0, EPOCH: 13, valid_loss: 0.016811797252068154\n",
      "FOLD: 0, EPOCH: 14, train_loss: 0.01666261170160126\n",
      "FOLD: 0, EPOCH: 14, valid_loss: 0.016884717947015397\n",
      "FOLD: 0, EPOCH: 15, train_loss: 0.015939908366448974\n",
      "FOLD: 0, EPOCH: 15, valid_loss: 0.016934114651611216\n",
      "FOLD: 0, EPOCH: 16, train_loss: 0.014881882527087992\n",
      "FOLD: 0, EPOCH: 16, valid_loss: 0.01730877161026001\n",
      "FOLD: 1, EPOCH: 0, train_loss: 0.5774828460872978\n",
      "FOLD: 1, EPOCH: 0, valid_loss: 0.049324503884865686\n",
      "FOLD: 1, EPOCH: 1, train_loss: 0.027099173818085645\n",
      "FOLD: 1, EPOCH: 1, valid_loss: 0.01938059152318881\n",
      "FOLD: 1, EPOCH: 2, train_loss: 0.02332876914659062\n",
      "FOLD: 1, EPOCH: 2, valid_loss: 0.01896660216152668\n",
      "FOLD: 1, EPOCH: 3, train_loss: 0.021554309270671895\n",
      "FOLD: 1, EPOCH: 3, valid_loss: 0.01722655574289652\n",
      "FOLD: 1, EPOCH: 4, train_loss: 0.02649610401508776\n",
      "FOLD: 1, EPOCH: 4, valid_loss: 2.368934851426345\n",
      "FOLD: 1, EPOCH: 5, train_loss: 0.02763789237753765\n",
      "FOLD: 1, EPOCH: 5, valid_loss: 0.01866957674232813\n",
      "FOLD: 1, EPOCH: 6, train_loss: 0.0224875923296487\n",
      "FOLD: 1, EPOCH: 6, valid_loss: 0.017978852471480004\n",
      "FOLD: 1, EPOCH: 7, train_loss: 0.021397448597928963\n",
      "FOLD: 1, EPOCH: 7, valid_loss: 0.01778942676117787\n",
      "FOLD: 1, EPOCH: 8, train_loss: 0.020797771124823672\n",
      "FOLD: 1, EPOCH: 8, valid_loss: 0.01750475110915991\n",
      "FOLD: 1, EPOCH: 9, train_loss: 0.0203738034375616\n",
      "FOLD: 1, EPOCH: 9, valid_loss: 0.017374272243334696\n",
      "FOLD: 1, EPOCH: 10, train_loss: 0.02015700193776472\n",
      "FOLD: 1, EPOCH: 10, valid_loss: 0.017205126153735015\n",
      "FOLD: 1, EPOCH: 11, train_loss: 0.01985621331511317\n",
      "FOLD: 1, EPOCH: 11, valid_loss: 0.016935237038594026\n",
      "FOLD: 1, EPOCH: 12, train_loss: 0.01955269813235547\n",
      "FOLD: 1, EPOCH: 12, valid_loss: 0.016986887615460616\n",
      "FOLD: 1, EPOCH: 13, train_loss: 0.019340204729421717\n",
      "FOLD: 1, EPOCH: 13, valid_loss: 0.016833949977388747\n",
      "FOLD: 1, EPOCH: 14, train_loss: 0.019088510449069576\n",
      "FOLD: 1, EPOCH: 14, valid_loss: 0.01674918307421299\n",
      "FOLD: 1, EPOCH: 15, train_loss: 0.018751364125794655\n",
      "FOLD: 1, EPOCH: 15, valid_loss: 0.016643070472547643\n",
      "FOLD: 1, EPOCH: 16, train_loss: 0.01836127561290522\n",
      "FOLD: 1, EPOCH: 16, valid_loss: 0.016632546885655478\n",
      "FOLD: 1, EPOCH: 17, train_loss: 0.01793897635227925\n",
      "FOLD: 1, EPOCH: 17, valid_loss: 0.016696228789022334\n",
      "FOLD: 1, EPOCH: 18, train_loss: 0.017402603819563583\n",
      "FOLD: 1, EPOCH: 18, valid_loss: 0.016565193708699483\n",
      "FOLD: 1, EPOCH: 19, train_loss: 0.016695217795770715\n",
      "FOLD: 1, EPOCH: 19, valid_loss: 0.016530340250868063\n",
      "FOLD: 1, EPOCH: 20, train_loss: 0.015822923553453105\n",
      "FOLD: 1, EPOCH: 20, valid_loss: 0.016599215280551177\n",
      "FOLD: 1, EPOCH: 21, train_loss: 0.014687915974472826\n",
      "FOLD: 1, EPOCH: 21, valid_loss: 0.016797164526696388\n",
      "FOLD: 2, EPOCH: 0, train_loss: 0.5757954012401201\n",
      "FOLD: 2, EPOCH: 0, valid_loss: 0.03582422750500532\n",
      "FOLD: 2, EPOCH: 1, train_loss: 0.02756635094615253\n",
      "FOLD: 2, EPOCH: 1, valid_loss: 0.019708737301138732\n",
      "FOLD: 2, EPOCH: 2, train_loss: 0.023040196405270615\n",
      "FOLD: 2, EPOCH: 2, valid_loss: 0.01829434587405278\n",
      "FOLD: 2, EPOCH: 3, train_loss: 0.023653644111913605\n",
      "FOLD: 2, EPOCH: 3, valid_loss: 0.017870059093603723\n",
      "FOLD: 2, EPOCH: 4, train_loss: 0.021235616751820653\n",
      "FOLD: 2, EPOCH: 4, valid_loss: 0.017495155334472656\n",
      "FOLD: 2, EPOCH: 5, train_loss: 0.020212560388687496\n",
      "FOLD: 2, EPOCH: 5, valid_loss: 0.017002234378686316\n",
      "FOLD: 2, EPOCH: 6, train_loss: 0.01998864355924967\n",
      "FOLD: 2, EPOCH: 6, valid_loss: 0.017694790059557326\n",
      "FOLD: 2, EPOCH: 7, train_loss: 0.019758108474716946\n",
      "FOLD: 2, EPOCH: 7, valid_loss: 0.017009496975403566\n",
      "FOLD: 2, EPOCH: 8, train_loss: 0.019110816203661868\n",
      "FOLD: 2, EPOCH: 8, valid_loss: 0.01672529013684163\n",
      "FOLD: 2, EPOCH: 9, train_loss: 0.018832043945990706\n",
      "FOLD: 2, EPOCH: 9, valid_loss: 0.016777334878077872\n",
      "FOLD: 2, EPOCH: 10, train_loss: 0.01859296201350721\n",
      "FOLD: 2, EPOCH: 10, valid_loss: 0.016610586299346045\n",
      "FOLD: 2, EPOCH: 11, train_loss: 0.01832781412412186\n",
      "FOLD: 2, EPOCH: 11, valid_loss: 0.016745674925354812\n",
      "FOLD: 2, EPOCH: 12, train_loss: 0.01808650283193266\n",
      "FOLD: 2, EPOCH: 12, valid_loss: 0.016607620395146884\n",
      "FOLD: 2, EPOCH: 13, train_loss: 0.01763333030347083\n",
      "FOLD: 2, EPOCH: 13, valid_loss: 0.016857980463940363\n",
      "FOLD: 2, EPOCH: 14, train_loss: 0.017040914667115825\n",
      "FOLD: 2, EPOCH: 14, valid_loss: 0.016775477391022902\n",
      "FOLD: 2, EPOCH: 15, train_loss: 0.016565614770091063\n",
      "FOLD: 2, EPOCH: 15, valid_loss: 0.017012133907813292\n",
      "FOLD: 2, EPOCH: 16, train_loss: 0.015675948127298743\n",
      "FOLD: 2, EPOCH: 16, valid_loss: 0.016947159113792274\n",
      "FOLD: 2, EPOCH: 17, train_loss: 0.01456714587638507\n",
      "FOLD: 2, EPOCH: 17, valid_loss: 0.01704710292128416\n",
      "FOLD: 2, EPOCH: 18, train_loss: 0.013275771162699204\n",
      "FOLD: 2, EPOCH: 18, valid_loss: 0.017167372915607233\n",
      "FOLD: 3, EPOCH: 0, train_loss: 0.576351029899072\n",
      "FOLD: 3, EPOCH: 0, valid_loss: 0.039264003244730145\n",
      "FOLD: 3, EPOCH: 1, train_loss: 0.027430825061290652\n",
      "FOLD: 3, EPOCH: 1, valid_loss: 0.019416331958312254\n",
      "FOLD: 3, EPOCH: 2, train_loss: 0.02334126492811216\n",
      "FOLD: 3, EPOCH: 2, valid_loss: 0.018378821989664666\n",
      "FOLD: 3, EPOCH: 3, train_loss: 0.022731825659001195\n",
      "FOLD: 3, EPOCH: 3, valid_loss: 0.01769481900219734\n",
      "FOLD: 3, EPOCH: 4, train_loss: 0.0219930573240728\n",
      "FOLD: 3, EPOCH: 4, valid_loss: 0.041061021674137846\n",
      "FOLD: 3, EPOCH: 5, train_loss: 0.025604894384741783\n",
      "FOLD: 3, EPOCH: 5, valid_loss: 0.01793255628301547\n",
      "FOLD: 3, EPOCH: 6, train_loss: 0.021631328238023294\n",
      "FOLD: 3, EPOCH: 6, valid_loss: 0.017572681777752362\n",
      "FOLD: 3, EPOCH: 7, train_loss: 0.020520915377985786\n",
      "FOLD: 3, EPOCH: 7, valid_loss: 0.017430871438521605\n",
      "FOLD: 3, EPOCH: 8, train_loss: 0.020204908818610617\n",
      "FOLD: 3, EPOCH: 8, valid_loss: 0.01718709574869046\n",
      "FOLD: 3, EPOCH: 9, train_loss: 0.01986967457609402\n",
      "FOLD: 3, EPOCH: 9, valid_loss: 0.01691100775049283\n",
      "FOLD: 3, EPOCH: 10, train_loss: 0.019674667383770685\n",
      "FOLD: 3, EPOCH: 10, valid_loss: 0.01673806379907406\n",
      "FOLD: 3, EPOCH: 11, train_loss: 0.019356421547362935\n",
      "FOLD: 3, EPOCH: 11, valid_loss: 0.016844701380110703\n",
      "FOLD: 3, EPOCH: 12, train_loss: 0.019105591635043558\n",
      "FOLD: 3, EPOCH: 12, valid_loss: 0.016749114371263064\n",
      "FOLD: 3, EPOCH: 13, train_loss: 0.018792306098180847\n",
      "FOLD: 3, EPOCH: 13, valid_loss: 0.01655422652570101\n",
      "FOLD: 3, EPOCH: 14, train_loss: 0.01845772171745429\n",
      "FOLD: 3, EPOCH: 14, valid_loss: 0.01655294567060012\n",
      "FOLD: 3, EPOCH: 15, train_loss: 0.018134117554369812\n",
      "FOLD: 3, EPOCH: 15, valid_loss: 0.016469557124834795\n",
      "FOLD: 3, EPOCH: 16, train_loss: 0.017626585690556345\n",
      "FOLD: 3, EPOCH: 16, valid_loss: 0.016377043838684376\n",
      "FOLD: 3, EPOCH: 17, train_loss: 0.017011712984861555\n",
      "FOLD: 3, EPOCH: 17, valid_loss: 0.0166000031794493\n",
      "FOLD: 3, EPOCH: 18, train_loss: 0.016252639489500103\n",
      "FOLD: 3, EPOCH: 18, valid_loss: 0.01673679218555872\n",
      "FOLD: 3, EPOCH: 19, train_loss: 0.015150528275281997\n",
      "FOLD: 3, EPOCH: 19, valid_loss: 0.016868434416560028\n",
      "FOLD: 3, EPOCH: 20, train_loss: 0.013908095242505943\n",
      "FOLD: 3, EPOCH: 20, valid_loss: 0.017014985187695578\n",
      "FOLD: 3, EPOCH: 21, train_loss: 0.012560611477474103\n",
      "FOLD: 3, EPOCH: 21, valid_loss: 0.017218054343874637\n",
      "FOLD: 3, EPOCH: 22, train_loss: 0.011241333873791469\n",
      "FOLD: 3, EPOCH: 22, valid_loss: 0.017441421890488036\n",
      "FOLD: 4, EPOCH: 0, train_loss: 0.5743434081810552\n",
      "FOLD: 4, EPOCH: 0, valid_loss: 0.03855701421315853\n",
      "FOLD: 4, EPOCH: 1, train_loss: 0.026871159169319515\n",
      "FOLD: 4, EPOCH: 1, valid_loss: 0.01991511035997134\n",
      "FOLD: 4, EPOCH: 2, train_loss: 0.02306287081257717\n",
      "FOLD: 4, EPOCH: 2, valid_loss: 0.01834762325653663\n",
      "FOLD: 4, EPOCH: 3, train_loss: 0.02083412411849241\n",
      "FOLD: 4, EPOCH: 3, valid_loss: 0.01736871998470563\n",
      "FOLD: 4, EPOCH: 4, train_loss: 0.0460165401769651\n",
      "FOLD: 4, EPOCH: 4, valid_loss: 0.021012001455976412\n",
      "FOLD: 4, EPOCH: 5, train_loss: 0.024822992599896482\n",
      "FOLD: 4, EPOCH: 5, valid_loss: 0.019412515684962273\n",
      "FOLD: 4, EPOCH: 6, train_loss: 0.02285265930097651\n",
      "FOLD: 4, EPOCH: 6, valid_loss: 0.018849854572461203\n",
      "FOLD: 4, EPOCH: 7, train_loss: 0.02174351001913483\n",
      "FOLD: 4, EPOCH: 7, valid_loss: 0.018222124530718878\n",
      "FOLD: 4, EPOCH: 8, train_loss: 0.021096782582635816\n",
      "FOLD: 4, EPOCH: 8, valid_loss: 0.01807025934641178\n",
      "FOLD: 4, EPOCH: 9, train_loss: 0.02064449805766344\n",
      "FOLD: 4, EPOCH: 9, valid_loss: 0.017884628417400215\n",
      "FOLD: 4, EPOCH: 10, train_loss: 0.020299999244712496\n",
      "FOLD: 4, EPOCH: 10, valid_loss: 0.017513250072415058\n",
      "FOLD: 4, EPOCH: 11, train_loss: 0.01997063809854759\n",
      "FOLD: 4, EPOCH: 11, valid_loss: 0.017369684834892932\n",
      "FOLD: 4, EPOCH: 12, train_loss: 0.019749658736022743\n",
      "FOLD: 4, EPOCH: 12, valid_loss: 0.017263403448920984\n",
      "FOLD: 4, EPOCH: 13, train_loss: 0.01953908478891527\n",
      "FOLD: 4, EPOCH: 13, valid_loss: 0.01708402642263816\n",
      "FOLD: 4, EPOCH: 14, train_loss: 0.01926482582112422\n",
      "FOLD: 4, EPOCH: 14, valid_loss: 0.017031967711563293\n",
      "FOLD: 4, EPOCH: 15, train_loss: 0.018967580025059147\n",
      "FOLD: 4, EPOCH: 15, valid_loss: 0.016943236884589378\n",
      "FOLD: 4, EPOCH: 16, train_loss: 0.018558638598266487\n",
      "FOLD: 4, EPOCH: 16, valid_loss: 0.016681365453853056\n",
      "FOLD: 4, EPOCH: 17, train_loss: 0.0182739019998022\n",
      "FOLD: 4, EPOCH: 17, valid_loss: 0.016632091898757678\n",
      "FOLD: 4, EPOCH: 18, train_loss: 0.017764385714120156\n",
      "FOLD: 4, EPOCH: 18, valid_loss: 0.016527131343117125\n",
      "FOLD: 4, EPOCH: 19, train_loss: 0.01722643565940293\n",
      "FOLD: 4, EPOCH: 19, valid_loss: 0.01650910760061099\n",
      "FOLD: 4, EPOCH: 20, train_loss: 0.016497441605236883\n",
      "FOLD: 4, EPOCH: 20, valid_loss: 0.016502149689656038\n",
      "FOLD: 4, EPOCH: 21, train_loss: 0.015576444830544092\n",
      "FOLD: 4, EPOCH: 21, valid_loss: 0.016422900586174086\n",
      "FOLD: 4, EPOCH: 22, train_loss: 0.014565065792585546\n",
      "FOLD: 4, EPOCH: 22, valid_loss: 0.016587785015312526\n",
      "FOLD: 4, EPOCH: 23, train_loss: 0.013573058264179004\n",
      "FOLD: 4, EPOCH: 23, valid_loss: 0.016691034086621724\n",
      "FOLD: 5, EPOCH: 0, train_loss: 0.5772001259532329\n",
      "FOLD: 5, EPOCH: 0, valid_loss: 0.038296270255859084\n",
      "FOLD: 5, EPOCH: 1, train_loss: 0.02733745612204075\n",
      "FOLD: 5, EPOCH: 1, valid_loss: 0.01953563652932644\n",
      "FOLD: 5, EPOCH: 2, train_loss: 0.023105361851284634\n",
      "FOLD: 5, EPOCH: 2, valid_loss: 0.01984798012731167\n",
      "FOLD: 5, EPOCH: 3, train_loss: 0.021423652440913626\n",
      "FOLD: 5, EPOCH: 3, valid_loss: 0.017776555166794702\n",
      "FOLD: 5, EPOCH: 4, train_loss: 0.021532244728626432\n",
      "FOLD: 5, EPOCH: 4, valid_loss: 0.01724446643717014\n",
      "FOLD: 5, EPOCH: 5, train_loss: 0.019569622705111634\n",
      "FOLD: 5, EPOCH: 5, valid_loss: 0.016731273741103135\n",
      "FOLD: 5, EPOCH: 6, train_loss: 0.01914649796546311\n",
      "FOLD: 5, EPOCH: 6, valid_loss: 0.016768640050521262\n",
      "FOLD: 5, EPOCH: 7, train_loss: 0.018697991514125385\n",
      "FOLD: 5, EPOCH: 7, valid_loss: 0.016856278436115153\n",
      "FOLD: 5, EPOCH: 8, train_loss: 0.01847216469311231\n",
      "FOLD: 5, EPOCH: 8, valid_loss: 0.016891050367401197\n",
      "FOLD: 5, EPOCH: 9, train_loss: 0.018341868083823373\n",
      "FOLD: 5, EPOCH: 9, valid_loss: 0.01679415270113028\n",
      "FOLD: 5, EPOCH: 10, train_loss: 0.018071837547058996\n",
      "FOLD: 5, EPOCH: 10, valid_loss: 0.017134152066249114\n",
      "FOLD: 5, EPOCH: 11, train_loss: 0.01792441137336396\n",
      "FOLD: 5, EPOCH: 11, valid_loss: 0.01691279445703213\n",
      "FOLD: 5, EPOCH: 12, train_loss: 0.01749739736771664\n",
      "FOLD: 5, EPOCH: 12, valid_loss: 0.0167008785960766\n",
      "FOLD: 5, EPOCH: 13, train_loss: 0.017042945000670245\n",
      "FOLD: 5, EPOCH: 13, valid_loss: 0.01672757789492607\n",
      "FOLD: 5, EPOCH: 14, train_loss: 0.016556742865390873\n",
      "FOLD: 5, EPOCH: 14, valid_loss: 0.016767253454488058\n",
      "FOLD: 5, EPOCH: 15, train_loss: 0.015810256974922644\n",
      "FOLD: 5, EPOCH: 15, valid_loss: 0.016912778051426776\n",
      "FOLD: 6, EPOCH: 0, train_loss: 0.5773376208805555\n",
      "FOLD: 6, EPOCH: 0, valid_loss: 0.0362572784607227\n",
      "FOLD: 6, EPOCH: 1, train_loss: 0.02658255282487418\n",
      "FOLD: 6, EPOCH: 1, valid_loss: 0.01943540945649147\n",
      "FOLD: 6, EPOCH: 2, train_loss: 0.022856786268184315\n",
      "FOLD: 6, EPOCH: 2, valid_loss: 0.01807415743286793\n",
      "FOLD: 6, EPOCH: 3, train_loss: 0.03612826943296839\n",
      "FOLD: 6, EPOCH: 3, valid_loss: 0.021558009947721776\n",
      "FOLD: 6, EPOCH: 4, train_loss: 0.024772959132049535\n",
      "FOLD: 6, EPOCH: 4, valid_loss: 0.01916476797599059\n",
      "FOLD: 6, EPOCH: 5, train_loss: 0.022566798747189948\n",
      "FOLD: 6, EPOCH: 5, valid_loss: 0.018531455730016414\n",
      "FOLD: 6, EPOCH: 6, train_loss: 0.0216439340918048\n",
      "FOLD: 6, EPOCH: 6, valid_loss: 0.0178662369457575\n",
      "FOLD: 6, EPOCH: 7, train_loss: 0.021004961702871968\n",
      "FOLD: 6, EPOCH: 7, valid_loss: 0.01774027843314868\n",
      "FOLD: 6, EPOCH: 8, train_loss: 0.02046185840122603\n",
      "FOLD: 6, EPOCH: 8, valid_loss: 0.017517995948974904\n",
      "FOLD: 6, EPOCH: 9, train_loss: 0.02015402789756253\n",
      "FOLD: 6, EPOCH: 9, valid_loss: 0.017252040310547903\n",
      "FOLD: 6, EPOCH: 10, train_loss: 0.019780002484047734\n",
      "FOLD: 6, EPOCH: 10, valid_loss: 0.017107643616887238\n",
      "FOLD: 6, EPOCH: 11, train_loss: 0.019483870650465425\n",
      "FOLD: 6, EPOCH: 11, valid_loss: 0.017003576915997725\n",
      "FOLD: 6, EPOCH: 12, train_loss: 0.019144466977465798\n",
      "FOLD: 6, EPOCH: 12, valid_loss: 0.016782163069225274\n",
      "FOLD: 6, EPOCH: 13, train_loss: 0.018972211139830383\n",
      "FOLD: 6, EPOCH: 13, valid_loss: 0.016741966255582295\n",
      "FOLD: 6, EPOCH: 14, train_loss: 0.01848157646285521\n",
      "FOLD: 6, EPOCH: 14, valid_loss: 0.01680958829820156\n",
      "FOLD: 6, EPOCH: 15, train_loss: 0.018104503862559795\n",
      "FOLD: 6, EPOCH: 15, valid_loss: 0.016723509949560348\n",
      "FOLD: 6, EPOCH: 16, train_loss: 0.01763410272227751\n",
      "FOLD: 6, EPOCH: 16, valid_loss: 0.016550129780975673\n",
      "FOLD: 6, EPOCH: 17, train_loss: 0.016925707094472\n",
      "FOLD: 6, EPOCH: 17, valid_loss: 0.016817809010927495\n",
      "FOLD: 6, EPOCH: 18, train_loss: 0.016064096795948776\n",
      "FOLD: 6, EPOCH: 18, valid_loss: 0.01687332335859537\n",
      "FOLD: 6, EPOCH: 19, train_loss: 0.014888462107125166\n",
      "FOLD: 6, EPOCH: 19, valid_loss: 0.016929392201396134\n",
      "FOLD: 6, EPOCH: 20, train_loss: 0.013373463011875347\n",
      "FOLD: 6, EPOCH: 20, valid_loss: 0.017127569764852524\n",
      "FOLD: 6, EPOCH: 21, train_loss: 0.01186227351678787\n",
      "FOLD: 6, EPOCH: 21, valid_loss: 0.017389250775942437\n",
      "FOLD: 6, EPOCH: 22, train_loss: 0.010525271422355561\n",
      "FOLD: 6, EPOCH: 22, valid_loss: 0.01750613247545866\n",
      "FOLD: 0, EPOCH: 0, train_loss: 0.5773314736984871\n",
      "FOLD: 0, EPOCH: 0, valid_loss: 0.036016437296683974\n",
      "FOLD: 0, EPOCH: 1, train_loss: 0.026702354007677453\n",
      "FOLD: 0, EPOCH: 1, valid_loss: 0.019819323976452533\n",
      "FOLD: 0, EPOCH: 2, train_loss: 0.02329447097774293\n",
      "FOLD: 0, EPOCH: 2, valid_loss: 0.019518981042962808\n",
      "FOLD: 0, EPOCH: 3, train_loss: 0.021770348646552175\n",
      "FOLD: 0, EPOCH: 3, valid_loss: 0.018369611495962508\n",
      "FOLD: 0, EPOCH: 4, train_loss: 0.020626625474038963\n",
      "FOLD: 0, EPOCH: 4, valid_loss: 0.01693929832142133\n",
      "FOLD: 0, EPOCH: 5, train_loss: 0.022364111566865765\n",
      "FOLD: 0, EPOCH: 5, valid_loss: 0.020650522783398628\n",
      "FOLD: 0, EPOCH: 6, train_loss: 0.02142151915845839\n",
      "FOLD: 0, EPOCH: 6, valid_loss: 0.01713111359052933\n",
      "FOLD: 0, EPOCH: 7, train_loss: 0.020207394443049625\n",
      "FOLD: 0, EPOCH: 7, valid_loss: 0.016877596624768697\n",
      "FOLD: 0, EPOCH: 8, train_loss: 0.01969865508176185\n",
      "FOLD: 0, EPOCH: 8, valid_loss: 0.01702972838225273\n",
      "FOLD: 0, EPOCH: 9, train_loss: 0.019241150619613158\n",
      "FOLD: 0, EPOCH: 9, valid_loss: 0.01634938198213394\n",
      "FOLD: 0, EPOCH: 10, train_loss: 0.018963436394728517\n",
      "FOLD: 0, EPOCH: 10, valid_loss: 0.01639451853071268\n",
      "FOLD: 0, EPOCH: 11, train_loss: 0.01864539129609192\n",
      "FOLD: 0, EPOCH: 11, valid_loss: 0.016369478705410775\n",
      "FOLD: 0, EPOCH: 12, train_loss: 0.01832395980789049\n",
      "FOLD: 0, EPOCH: 12, valid_loss: 0.016276760385013543\n",
      "FOLD: 0, EPOCH: 13, train_loss: 0.017980229889822973\n",
      "FOLD: 0, EPOCH: 13, valid_loss: 0.016418050831327073\n",
      "FOLD: 0, EPOCH: 14, train_loss: 0.017589168232941144\n",
      "FOLD: 0, EPOCH: 14, valid_loss: 0.01659144188922185\n",
      "FOLD: 0, EPOCH: 15, train_loss: 0.017077778377947776\n",
      "FOLD: 0, EPOCH: 15, valid_loss: 0.01646243050121344\n",
      "FOLD: 0, EPOCH: 16, train_loss: 0.01633694808225374\n",
      "FOLD: 0, EPOCH: 16, valid_loss: 0.01659651888677707\n",
      "FOLD: 0, EPOCH: 17, train_loss: 0.01542542497249874\n",
      "FOLD: 0, EPOCH: 17, valid_loss: 0.016996435892696563\n",
      "FOLD: 1, EPOCH: 0, train_loss: 0.5748743054431837\n",
      "FOLD: 1, EPOCH: 0, valid_loss: 0.03720935405446933\n",
      "FOLD: 1, EPOCH: 1, train_loss: 0.026886693327813536\n",
      "FOLD: 1, EPOCH: 1, valid_loss: 0.01917163125024392\n",
      "FOLD: 1, EPOCH: 2, train_loss: 0.022921032473646307\n",
      "FOLD: 1, EPOCH: 2, valid_loss: 0.01841402383377919\n",
      "FOLD: 1, EPOCH: 3, train_loss: 0.02997711401533436\n",
      "FOLD: 1, EPOCH: 3, valid_loss: 0.022110607045201156\n",
      "FOLD: 1, EPOCH: 4, train_loss: 0.02297092881053686\n",
      "FOLD: 1, EPOCH: 4, valid_loss: 0.01824140018568589\n",
      "FOLD: 1, EPOCH: 5, train_loss: 0.02144501023497936\n",
      "FOLD: 1, EPOCH: 5, valid_loss: 0.017783485496273406\n",
      "FOLD: 1, EPOCH: 6, train_loss: 0.02080516401376273\n",
      "FOLD: 1, EPOCH: 6, valid_loss: 0.01780354518156785\n",
      "FOLD: 1, EPOCH: 7, train_loss: 0.020242183393723256\n",
      "FOLD: 1, EPOCH: 7, valid_loss: 0.017281383419266112\n",
      "FOLD: 1, EPOCH: 8, train_loss: 0.01999430595016157\n",
      "FOLD: 1, EPOCH: 8, valid_loss: 0.01715162625679603\n",
      "FOLD: 1, EPOCH: 9, train_loss: 0.019633004869762306\n",
      "FOLD: 1, EPOCH: 9, valid_loss: 0.01689120611319175\n",
      "FOLD: 1, EPOCH: 10, train_loss: 0.01933561499557785\n",
      "FOLD: 1, EPOCH: 10, valid_loss: 0.016890125492444404\n",
      "FOLD: 1, EPOCH: 11, train_loss: 0.01904778086857216\n",
      "FOLD: 1, EPOCH: 11, valid_loss: 0.016794332947868567\n",
      "FOLD: 1, EPOCH: 12, train_loss: 0.018670477300278238\n",
      "FOLD: 1, EPOCH: 12, valid_loss: 0.016681555085457288\n",
      "FOLD: 1, EPOCH: 13, train_loss: 0.018272831457088124\n",
      "FOLD: 1, EPOCH: 13, valid_loss: 0.016711538227704856\n",
      "FOLD: 1, EPOCH: 14, train_loss: 0.017846241391993856\n",
      "FOLD: 1, EPOCH: 14, valid_loss: 0.01671007232597241\n",
      "FOLD: 1, EPOCH: 15, train_loss: 0.0172911862767226\n",
      "FOLD: 1, EPOCH: 15, valid_loss: 0.01663442600805026\n",
      "FOLD: 1, EPOCH: 16, train_loss: 0.016517881090073166\n",
      "FOLD: 1, EPOCH: 16, valid_loss: 0.016746872749466162\n",
      "FOLD: 1, EPOCH: 17, train_loss: 0.015568452912407953\n",
      "FOLD: 1, EPOCH: 17, valid_loss: 0.01709293803343406\n",
      "FOLD: 1, EPOCH: 18, train_loss: 0.014470341640549738\n",
      "FOLD: 1, EPOCH: 18, valid_loss: 0.017175657603030022\n",
      "FOLD: 1, EPOCH: 19, train_loss: 0.013006431717626952\n",
      "FOLD: 1, EPOCH: 19, valid_loss: 0.017493760356536277\n",
      "FOLD: 1, EPOCH: 20, train_loss: 0.011544765262688333\n",
      "FOLD: 1, EPOCH: 20, valid_loss: 0.01759854632501419\n",
      "FOLD: 1, EPOCH: 21, train_loss: 0.010052609647548682\n",
      "FOLD: 1, EPOCH: 21, valid_loss: 0.017785504890175965\n",
      "FOLD: 2, EPOCH: 0, train_loss: 0.5767973635245014\n",
      "FOLD: 2, EPOCH: 0, valid_loss: 0.038110169367148325\n",
      "FOLD: 2, EPOCH: 1, train_loss: 0.02764121412828162\n",
      "FOLD: 2, EPOCH: 1, valid_loss: 0.01988936631152263\n",
      "FOLD: 2, EPOCH: 2, train_loss: 0.02310437593307044\n",
      "FOLD: 2, EPOCH: 2, valid_loss: 0.019222325430466577\n",
      "FOLD: 2, EPOCH: 3, train_loss: 0.021475497633218765\n",
      "FOLD: 2, EPOCH: 3, valid_loss: 0.01836147761115661\n",
      "FOLD: 2, EPOCH: 4, train_loss: 0.02200403414364602\n",
      "FOLD: 2, EPOCH: 4, valid_loss: 0.017268767580389977\n",
      "FOLD: 2, EPOCH: 5, train_loss: 0.01989470573293196\n",
      "FOLD: 2, EPOCH: 5, valid_loss: 0.01665429398417473\n",
      "FOLD: 2, EPOCH: 6, train_loss: 0.019219649527725334\n",
      "FOLD: 2, EPOCH: 6, valid_loss: 0.016527828975365713\n",
      "FOLD: 2, EPOCH: 7, train_loss: 0.018839959533432045\n",
      "FOLD: 2, EPOCH: 7, valid_loss: 0.016496488251365148\n",
      "FOLD: 2, EPOCH: 8, train_loss: 0.018611335673847713\n",
      "FOLD: 2, EPOCH: 8, valid_loss: 0.016818698352346055\n",
      "FOLD: 2, EPOCH: 9, train_loss: 0.018423291149775724\n",
      "FOLD: 2, EPOCH: 9, valid_loss: 0.01692574184674483\n",
      "FOLD: 2, EPOCH: 10, train_loss: 0.018239909355100746\n",
      "FOLD: 2, EPOCH: 10, valid_loss: 0.016758704128173683\n",
      "FOLD: 2, EPOCH: 11, train_loss: 0.017978689356430155\n",
      "FOLD: 2, EPOCH: 11, valid_loss: 0.016830557957291603\n",
      "FOLD: 2, EPOCH: 12, train_loss: 0.0176153487173488\n",
      "FOLD: 2, EPOCH: 12, valid_loss: 0.016971325071958396\n",
      "FOLD: 2, EPOCH: 13, train_loss: 0.017206709693513206\n",
      "FOLD: 2, EPOCH: 13, valid_loss: 0.016703735320613936\n",
      "FOLD: 2, EPOCH: 14, train_loss: 0.016704641068605957\n",
      "FOLD: 2, EPOCH: 14, valid_loss: 0.01686778449668334\n",
      "FOLD: 2, EPOCH: 15, train_loss: 0.016066396986511914\n",
      "FOLD: 2, EPOCH: 15, valid_loss: 0.017004430294036865\n",
      "FOLD: 2, EPOCH: 16, train_loss: 0.01515545733776447\n",
      "FOLD: 2, EPOCH: 16, valid_loss: 0.017018952765143834\n",
      "FOLD: 2, EPOCH: 17, train_loss: 0.014047188936053095\n",
      "FOLD: 2, EPOCH: 17, valid_loss: 0.01733424299611495\n",
      "FOLD: 3, EPOCH: 0, train_loss: 0.5773235995423149\n",
      "FOLD: 3, EPOCH: 0, valid_loss: 0.0293300745005791\n",
      "FOLD: 3, EPOCH: 1, train_loss: 0.02672335067512216\n",
      "FOLD: 3, EPOCH: 1, valid_loss: 0.019413276074024346\n",
      "FOLD: 3, EPOCH: 2, train_loss: 0.02281393840707637\n",
      "FOLD: 3, EPOCH: 2, valid_loss: 0.018662679940462112\n",
      "FOLD: 3, EPOCH: 3, train_loss: 0.021481684962841304\n",
      "FOLD: 3, EPOCH: 3, valid_loss: 0.017851154678142987\n",
      "FOLD: 3, EPOCH: 4, train_loss: 0.020555225855393988\n",
      "FOLD: 3, EPOCH: 4, valid_loss: 0.016967598205575578\n",
      "FOLD: 3, EPOCH: 5, train_loss: 0.022482548815173073\n",
      "FOLD: 3, EPOCH: 5, valid_loss: 0.0177528838125559\n",
      "FOLD: 3, EPOCH: 6, train_loss: 0.020786024101481244\n",
      "FOLD: 3, EPOCH: 6, valid_loss: 0.01722352349987397\n",
      "FOLD: 3, EPOCH: 7, train_loss: 0.02005861621551417\n",
      "FOLD: 3, EPOCH: 7, valid_loss: 0.016843468953783695\n",
      "FOLD: 3, EPOCH: 8, train_loss: 0.019579563088513708\n",
      "FOLD: 3, EPOCH: 8, valid_loss: 0.016765103890345648\n",
      "FOLD: 3, EPOCH: 9, train_loss: 0.019344770777467137\n",
      "FOLD: 3, EPOCH: 9, valid_loss: 0.03293923503504349\n",
      "FOLD: 3, EPOCH: 10, train_loss: 0.019658014153105183\n",
      "FOLD: 3, EPOCH: 10, valid_loss: 0.01672620068375881\n",
      "FOLD: 3, EPOCH: 11, train_loss: 0.018900332066255646\n",
      "FOLD: 3, EPOCH: 11, valid_loss: 0.016516467556357384\n",
      "FOLD: 3, EPOCH: 12, train_loss: 0.018632372916751617\n",
      "FOLD: 3, EPOCH: 12, valid_loss: 0.016630508936941624\n",
      "FOLD: 3, EPOCH: 13, train_loss: 0.018284217479663925\n",
      "FOLD: 3, EPOCH: 13, valid_loss: 0.01661320338742091\n",
      "FOLD: 3, EPOCH: 14, train_loss: 0.01782192026793554\n",
      "FOLD: 3, EPOCH: 14, valid_loss: 0.016822054552344177\n",
      "FOLD: 3, EPOCH: 15, train_loss: 0.01740734581206296\n",
      "FOLD: 3, EPOCH: 15, valid_loss: 0.016748629080561492\n",
      "FOLD: 3, EPOCH: 16, train_loss: 0.01677334260799595\n",
      "FOLD: 3, EPOCH: 16, valid_loss: 0.01683012768626213\n",
      "FOLD: 3, EPOCH: 17, train_loss: 0.015862774745737378\n",
      "FOLD: 3, EPOCH: 17, valid_loss: 0.016991489351941988\n",
      "FOLD: 3, EPOCH: 18, train_loss: 0.0147687770501786\n",
      "FOLD: 3, EPOCH: 18, valid_loss: 0.017023063622988187\n",
      "FOLD: 4, EPOCH: 0, train_loss: 0.5759058651086446\n",
      "FOLD: 4, EPOCH: 0, valid_loss: 0.0410984860589871\n",
      "FOLD: 4, EPOCH: 1, train_loss: 0.026979132580596046\n",
      "FOLD: 4, EPOCH: 1, valid_loss: 0.019333031458350327\n",
      "FOLD: 4, EPOCH: 2, train_loss: 0.022872107506201073\n",
      "FOLD: 4, EPOCH: 2, valid_loss: 0.018035771181950204\n",
      "FOLD: 4, EPOCH: 3, train_loss: 0.021002046839409583\n",
      "FOLD: 4, EPOCH: 3, valid_loss: 0.01745841480218447\n",
      "FOLD: 4, EPOCH: 4, train_loss: 0.020110989392206475\n",
      "FOLD: 4, EPOCH: 4, valid_loss: 0.017324681035601176\n",
      "FOLD: 4, EPOCH: 5, train_loss: 0.019548274828372774\n",
      "FOLD: 4, EPOCH: 5, valid_loss: 0.016732783773197576\n",
      "FOLD: 4, EPOCH: 6, train_loss: 0.02384074913287485\n",
      "FOLD: 4, EPOCH: 6, valid_loss: 0.018609106110838745\n",
      "FOLD: 4, EPOCH: 7, train_loss: 0.021510269215984923\n",
      "FOLD: 4, EPOCH: 7, valid_loss: 0.017801602729237996\n",
      "FOLD: 4, EPOCH: 8, train_loss: 0.021821188186672894\n",
      "FOLD: 4, EPOCH: 8, valid_loss: 0.017953855487016532\n",
      "FOLD: 4, EPOCH: 9, train_loss: 0.020698931194036395\n",
      "FOLD: 4, EPOCH: 9, valid_loss: 0.01782898447261407\n",
      "FOLD: 4, EPOCH: 10, train_loss: 0.020041341515811713\n",
      "FOLD: 4, EPOCH: 10, valid_loss: 0.017268674161571722\n",
      "FOLD: 4, EPOCH: 11, train_loss: 0.01965053628727391\n",
      "FOLD: 4, EPOCH: 11, valid_loss: 0.017191223943462737\n",
      "FOLD: 4, EPOCH: 12, train_loss: 0.01940017900857571\n",
      "FOLD: 4, EPOCH: 12, valid_loss: 0.016894234917484797\n",
      "FOLD: 4, EPOCH: 13, train_loss: 0.01908175659844199\n",
      "FOLD: 4, EPOCH: 13, valid_loss: 0.016613321737028085\n",
      "FOLD: 4, EPOCH: 14, train_loss: 0.018820990204206994\n",
      "FOLD: 4, EPOCH: 14, valid_loss: 0.016737036120433074\n",
      "FOLD: 4, EPOCH: 15, train_loss: 0.018474647246703908\n",
      "FOLD: 4, EPOCH: 15, valid_loss: 0.016504020071946658\n",
      "FOLD: 4, EPOCH: 16, train_loss: 0.018105251387365767\n",
      "FOLD: 4, EPOCH: 16, valid_loss: 0.016511215541798335\n",
      "FOLD: 4, EPOCH: 17, train_loss: 0.01759060167682332\n",
      "FOLD: 4, EPOCH: 17, valid_loss: 0.01645769028422924\n",
      "FOLD: 4, EPOCH: 18, train_loss: 0.01692433192117794\n",
      "FOLD: 4, EPOCH: 18, valid_loss: 0.016515727154910564\n",
      "FOLD: 5, EPOCH: 0, train_loss: 0.5770943655657608\n",
      "FOLD: 5, EPOCH: 0, valid_loss: 0.03327759255010348\n",
      "FOLD: 5, EPOCH: 1, train_loss: 0.026874462142586708\n",
      "FOLD: 5, EPOCH: 1, valid_loss: 0.019689277817423526\n",
      "FOLD: 5, EPOCH: 2, train_loss: 0.02288478013832827\n",
      "FOLD: 5, EPOCH: 2, valid_loss: 0.018485824792430952\n",
      "FOLD: 5, EPOCH: 3, train_loss: 0.022089557092938875\n",
      "FOLD: 5, EPOCH: 3, valid_loss: 0.03401935071899341\n",
      "FOLD: 5, EPOCH: 4, train_loss: 0.020873828866594547\n",
      "FOLD: 5, EPOCH: 4, valid_loss: 0.017164740711450577\n",
      "FOLD: 5, EPOCH: 5, train_loss: 0.019508030290740566\n",
      "FOLD: 5, EPOCH: 5, valid_loss: 0.01677538089167613\n",
      "FOLD: 5, EPOCH: 6, train_loss: 0.01961197256035096\n",
      "FOLD: 5, EPOCH: 6, valid_loss: 0.01677646502279318\n",
      "FOLD: 5, EPOCH: 7, train_loss: 0.019062196533824946\n",
      "FOLD: 5, EPOCH: 7, valid_loss: 0.017070099496497557\n",
      "FOLD: 5, EPOCH: 8, train_loss: 0.018683273722795216\n",
      "FOLD: 5, EPOCH: 8, valid_loss: 0.016918364768991105\n",
      "FOLD: 5, EPOCH: 9, train_loss: 0.01849631970194546\n",
      "FOLD: 5, EPOCH: 9, valid_loss: 0.016912531537505295\n",
      "FOLD: 5, EPOCH: 10, train_loss: 0.018394381865053565\n",
      "FOLD: 5, EPOCH: 10, valid_loss: 0.016865804361609314\n",
      "FOLD: 5, EPOCH: 11, train_loss: 0.018106652146859747\n",
      "FOLD: 5, EPOCH: 11, valid_loss: 0.016740182414650917\n",
      "FOLD: 5, EPOCH: 12, train_loss: 0.01777347269140788\n",
      "FOLD: 5, EPOCH: 12, valid_loss: 0.01692014732039892\n",
      "FOLD: 5, EPOCH: 13, train_loss: 0.017441336417923104\n",
      "FOLD: 5, EPOCH: 13, valid_loss: 0.016760337453048963\n",
      "FOLD: 5, EPOCH: 14, train_loss: 0.016975395406621532\n",
      "FOLD: 5, EPOCH: 14, valid_loss: 0.01663737615140585\n",
      "FOLD: 5, EPOCH: 15, train_loss: 0.016386523817640705\n",
      "FOLD: 5, EPOCH: 15, valid_loss: 0.01673578005284071\n",
      "FOLD: 5, EPOCH: 16, train_loss: 0.015534699416241131\n",
      "FOLD: 5, EPOCH: 16, valid_loss: 0.017192986220694505\n",
      "FOLD: 6, EPOCH: 0, train_loss: 0.5771564876006262\n",
      "FOLD: 6, EPOCH: 0, valid_loss: 0.047133828011842877\n",
      "FOLD: 6, EPOCH: 1, train_loss: 0.026874595724448964\n",
      "FOLD: 6, EPOCH: 1, valid_loss: 0.01993421293221987\n",
      "FOLD: 6, EPOCH: 2, train_loss: 0.02304437560205524\n",
      "FOLD: 6, EPOCH: 2, valid_loss: 0.01872896818587413\n",
      "FOLD: 6, EPOCH: 3, train_loss: 0.02279513533151633\n",
      "FOLD: 6, EPOCH: 3, valid_loss: 0.017290293597258054\n",
      "FOLD: 6, EPOCH: 4, train_loss: 0.02013777075587092\n",
      "FOLD: 6, EPOCH: 4, valid_loss: 0.017061293626633976\n",
      "FOLD: 6, EPOCH: 5, train_loss: 0.020169612045425014\n",
      "FOLD: 6, EPOCH: 5, valid_loss: 0.02050808831476248\n",
      "FOLD: 6, EPOCH: 6, train_loss: 0.02010482723346433\n",
      "FOLD: 6, EPOCH: 6, valid_loss: 0.016912045387121346\n",
      "FOLD: 6, EPOCH: 7, train_loss: 0.019298181969773124\n",
      "FOLD: 6, EPOCH: 7, valid_loss: 0.016709375983247392\n",
      "FOLD: 6, EPOCH: 8, train_loss: 0.018727703296856302\n",
      "FOLD: 6, EPOCH: 8, valid_loss: 0.016869099165957708\n",
      "FOLD: 6, EPOCH: 9, train_loss: 0.01864236029418739\n",
      "FOLD: 6, EPOCH: 9, valid_loss: 0.01676727494654747\n",
      "FOLD: 6, EPOCH: 10, train_loss: 0.018404241575783974\n",
      "FOLD: 6, EPOCH: 10, valid_loss: 0.016852762263554793\n",
      "FOLD: 6, EPOCH: 11, train_loss: 0.018164567825560633\n",
      "FOLD: 6, EPOCH: 11, valid_loss: 0.016993384091899946\n",
      "FOLD: 6, EPOCH: 12, train_loss: 0.017804249416331987\n",
      "FOLD: 6, EPOCH: 12, valid_loss: 0.01656720844598917\n",
      "FOLD: 6, EPOCH: 13, train_loss: 0.017359297747748928\n",
      "FOLD: 6, EPOCH: 13, valid_loss: 0.01698164684841266\n",
      "FOLD: 6, EPOCH: 14, train_loss: 0.01702797317222969\n",
      "FOLD: 6, EPOCH: 14, valid_loss: 0.01696072303904937\n",
      "FOLD: 6, EPOCH: 15, train_loss: 0.0163534544911739\n",
      "FOLD: 6, EPOCH: 15, valid_loss: 0.017147138284949157\n",
      "FOLD: 6, EPOCH: 16, train_loss: 0.015556160335403841\n",
      "FOLD: 6, EPOCH: 16, valid_loss: 0.017221886807909377\n",
      "FOLD: 6, EPOCH: 17, train_loss: 0.014527566315656578\n",
      "FOLD: 6, EPOCH: 17, valid_loss: 0.017248854256020144\n",
      "FOLD: 0, EPOCH: 0, train_loss: 0.5771034853784619\n",
      "FOLD: 0, EPOCH: 0, valid_loss: 0.03843986071073092\n",
      "FOLD: 0, EPOCH: 1, train_loss: 0.027020318408471508\n",
      "FOLD: 0, EPOCH: 1, valid_loss: 0.019703753865682162\n",
      "FOLD: 0, EPOCH: 2, train_loss: 0.023666706313756673\n",
      "FOLD: 0, EPOCH: 2, valid_loss: 0.018105417060164306\n",
      "FOLD: 0, EPOCH: 3, train_loss: 0.021864379303076782\n",
      "FOLD: 0, EPOCH: 3, valid_loss: 0.017313494060475092\n",
      "FOLD: 0, EPOCH: 4, train_loss: 0.02000284680744281\n",
      "FOLD: 0, EPOCH: 4, valid_loss: 0.016902700281487062\n",
      "FOLD: 0, EPOCH: 5, train_loss: 0.01917153171490173\n",
      "FOLD: 0, EPOCH: 5, valid_loss: 0.016626323358370707\n",
      "FOLD: 0, EPOCH: 6, train_loss: 0.01892680684859688\n",
      "FOLD: 0, EPOCH: 6, valid_loss: 0.016740258424901046\n",
      "FOLD: 0, EPOCH: 7, train_loss: 0.019248858320753317\n",
      "FOLD: 0, EPOCH: 7, valid_loss: 0.01838150892693263\n",
      "FOLD: 0, EPOCH: 8, train_loss: 0.01949949177435121\n",
      "FOLD: 0, EPOCH: 8, valid_loss: 0.016624461931104843\n",
      "FOLD: 0, EPOCH: 9, train_loss: 0.018565038093239873\n",
      "FOLD: 0, EPOCH: 9, valid_loss: 0.01678539117654929\n",
      "FOLD: 0, EPOCH: 10, train_loss: 0.018201687851467648\n",
      "FOLD: 0, EPOCH: 10, valid_loss: 0.01664405086865792\n",
      "FOLD: 0, EPOCH: 11, train_loss: 0.01789620767876103\n",
      "FOLD: 0, EPOCH: 11, valid_loss: 0.016560919367923185\n",
      "FOLD: 0, EPOCH: 12, train_loss: 0.017490750166109285\n",
      "FOLD: 0, EPOCH: 12, valid_loss: 0.01662934234795662\n",
      "FOLD: 0, EPOCH: 13, train_loss: 0.017071871892423242\n",
      "FOLD: 0, EPOCH: 13, valid_loss: 0.01672928765989267\n",
      "FOLD: 0, EPOCH: 14, train_loss: 0.016564516262528865\n",
      "FOLD: 0, EPOCH: 14, valid_loss: 0.01664389705715271\n",
      "FOLD: 0, EPOCH: 15, train_loss: 0.015737777487752406\n",
      "FOLD: 0, EPOCH: 15, valid_loss: 0.016993878695827264\n",
      "FOLD: 0, EPOCH: 16, train_loss: 0.014915008337010403\n",
      "FOLD: 0, EPOCH: 16, valid_loss: 0.017069445779690377\n",
      "FOLD: 0, EPOCH: 17, train_loss: 0.013826315454836632\n",
      "FOLD: 0, EPOCH: 17, valid_loss: 0.01741763920738147\n",
      "FOLD: 1, EPOCH: 0, train_loss: 0.5772602345190339\n",
      "FOLD: 1, EPOCH: 0, valid_loss: 0.05985604455837837\n",
      "FOLD: 1, EPOCH: 1, train_loss: 0.0272571356665041\n",
      "FOLD: 1, EPOCH: 1, valid_loss: 0.019378779599299796\n",
      "FOLD: 1, EPOCH: 2, train_loss: 0.02324134056028482\n",
      "FOLD: 1, EPOCH: 2, valid_loss: 0.01810464162666064\n",
      "FOLD: 1, EPOCH: 3, train_loss: 0.022518689442123915\n",
      "FOLD: 1, EPOCH: 3, valid_loss: 0.04298722099226255\n",
      "FOLD: 1, EPOCH: 4, train_loss: 0.03432680188199958\n",
      "FOLD: 1, EPOCH: 4, valid_loss: 0.019559736291949566\n",
      "FOLD: 1, EPOCH: 5, train_loss: 0.022939953701318922\n",
      "FOLD: 1, EPOCH: 5, valid_loss: 0.018616199063567016\n",
      "FOLD: 1, EPOCH: 6, train_loss: 0.02183064317481743\n",
      "FOLD: 1, EPOCH: 6, valid_loss: 0.018019393659554996\n",
      "FOLD: 1, EPOCH: 7, train_loss: 0.021123698509826854\n",
      "FOLD: 1, EPOCH: 7, valid_loss: 0.017680364875839308\n",
      "FOLD: 1, EPOCH: 8, train_loss: 0.02067382205781099\n",
      "FOLD: 1, EPOCH: 8, valid_loss: 0.017508919709003888\n",
      "FOLD: 1, EPOCH: 9, train_loss: 0.020266208898376773\n",
      "FOLD: 1, EPOCH: 9, valid_loss: 0.01714831619308545\n",
      "FOLD: 1, EPOCH: 10, train_loss: 0.01992403413798358\n",
      "FOLD: 1, EPOCH: 10, valid_loss: 0.017132565665703554\n",
      "FOLD: 1, EPOCH: 11, train_loss: 0.01963220043359576\n",
      "FOLD: 1, EPOCH: 11, valid_loss: 0.01692153370151153\n",
      "FOLD: 1, EPOCH: 12, train_loss: 0.019338699284236174\n",
      "FOLD: 1, EPOCH: 12, valid_loss: 0.016829957612431966\n",
      "FOLD: 1, EPOCH: 13, train_loss: 0.018984220166866843\n",
      "FOLD: 1, EPOCH: 13, valid_loss: 0.01670815530591286\n",
      "FOLD: 1, EPOCH: 14, train_loss: 0.01858633822081862\n",
      "FOLD: 1, EPOCH: 14, valid_loss: 0.01657526560414296\n",
      "FOLD: 1, EPOCH: 15, train_loss: 0.018090156259367596\n",
      "FOLD: 1, EPOCH: 15, valid_loss: 0.01672570314258337\n",
      "FOLD: 1, EPOCH: 16, train_loss: 0.017716865055263042\n",
      "FOLD: 1, EPOCH: 16, valid_loss: 0.016511132152607806\n",
      "FOLD: 1, EPOCH: 17, train_loss: 0.01701621708737032\n",
      "FOLD: 1, EPOCH: 17, valid_loss: 0.016699246775645476\n",
      "FOLD: 1, EPOCH: 18, train_loss: 0.016192404779832106\n",
      "FOLD: 1, EPOCH: 18, valid_loss: 0.016719133020020448\n",
      "FOLD: 1, EPOCH: 19, train_loss: 0.015032767934875714\n",
      "FOLD: 1, EPOCH: 19, valid_loss: 0.016905110902511157\n",
      "FOLD: 1, EPOCH: 20, train_loss: 0.0137114015256835\n",
      "FOLD: 1, EPOCH: 20, valid_loss: 0.017078482044430878\n",
      "FOLD: 1, EPOCH: 21, train_loss: 0.012200360337423312\n",
      "FOLD: 1, EPOCH: 21, valid_loss: 0.017297623822322257\n",
      "FOLD: 1, EPOCH: 22, train_loss: 0.010882821424889404\n",
      "FOLD: 1, EPOCH: 22, valid_loss: 0.017508182531365983\n",
      "FOLD: 2, EPOCH: 0, train_loss: 0.5776758440140937\n",
      "FOLD: 2, EPOCH: 0, valid_loss: 0.04893588847838915\n",
      "FOLD: 2, EPOCH: 1, train_loss: 0.027553550798345258\n",
      "FOLD: 2, EPOCH: 1, valid_loss: 0.019298776411093198\n",
      "FOLD: 2, EPOCH: 2, train_loss: 0.02314781374927308\n",
      "FOLD: 2, EPOCH: 2, valid_loss: 0.018348725512623787\n",
      "FOLD: 2, EPOCH: 3, train_loss: 0.053114524161493454\n",
      "FOLD: 2, EPOCH: 3, valid_loss: 0.023249730897637513\n",
      "FOLD: 2, EPOCH: 4, train_loss: 0.026430627960409667\n",
      "FOLD: 2, EPOCH: 4, valid_loss: 0.020311052409502175\n",
      "FOLD: 2, EPOCH: 5, train_loss: 0.024414217628135875\n",
      "FOLD: 2, EPOCH: 5, valid_loss: 0.01972596547924555\n",
      "FOLD: 2, EPOCH: 6, train_loss: 0.023027192876749748\n",
      "FOLD: 2, EPOCH: 6, valid_loss: 0.019009516072961\n",
      "FOLD: 2, EPOCH: 7, train_loss: 0.022102331969182234\n",
      "FOLD: 2, EPOCH: 7, valid_loss: 0.018393758970957536\n",
      "FOLD: 2, EPOCH: 8, train_loss: 0.02175891333939256\n",
      "FOLD: 2, EPOCH: 8, valid_loss: 0.017860860778735235\n",
      "FOLD: 2, EPOCH: 9, train_loss: 0.021126627292786096\n",
      "FOLD: 2, EPOCH: 9, valid_loss: 0.017671918926330712\n",
      "FOLD: 2, EPOCH: 10, train_loss: 0.020726229089337425\n",
      "FOLD: 2, EPOCH: 10, valid_loss: 0.017643738967867997\n",
      "FOLD: 2, EPOCH: 11, train_loss: 0.02032731652159143\n",
      "FOLD: 2, EPOCH: 11, valid_loss: 0.017348077291479476\n",
      "FOLD: 2, EPOCH: 12, train_loss: 0.019955564441310393\n",
      "FOLD: 2, EPOCH: 12, valid_loss: 0.017190788084497817\n",
      "FOLD: 2, EPOCH: 13, train_loss: 0.019643768743687385\n",
      "FOLD: 2, EPOCH: 13, valid_loss: 0.016933388721484404\n",
      "FOLD: 2, EPOCH: 14, train_loss: 0.019380919559783227\n",
      "FOLD: 2, EPOCH: 14, valid_loss: 0.016818378407221574\n",
      "FOLD: 2, EPOCH: 15, train_loss: 0.018967282253544073\n",
      "FOLD: 2, EPOCH: 15, valid_loss: 0.016707007988141134\n",
      "FOLD: 2, EPOCH: 16, train_loss: 0.01861456240451819\n",
      "FOLD: 2, EPOCH: 16, valid_loss: 0.016503610433294222\n",
      "FOLD: 2, EPOCH: 17, train_loss: 0.01817100474963317\n",
      "FOLD: 2, EPOCH: 17, valid_loss: 0.01644989661872387\n",
      "FOLD: 2, EPOCH: 18, train_loss: 0.017583575351415453\n",
      "FOLD: 2, EPOCH: 18, valid_loss: 0.016434943446746238\n",
      "FOLD: 2, EPOCH: 19, train_loss: 0.016928612959344645\n",
      "FOLD: 2, EPOCH: 19, valid_loss: 0.016364216732864197\n",
      "FOLD: 2, EPOCH: 20, train_loss: 0.015956297617506335\n",
      "FOLD: 2, EPOCH: 20, valid_loss: 0.01653228155695475\n",
      "FOLD: 2, EPOCH: 21, train_loss: 0.014996852536962644\n",
      "FOLD: 2, EPOCH: 21, valid_loss: 0.016581508402641002\n",
      "FOLD: 2, EPOCH: 22, train_loss: 0.013758150218809778\n",
      "FOLD: 2, EPOCH: 22, valid_loss: 0.016706415022221897\n",
      "FOLD: 2, EPOCH: 23, train_loss: 0.012668997942897919\n",
      "FOLD: 2, EPOCH: 23, valid_loss: 0.016765868434539206\n",
      "FOLD: 2, EPOCH: 24, train_loss: 0.011962899824956784\n",
      "FOLD: 2, EPOCH: 24, valid_loss: 0.016814274426836234\n",
      "FOLD: 3, EPOCH: 0, train_loss: 0.5776857503664654\n",
      "FOLD: 3, EPOCH: 0, valid_loss: 0.03822657293998278\n",
      "FOLD: 3, EPOCH: 1, train_loss: 0.026468067530643295\n",
      "FOLD: 3, EPOCH: 1, valid_loss: 0.01962025134036174\n",
      "FOLD: 3, EPOCH: 2, train_loss: 0.023196628694800107\n",
      "FOLD: 3, EPOCH: 2, valid_loss: 0.018069324585107658\n",
      "FOLD: 3, EPOCH: 3, train_loss: 0.03584872709738242\n",
      "FOLD: 3, EPOCH: 3, valid_loss: 0.020576345089536447\n",
      "FOLD: 3, EPOCH: 4, train_loss: 0.023851492190481844\n",
      "FOLD: 3, EPOCH: 4, valid_loss: 0.018795254711921398\n",
      "FOLD: 3, EPOCH: 5, train_loss: 0.022137328705473525\n",
      "FOLD: 3, EPOCH: 5, valid_loss: 0.018042418246085826\n",
      "FOLD: 3, EPOCH: 6, train_loss: 0.02121024304447142\n",
      "FOLD: 3, EPOCH: 6, valid_loss: 0.017786391509267\n",
      "FOLD: 3, EPOCH: 7, train_loss: 0.02056745787125987\n",
      "FOLD: 3, EPOCH: 7, valid_loss: 0.01731246509231054\n",
      "FOLD: 3, EPOCH: 8, train_loss: 0.02008362637983786\n",
      "FOLD: 3, EPOCH: 8, valid_loss: 0.017446435844668977\n",
      "FOLD: 3, EPOCH: 9, train_loss: 0.019789838433467054\n",
      "FOLD: 3, EPOCH: 9, valid_loss: 0.016824287434036914\n",
      "FOLD: 3, EPOCH: 10, train_loss: 0.019396323307945922\n",
      "FOLD: 3, EPOCH: 10, valid_loss: 0.01681312245245163\n",
      "FOLD: 3, EPOCH: 11, train_loss: 0.018952160519925324\n",
      "FOLD: 3, EPOCH: 11, valid_loss: 0.016760470775457528\n",
      "FOLD: 3, EPOCH: 12, train_loss: 0.01861368557689963\n",
      "FOLD: 3, EPOCH: 12, valid_loss: 0.016671635067233674\n",
      "FOLD: 3, EPOCH: 13, train_loss: 0.018200902671024605\n",
      "FOLD: 3, EPOCH: 13, valid_loss: 0.016564014152838633\n",
      "FOLD: 3, EPOCH: 14, train_loss: 0.017713227384799236\n",
      "FOLD: 3, EPOCH: 14, valid_loss: 0.0166157023408092\n",
      "FOLD: 3, EPOCH: 15, train_loss: 0.01713527925312519\n",
      "FOLD: 3, EPOCH: 15, valid_loss: 0.016716521663161423\n",
      "FOLD: 3, EPOCH: 16, train_loss: 0.016435893378346354\n",
      "FOLD: 3, EPOCH: 16, valid_loss: 0.01684268406377389\n",
      "FOLD: 3, EPOCH: 17, train_loss: 0.015350093095991257\n",
      "FOLD: 3, EPOCH: 17, valid_loss: 0.016918368494281404\n",
      "FOLD: 3, EPOCH: 18, train_loss: 0.014156657774504778\n",
      "FOLD: 3, EPOCH: 18, valid_loss: 0.017187136583603345\n",
      "FOLD: 3, EPOCH: 19, train_loss: 0.012761763057898026\n",
      "FOLD: 3, EPOCH: 19, valid_loss: 0.017342488926190596\n",
      "FOLD: 3, EPOCH: 20, train_loss: 0.011266531171025457\n",
      "FOLD: 3, EPOCH: 20, valid_loss: 0.017608083211458646\n",
      "FOLD: 4, EPOCH: 0, train_loss: 0.58006821154944\n",
      "FOLD: 4, EPOCH: 0, valid_loss: 0.05820215751345341\n",
      "FOLD: 4, EPOCH: 1, train_loss: 0.02728890036106915\n",
      "FOLD: 4, EPOCH: 1, valid_loss: 0.019812918053223535\n",
      "FOLD: 4, EPOCH: 2, train_loss: 0.023110917844885105\n",
      "FOLD: 4, EPOCH: 2, valid_loss: 0.018752324036680736\n",
      "FOLD: 4, EPOCH: 3, train_loss: 0.021198723842767445\n",
      "FOLD: 4, EPOCH: 3, valid_loss: 0.01750849115733917\n",
      "FOLD: 4, EPOCH: 4, train_loss: 0.01990999885507532\n",
      "FOLD: 4, EPOCH: 4, valid_loss: 0.01737049838098196\n",
      "FOLD: 4, EPOCH: 5, train_loss: 0.021116415315584558\n",
      "FOLD: 4, EPOCH: 5, valid_loss: 0.017045303176228817\n",
      "FOLD: 4, EPOCH: 6, train_loss: 0.019487472603449952\n",
      "FOLD: 4, EPOCH: 6, valid_loss: 0.016792283823283818\n",
      "FOLD: 4, EPOCH: 7, train_loss: 0.018921830641055428\n",
      "FOLD: 4, EPOCH: 7, valid_loss: 0.0169377291145233\n",
      "FOLD: 4, EPOCH: 8, train_loss: 0.018646002646434953\n",
      "FOLD: 4, EPOCH: 8, valid_loss: 0.016886285649469264\n",
      "FOLD: 4, EPOCH: 9, train_loss: 0.018305599588800122\n",
      "FOLD: 4, EPOCH: 9, valid_loss: 0.01691983317813048\n",
      "FOLD: 4, EPOCH: 10, train_loss: 0.018141600529889803\n",
      "FOLD: 4, EPOCH: 10, valid_loss: 0.016848551395993967\n",
      "FOLD: 4, EPOCH: 11, train_loss: 0.017799773933114233\n",
      "FOLD: 4, EPOCH: 11, valid_loss: 0.017040280410303518\n",
      "FOLD: 4, EPOCH: 12, train_loss: 0.01754125125857221\n",
      "FOLD: 4, EPOCH: 12, valid_loss: 0.01690670933860999\n",
      "FOLD: 4, EPOCH: 13, train_loss: 0.017115191367731708\n",
      "FOLD: 4, EPOCH: 13, valid_loss: 0.0169509443669365\n",
      "FOLD: 4, EPOCH: 14, train_loss: 0.01663653471985379\n",
      "FOLD: 4, EPOCH: 14, valid_loss: 0.016990565193387177\n",
      "FOLD: 4, EPOCH: 15, train_loss: 0.01593606697546469\n",
      "FOLD: 4, EPOCH: 15, valid_loss: 0.017182907519432213\n",
      "FOLD: 4, EPOCH: 16, train_loss: 0.015069292644290504\n",
      "FOLD: 4, EPOCH: 16, valid_loss: 0.017167372199205253\n",
      "FOLD: 5, EPOCH: 0, train_loss: 0.5769072018463064\n",
      "FOLD: 5, EPOCH: 0, valid_loss: 0.03982672897668985\n",
      "FOLD: 5, EPOCH: 1, train_loss: 0.027040047294183356\n",
      "FOLD: 5, EPOCH: 1, valid_loss: 0.019687822876641385\n",
      "FOLD: 5, EPOCH: 2, train_loss: 0.022942209440107282\n",
      "FOLD: 5, EPOCH: 2, valid_loss: 0.017988188550449334\n",
      "FOLD: 5, EPOCH: 3, train_loss: 0.02175863107313981\n",
      "FOLD: 5, EPOCH: 3, valid_loss: 0.017602731903585103\n",
      "FOLD: 5, EPOCH: 4, train_loss: 0.020033459330128657\n",
      "FOLD: 5, EPOCH: 4, valid_loss: 0.017219387639600497\n",
      "FOLD: 5, EPOCH: 5, train_loss: 0.019574779891283124\n",
      "FOLD: 5, EPOCH: 5, valid_loss: 0.016944172505575877\n",
      "FOLD: 5, EPOCH: 6, train_loss: 0.01944683839541835\n",
      "FOLD: 5, EPOCH: 6, valid_loss: 0.017212031194223806\n",
      "FOLD: 5, EPOCH: 7, train_loss: 0.019166911624976107\n",
      "FOLD: 5, EPOCH: 7, valid_loss: 0.016872508451342583\n",
      "FOLD: 5, EPOCH: 8, train_loss: 0.018759243089605023\n",
      "FOLD: 5, EPOCH: 8, valid_loss: 0.016906998120248318\n",
      "FOLD: 5, EPOCH: 9, train_loss: 0.018467115691384754\n",
      "FOLD: 5, EPOCH: 9, valid_loss: 0.016825637493569117\n",
      "FOLD: 5, EPOCH: 10, train_loss: 0.018203736836644443\n",
      "FOLD: 5, EPOCH: 10, valid_loss: 0.01669319038494275\n",
      "FOLD: 5, EPOCH: 11, train_loss: 0.01805761068858005\n",
      "FOLD: 5, EPOCH: 11, valid_loss: 0.016974651971115515\n",
      "FOLD: 5, EPOCH: 12, train_loss: 0.017774926372677892\n",
      "FOLD: 5, EPOCH: 12, valid_loss: 0.01688774051861121\n",
      "FOLD: 5, EPOCH: 13, train_loss: 0.01733001894191713\n",
      "FOLD: 5, EPOCH: 13, valid_loss: 0.016743920385264434\n",
      "FOLD: 5, EPOCH: 14, train_loss: 0.016818912951527414\n",
      "FOLD: 5, EPOCH: 14, valid_loss: 0.016949592946240537\n",
      "FOLD: 5, EPOCH: 15, train_loss: 0.016223558048541482\n",
      "FOLD: 5, EPOCH: 15, valid_loss: 0.016968552094812576\n",
      "FOLD: 5, EPOCH: 16, train_loss: 0.015391304396797676\n",
      "FOLD: 5, EPOCH: 16, valid_loss: 0.017003734237872638\n",
      "FOLD: 5, EPOCH: 17, train_loss: 0.01439143781474716\n",
      "FOLD: 5, EPOCH: 17, valid_loss: 0.017192155624238346\n",
      "FOLD: 5, EPOCH: 18, train_loss: 0.013190038212751215\n",
      "FOLD: 5, EPOCH: 18, valid_loss: 0.017419985925348904\n",
      "FOLD: 6, EPOCH: 0, train_loss: 0.5779674978473702\n",
      "FOLD: 6, EPOCH: 0, valid_loss: 0.0504121038203056\n",
      "FOLD: 6, EPOCH: 1, train_loss: 0.027657615020871162\n",
      "FOLD: 6, EPOCH: 1, valid_loss: 0.01944775263277384\n",
      "FOLD: 6, EPOCH: 2, train_loss: 0.023171599148898513\n",
      "FOLD: 6, EPOCH: 2, valid_loss: 0.017975884776275892\n",
      "FOLD: 6, EPOCH: 3, train_loss: 0.02301167110232888\n",
      "FOLD: 6, EPOCH: 3, valid_loss: 0.018420450532665618\n",
      "FOLD: 6, EPOCH: 4, train_loss: 0.020820415478099038\n",
      "FOLD: 6, EPOCH: 4, valid_loss: 0.01788990242550006\n",
      "FOLD: 6, EPOCH: 5, train_loss: 0.01992676213282991\n",
      "FOLD: 6, EPOCH: 5, valid_loss: 0.01700428293014948\n",
      "FOLD: 6, EPOCH: 6, train_loss: 0.019140935377091974\n",
      "FOLD: 6, EPOCH: 6, valid_loss: 0.016780318978887338\n",
      "FOLD: 6, EPOCH: 7, train_loss: 0.01874380186200142\n",
      "FOLD: 6, EPOCH: 7, valid_loss: 0.016913970860724267\n",
      "FOLD: 6, EPOCH: 8, train_loss: 0.018525944972360455\n",
      "FOLD: 6, EPOCH: 8, valid_loss: 0.016755950422241137\n",
      "FOLD: 6, EPOCH: 9, train_loss: 0.01827316638082266\n",
      "FOLD: 6, EPOCH: 9, valid_loss: 0.016812113901743524\n",
      "FOLD: 6, EPOCH: 10, train_loss: 0.01810048027215777\n",
      "FOLD: 6, EPOCH: 10, valid_loss: 0.016759279685524795\n",
      "FOLD: 6, EPOCH: 11, train_loss: 0.017876473293211813\n",
      "FOLD: 6, EPOCH: 11, valid_loss: 0.017278792193302743\n",
      "FOLD: 6, EPOCH: 12, train_loss: 0.01759342842961888\n",
      "FOLD: 6, EPOCH: 12, valid_loss: 0.01695787562773778\n",
      "FOLD: 6, EPOCH: 13, train_loss: 0.017184417090705922\n",
      "FOLD: 6, EPOCH: 13, valid_loss: 0.01699962395314987\n",
      "FOLD: 6, EPOCH: 14, train_loss: 0.01664298918802996\n",
      "FOLD: 6, EPOCH: 14, valid_loss: 0.017193269414397385\n",
      "FOLD: 6, EPOCH: 15, train_loss: 0.016056855964298185\n",
      "FOLD: 6, EPOCH: 15, valid_loss: 0.01735593779728963\n",
      "FOLD: 6, EPOCH: 16, train_loss: 0.015036967935392985\n",
      "FOLD: 6, EPOCH: 16, valid_loss: 0.017195884854747698\n",
      "FOLD: 0, EPOCH: 0, train_loss: 0.5787596217281109\n",
      "FOLD: 0, EPOCH: 0, valid_loss: 0.07725895941257477\n",
      "FOLD: 0, EPOCH: 1, train_loss: 0.027690375777515205\n",
      "FOLD: 0, EPOCH: 1, valid_loss: 0.020419712106768902\n",
      "FOLD: 0, EPOCH: 2, train_loss: 0.023121397438887005\n",
      "FOLD: 0, EPOCH: 2, valid_loss: 0.018115635961294174\n",
      "FOLD: 0, EPOCH: 3, train_loss: 0.021275773493422044\n",
      "FOLD: 0, EPOCH: 3, valid_loss: 0.018227981690030832\n",
      "FOLD: 0, EPOCH: 4, train_loss: 0.020257512812276144\n",
      "FOLD: 0, EPOCH: 4, valid_loss: 0.016967742345654048\n",
      "FOLD: 0, EPOCH: 5, train_loss: 0.019197498976781562\n",
      "FOLD: 0, EPOCH: 5, valid_loss: 0.01705052123333399\n",
      "FOLD: 0, EPOCH: 6, train_loss: 0.019235939769124664\n",
      "FOLD: 0, EPOCH: 6, valid_loss: 0.023781869417199723\n",
      "FOLD: 0, EPOCH: 7, train_loss: 0.020038535315039997\n",
      "FOLD: 0, EPOCH: 7, valid_loss: 0.016642434880710565\n",
      "FOLD: 0, EPOCH: 8, train_loss: 0.018910022376961\n",
      "FOLD: 0, EPOCH: 8, valid_loss: 0.016730556407800086\n",
      "FOLD: 0, EPOCH: 9, train_loss: 0.01847922628292361\n",
      "FOLD: 0, EPOCH: 9, valid_loss: 0.016720504356691472\n",
      "FOLD: 0, EPOCH: 10, train_loss: 0.018056071489243895\n",
      "FOLD: 0, EPOCH: 10, valid_loss: 0.01654282111961108\n",
      "FOLD: 0, EPOCH: 11, train_loss: 0.01771083568550042\n",
      "FOLD: 0, EPOCH: 11, valid_loss: 0.016417207267995063\n",
      "FOLD: 0, EPOCH: 12, train_loss: 0.017425878439098597\n",
      "FOLD: 0, EPOCH: 12, valid_loss: 0.016948702172018014\n",
      "FOLD: 0, EPOCH: 13, train_loss: 0.017031187720194057\n",
      "FOLD: 0, EPOCH: 13, valid_loss: 0.016963532051214807\n",
      "FOLD: 0, EPOCH: 14, train_loss: 0.01630749404933807\n",
      "FOLD: 0, EPOCH: 14, valid_loss: 0.01683324883477046\n",
      "FOLD: 0, EPOCH: 15, train_loss: 0.015613838929582286\n",
      "FOLD: 0, EPOCH: 15, valid_loss: 0.017018465038675528\n",
      "FOLD: 0, EPOCH: 16, train_loss: 0.014756668812117062\n",
      "FOLD: 0, EPOCH: 16, valid_loss: 0.01711689394253951\n",
      "FOLD: 1, EPOCH: 0, train_loss: 0.5776332905767737\n",
      "FOLD: 1, EPOCH: 0, valid_loss: 0.041483195641866095\n",
      "FOLD: 1, EPOCH: 1, train_loss: 0.028275437048963598\n",
      "FOLD: 1, EPOCH: 1, valid_loss: 0.01936651708988043\n",
      "FOLD: 1, EPOCH: 2, train_loss: 0.02323118192017884\n",
      "FOLD: 1, EPOCH: 2, valid_loss: 0.017997664041244067\n",
      "FOLD: 1, EPOCH: 3, train_loss: 0.02126395528682986\n",
      "FOLD: 1, EPOCH: 3, valid_loss: 0.017483115339508422\n",
      "FOLD: 1, EPOCH: 4, train_loss: 0.023564787556392117\n",
      "FOLD: 1, EPOCH: 4, valid_loss: 0.017232944185917195\n",
      "FOLD: 1, EPOCH: 5, train_loss: 0.020212244166917092\n",
      "FOLD: 1, EPOCH: 5, valid_loss: 0.016843309052861653\n",
      "FOLD: 1, EPOCH: 6, train_loss: 0.019719076292538964\n",
      "FOLD: 1, EPOCH: 6, valid_loss: 0.01675714308825823\n",
      "FOLD: 1, EPOCH: 7, train_loss: 0.01920518105396548\n",
      "FOLD: 1, EPOCH: 7, valid_loss: 0.0167540365543503\n",
      "FOLD: 1, EPOCH: 8, train_loss: 0.01879082411225583\n",
      "FOLD: 1, EPOCH: 8, valid_loss: 0.016779408503610354\n",
      "FOLD: 1, EPOCH: 9, train_loss: 0.018679513948390614\n",
      "FOLD: 1, EPOCH: 9, valid_loss: 0.017188409343361855\n",
      "FOLD: 1, EPOCH: 10, train_loss: 0.02018999562573594\n",
      "FOLD: 1, EPOCH: 10, valid_loss: 0.016931628808379173\n",
      "FOLD: 1, EPOCH: 11, train_loss: 0.0191045123328631\n",
      "FOLD: 1, EPOCH: 11, valid_loss: 0.016504823731688354\n",
      "FOLD: 1, EPOCH: 12, train_loss: 0.018513290488438028\n",
      "FOLD: 1, EPOCH: 12, valid_loss: 0.016646617736953955\n",
      "FOLD: 1, EPOCH: 13, train_loss: 0.018078017275075655\n",
      "FOLD: 1, EPOCH: 13, valid_loss: 0.016631039432608165\n",
      "FOLD: 1, EPOCH: 14, train_loss: 0.017564928184288578\n",
      "FOLD: 1, EPOCH: 14, valid_loss: 0.01666028009584317\n",
      "FOLD: 1, EPOCH: 15, train_loss: 0.017042016686015838\n",
      "FOLD: 1, EPOCH: 15, valid_loss: 0.016765849091685735\n",
      "FOLD: 1, EPOCH: 16, train_loss: 0.016219375013197597\n",
      "FOLD: 1, EPOCH: 16, valid_loss: 0.016972570035320062\n",
      "FOLD: 1, EPOCH: 17, train_loss: 0.015254275848132532\n",
      "FOLD: 1, EPOCH: 17, valid_loss: 0.01708898335122145\n",
      "FOLD: 1, EPOCH: 18, train_loss: 0.014163116521730617\n",
      "FOLD: 1, EPOCH: 18, valid_loss: 0.01725681577450954\n",
      "FOLD: 2, EPOCH: 0, train_loss: 0.5772665524603547\n",
      "FOLD: 2, EPOCH: 0, valid_loss: 0.03722262411163403\n",
      "FOLD: 2, EPOCH: 1, train_loss: 0.02682476259163908\n",
      "FOLD: 2, EPOCH: 1, valid_loss: 0.019379593145388823\n",
      "FOLD: 2, EPOCH: 2, train_loss: 0.02297527383308153\n",
      "FOLD: 2, EPOCH: 2, valid_loss: 0.021952694568496484\n",
      "FOLD: 2, EPOCH: 3, train_loss: 0.038863351543408794\n",
      "FOLD: 2, EPOCH: 3, valid_loss: 0.020814199000597\n",
      "FOLD: 2, EPOCH: 4, train_loss: 0.023650809165996475\n",
      "FOLD: 2, EPOCH: 4, valid_loss: 0.018931725563911293\n",
      "FOLD: 2, EPOCH: 5, train_loss: 0.022152386630910473\n",
      "FOLD: 2, EPOCH: 5, valid_loss: 0.01824885420501232\n",
      "FOLD: 2, EPOCH: 6, train_loss: 0.02144614513963461\n",
      "FOLD: 2, EPOCH: 6, valid_loss: 0.01785195332307082\n",
      "FOLD: 2, EPOCH: 7, train_loss: 0.020877066521427116\n",
      "FOLD: 2, EPOCH: 7, valid_loss: 0.017886289323751744\n",
      "FOLD: 2, EPOCH: 8, train_loss: 0.02042302766160385\n",
      "FOLD: 2, EPOCH: 8, valid_loss: 0.017389698670460627\n",
      "FOLD: 2, EPOCH: 9, train_loss: 0.019989126311564766\n",
      "FOLD: 2, EPOCH: 9, valid_loss: 0.017379599551741894\n",
      "FOLD: 2, EPOCH: 10, train_loss: 0.019726910074619023\n",
      "FOLD: 2, EPOCH: 10, valid_loss: 0.016962230062255494\n",
      "FOLD: 2, EPOCH: 11, train_loss: 0.019265253826774454\n",
      "FOLD: 2, EPOCH: 11, valid_loss: 0.01680707473021287\n",
      "FOLD: 2, EPOCH: 12, train_loss: 0.018864594072707602\n",
      "FOLD: 2, EPOCH: 12, valid_loss: 0.016736737953928802\n",
      "FOLD: 2, EPOCH: 13, train_loss: 0.018456528517040046\n",
      "FOLD: 2, EPOCH: 13, valid_loss: 0.0166356609417842\n",
      "FOLD: 2, EPOCH: 14, train_loss: 0.018026516294559917\n",
      "FOLD: 2, EPOCH: 14, valid_loss: 0.016500630201055452\n",
      "FOLD: 2, EPOCH: 15, train_loss: 0.017339373737372255\n",
      "FOLD: 2, EPOCH: 15, valid_loss: 0.016611105332580898\n",
      "FOLD: 2, EPOCH: 16, train_loss: 0.016668074135039304\n",
      "FOLD: 2, EPOCH: 16, valid_loss: 0.016599430774266902\n",
      "FOLD: 2, EPOCH: 17, train_loss: 0.015761820863731003\n",
      "FOLD: 2, EPOCH: 17, valid_loss: 0.016740002741034214\n",
      "FOLD: 2, EPOCH: 18, train_loss: 0.014646338122720653\n",
      "FOLD: 2, EPOCH: 18, valid_loss: 0.016799334794856034\n",
      "FOLD: 2, EPOCH: 19, train_loss: 0.013305411497886116\n",
      "FOLD: 2, EPOCH: 19, valid_loss: 0.017211849299760964\n",
      "FOLD: 2, EPOCH: 20, train_loss: 0.011780366515489044\n",
      "FOLD: 2, EPOCH: 20, valid_loss: 0.01719672490771\n",
      "FOLD: 2, EPOCH: 21, train_loss: 0.010332947118660889\n",
      "FOLD: 2, EPOCH: 21, valid_loss: 0.017416192791782893\n",
      "FOLD: 3, EPOCH: 0, train_loss: 0.5760717671867963\n",
      "FOLD: 3, EPOCH: 0, valid_loss: 0.031879077737147994\n",
      "FOLD: 3, EPOCH: 1, train_loss: 0.027283055556787027\n",
      "FOLD: 3, EPOCH: 1, valid_loss: 0.019892320610009707\n",
      "FOLD: 3, EPOCH: 2, train_loss: 0.02311601726388609\n",
      "FOLD: 3, EPOCH: 2, valid_loss: 0.01788546359882905\n",
      "FOLD: 3, EPOCH: 3, train_loss: 0.02731187382360568\n",
      "FOLD: 3, EPOCH: 3, valid_loss: 0.36965771134083086\n",
      "FOLD: 3, EPOCH: 4, train_loss: 0.027908733416650747\n",
      "FOLD: 3, EPOCH: 4, valid_loss: 0.01809485973073886\n",
      "FOLD: 3, EPOCH: 5, train_loss: 0.02265641765316596\n",
      "FOLD: 3, EPOCH: 5, valid_loss: 0.01758604869246483\n",
      "FOLD: 3, EPOCH: 6, train_loss: 0.021353354249652977\n",
      "FOLD: 3, EPOCH: 6, valid_loss: 0.017408028674813416\n",
      "FOLD: 3, EPOCH: 7, train_loss: 0.02041740292632902\n",
      "FOLD: 3, EPOCH: 7, valid_loss: 0.017276603298691604\n",
      "FOLD: 3, EPOCH: 8, train_loss: 0.01992391364497913\n",
      "FOLD: 3, EPOCH: 8, valid_loss: 0.016970246027295407\n",
      "FOLD: 3, EPOCH: 9, train_loss: 0.01957616338355316\n",
      "FOLD: 3, EPOCH: 9, valid_loss: 0.016767318575428083\n",
      "FOLD: 3, EPOCH: 10, train_loss: 0.019233204248185094\n",
      "FOLD: 3, EPOCH: 10, valid_loss: 0.0167516739322589\n",
      "FOLD: 3, EPOCH: 11, train_loss: 0.0188997708059646\n",
      "FOLD: 3, EPOCH: 11, valid_loss: 0.01692108580699334\n",
      "FOLD: 3, EPOCH: 12, train_loss: 0.01855232405501443\n",
      "FOLD: 3, EPOCH: 12, valid_loss: 0.016827171095288716\n",
      "FOLD: 3, EPOCH: 13, train_loss: 0.018112910105972678\n",
      "FOLD: 3, EPOCH: 13, valid_loss: 0.01683964179112361\n",
      "FOLD: 3, EPOCH: 14, train_loss: 0.01762957772793802\n",
      "FOLD: 3, EPOCH: 14, valid_loss: 0.016720518183249693\n",
      "FOLD: 3, EPOCH: 15, train_loss: 0.01701937652369206\n",
      "FOLD: 3, EPOCH: 15, valid_loss: 0.016852583592900865\n",
      "FOLD: 3, EPOCH: 16, train_loss: 0.01626921082670624\n",
      "FOLD: 3, EPOCH: 16, valid_loss: 0.016880555364948053\n",
      "FOLD: 3, EPOCH: 17, train_loss: 0.015266212332691695\n",
      "FOLD: 3, EPOCH: 17, valid_loss: 0.01722084329678462\n",
      "FOLD: 3, EPOCH: 18, train_loss: 0.014014857972191798\n",
      "FOLD: 3, EPOCH: 18, valid_loss: 0.017442233717212312\n",
      "FOLD: 3, EPOCH: 19, train_loss: 0.012512910016183112\n",
      "FOLD: 3, EPOCH: 19, valid_loss: 0.017691826447844505\n",
      "FOLD: 4, EPOCH: 0, train_loss: 0.5775828574960297\n",
      "FOLD: 4, EPOCH: 0, valid_loss: 0.044580954198653884\n",
      "FOLD: 4, EPOCH: 1, train_loss: 0.027136851278309886\n",
      "FOLD: 4, EPOCH: 1, valid_loss: 0.019990885057128392\n",
      "FOLD: 4, EPOCH: 2, train_loss: 0.023067261092364788\n",
      "FOLD: 4, EPOCH: 2, valid_loss: 0.01831155313322177\n",
      "FOLD: 4, EPOCH: 3, train_loss: 0.02144856083936788\n",
      "FOLD: 4, EPOCH: 3, valid_loss: 0.017517120362474367\n",
      "FOLD: 4, EPOCH: 4, train_loss: 0.019912104071998917\n",
      "FOLD: 4, EPOCH: 4, valid_loss: 0.017246639212736718\n",
      "FOLD: 4, EPOCH: 5, train_loss: 0.019603108055889606\n",
      "FOLD: 4, EPOCH: 5, valid_loss: 0.016850198690707866\n",
      "FOLD: 4, EPOCH: 6, train_loss: 0.022540382814367075\n",
      "FOLD: 4, EPOCH: 6, valid_loss: 0.01764392465926134\n",
      "FOLD: 4, EPOCH: 7, train_loss: 0.02083980309701449\n",
      "FOLD: 4, EPOCH: 7, valid_loss: 0.017155225460345928\n",
      "FOLD: 4, EPOCH: 8, train_loss: 0.019916935244927537\n",
      "FOLD: 4, EPOCH: 8, valid_loss: 0.01711823261128022\n",
      "FOLD: 4, EPOCH: 9, train_loss: 0.01935172632235933\n",
      "FOLD: 4, EPOCH: 9, valid_loss: 0.0248330609443096\n",
      "FOLD: 4, EPOCH: 10, train_loss: 0.019337859281615633\n",
      "FOLD: 4, EPOCH: 10, valid_loss: 0.016939724150758523\n",
      "FOLD: 4, EPOCH: 11, train_loss: 0.018749018778672088\n",
      "FOLD: 4, EPOCH: 11, valid_loss: 0.016797179857698772\n",
      "FOLD: 4, EPOCH: 12, train_loss: 0.01830913534236921\n",
      "FOLD: 4, EPOCH: 12, valid_loss: 0.0168081706819626\n",
      "FOLD: 4, EPOCH: 13, train_loss: 0.017948514026765887\n",
      "FOLD: 4, EPOCH: 13, valid_loss: 0.016864592639299538\n",
      "FOLD: 4, EPOCH: 14, train_loss: 0.017523168686878036\n",
      "FOLD: 4, EPOCH: 14, valid_loss: 0.016810416602171384\n",
      "FOLD: 4, EPOCH: 15, train_loss: 0.016933375541624184\n",
      "FOLD: 4, EPOCH: 15, valid_loss: 0.016908670489031535\n",
      "FOLD: 4, EPOCH: 16, train_loss: 0.016066116003974062\n",
      "FOLD: 4, EPOCH: 16, valid_loss: 0.017131951852486685\n",
      "FOLD: 5, EPOCH: 0, train_loss: 0.5772930614750933\n",
      "FOLD: 5, EPOCH: 0, valid_loss: 0.04810401911918934\n",
      "FOLD: 5, EPOCH: 1, train_loss: 0.02723741319936675\n",
      "FOLD: 5, EPOCH: 1, valid_loss: 0.01970961095335392\n",
      "FOLD: 5, EPOCH: 2, train_loss: 0.023133065803228197\n",
      "FOLD: 5, EPOCH: 2, valid_loss: 0.018092637236874837\n",
      "FOLD: 5, EPOCH: 3, train_loss: 0.03177827143588582\n",
      "FOLD: 5, EPOCH: 3, valid_loss: 0.02325858247394745\n",
      "FOLD: 5, EPOCH: 4, train_loss: 0.02419425982579186\n",
      "FOLD: 5, EPOCH: 4, valid_loss: 0.018683823828513805\n",
      "FOLD: 5, EPOCH: 5, train_loss: 0.021843680633685074\n",
      "FOLD: 5, EPOCH: 5, valid_loss: 0.01802331216346759\n",
      "FOLD: 5, EPOCH: 6, train_loss: 0.020924671829955\n",
      "FOLD: 5, EPOCH: 6, valid_loss: 0.017635210417211056\n",
      "FOLD: 5, EPOCH: 7, train_loss: 0.02042511266631049\n",
      "FOLD: 5, EPOCH: 7, valid_loss: 0.017319461832252834\n",
      "FOLD: 5, EPOCH: 8, train_loss: 0.019895977642689203\n",
      "FOLD: 5, EPOCH: 8, valid_loss: 0.016963490070058748\n",
      "FOLD: 5, EPOCH: 9, train_loss: 0.019515037511450214\n",
      "FOLD: 5, EPOCH: 9, valid_loss: 0.016793857615154523\n",
      "FOLD: 5, EPOCH: 10, train_loss: 0.01906225420031193\n",
      "FOLD: 5, EPOCH: 10, valid_loss: 0.016759164917927522\n",
      "FOLD: 5, EPOCH: 11, train_loss: 0.01877257799276629\n",
      "FOLD: 5, EPOCH: 11, valid_loss: 0.01657223615508813\n",
      "FOLD: 5, EPOCH: 12, train_loss: 0.01838529673782555\n",
      "FOLD: 5, EPOCH: 12, valid_loss: 0.016812459995540287\n",
      "FOLD: 5, EPOCH: 13, train_loss: 0.017979404838705384\n",
      "FOLD: 5, EPOCH: 13, valid_loss: 0.016620407310815957\n",
      "FOLD: 5, EPOCH: 14, train_loss: 0.01740087615326047\n",
      "FOLD: 5, EPOCH: 14, valid_loss: 0.016727973921940878\n",
      "FOLD: 5, EPOCH: 15, train_loss: 0.016744332375457964\n",
      "FOLD: 5, EPOCH: 15, valid_loss: 0.016865015459748414\n",
      "FOLD: 5, EPOCH: 16, train_loss: 0.015933485110164493\n",
      "FOLD: 5, EPOCH: 16, valid_loss: 0.01701832412240597\n",
      "FOLD: 5, EPOCH: 17, train_loss: 0.014954391464188293\n",
      "FOLD: 5, EPOCH: 17, valid_loss: 0.017173327433948334\n",
      "FOLD: 5, EPOCH: 18, train_loss: 0.013699880096356611\n",
      "FOLD: 5, EPOCH: 18, valid_loss: 0.017310601085997544\n",
      "FOLD: 5, EPOCH: 19, train_loss: 0.012217773124575615\n",
      "FOLD: 5, EPOCH: 19, valid_loss: 0.01750787956496844\n",
      "FOLD: 6, EPOCH: 0, train_loss: 0.5763720111367671\n",
      "FOLD: 6, EPOCH: 0, valid_loss: 0.03559328615665436\n",
      "FOLD: 6, EPOCH: 1, train_loss: 0.0272473455280871\n",
      "FOLD: 6, EPOCH: 1, valid_loss: 0.01973447432884803\n",
      "FOLD: 6, EPOCH: 2, train_loss: 0.02319748591430284\n",
      "FOLD: 6, EPOCH: 2, valid_loss: 0.018158220327817477\n",
      "FOLD: 6, EPOCH: 3, train_loss: 0.021723853877267323\n",
      "FOLD: 6, EPOCH: 3, valid_loss: 0.017403080844535276\n",
      "FOLD: 6, EPOCH: 4, train_loss: 0.020416398633372138\n",
      "FOLD: 6, EPOCH: 4, valid_loss: 0.017092033074452326\n",
      "FOLD: 6, EPOCH: 5, train_loss: 0.019171500301642996\n",
      "FOLD: 6, EPOCH: 5, valid_loss: 0.016860240353987768\n",
      "FOLD: 6, EPOCH: 6, train_loss: 0.019104647299123777\n",
      "FOLD: 6, EPOCH: 6, valid_loss: 0.016847741575195238\n",
      "FOLD: 6, EPOCH: 7, train_loss: 0.018625366073605175\n",
      "FOLD: 6, EPOCH: 7, valid_loss: 0.01676684023382572\n",
      "FOLD: 6, EPOCH: 8, train_loss: 0.018548145563014456\n",
      "FOLD: 6, EPOCH: 8, valid_loss: 0.017050326586915895\n",
      "FOLD: 6, EPOCH: 9, train_loss: 0.018763675266323058\n",
      "FOLD: 6, EPOCH: 9, valid_loss: 0.017027753190352365\n",
      "FOLD: 6, EPOCH: 10, train_loss: 0.018292799390651083\n",
      "FOLD: 6, EPOCH: 10, valid_loss: 0.01680607097939803\n",
      "FOLD: 6, EPOCH: 11, train_loss: 0.01786834323728407\n",
      "FOLD: 6, EPOCH: 11, valid_loss: 0.016983232675836638\n",
      "FOLD: 6, EPOCH: 12, train_loss: 0.01754828338586801\n",
      "FOLD: 6, EPOCH: 12, valid_loss: 0.017121104523539543\n",
      "FOLD: 6, EPOCH: 13, train_loss: 0.01711252857805104\n",
      "FOLD: 6, EPOCH: 13, valid_loss: 0.016867004621487398\n",
      "FOLD: 6, EPOCH: 14, train_loss: 0.0166044351015542\n",
      "FOLD: 6, EPOCH: 14, valid_loss: 0.01719092742468302\n",
      "FOLD: 6, EPOCH: 15, train_loss: 0.015866835500944306\n",
      "FOLD: 6, EPOCH: 15, valid_loss: 0.017252518293949273\n",
      "FOLD: 6, EPOCH: 16, train_loss: 0.014933154515519336\n",
      "FOLD: 6, EPOCH: 16, valid_loss: 0.017250051721930504\n",
      "FOLD: 6, EPOCH: 17, train_loss: 0.013927643288027597\n",
      "FOLD: 6, EPOCH: 17, valid_loss: 0.017432433624680225\n",
      "FOLD: 0, EPOCH: 0, train_loss: 0.5783735967266399\n",
      "FOLD: 0, EPOCH: 0, valid_loss: 0.04593255829352599\n",
      "FOLD: 0, EPOCH: 1, train_loss: 0.027640461745495733\n",
      "FOLD: 0, EPOCH: 1, valid_loss: 0.019626166528234117\n",
      "FOLD: 0, EPOCH: 2, train_loss: 0.023360641698378162\n",
      "FOLD: 0, EPOCH: 2, valid_loss: 0.018057561694429472\n",
      "FOLD: 0, EPOCH: 3, train_loss: 0.023556621569032606\n",
      "FOLD: 0, EPOCH: 3, valid_loss: 0.017710321224652804\n",
      "FOLD: 0, EPOCH: 4, train_loss: 0.02082211713029726\n",
      "FOLD: 0, EPOCH: 4, valid_loss: 0.018557132723239753\n",
      "FOLD: 0, EPOCH: 5, train_loss: 0.019931468810584094\n",
      "FOLD: 0, EPOCH: 5, valid_loss: 0.016699550601725396\n",
      "FOLD: 0, EPOCH: 6, train_loss: 0.019577279435218992\n",
      "FOLD: 0, EPOCH: 6, valid_loss: 0.016736463285409488\n",
      "FOLD: 0, EPOCH: 7, train_loss: 0.018980773392359953\n",
      "FOLD: 0, EPOCH: 7, valid_loss: 0.2433300935305082\n",
      "FOLD: 0, EPOCH: 8, train_loss: 0.01975716819130891\n",
      "FOLD: 0, EPOCH: 8, valid_loss: 0.016606793309060428\n",
      "FOLD: 0, EPOCH: 9, train_loss: 0.018755370876877696\n",
      "FOLD: 0, EPOCH: 9, valid_loss: 0.016486945991905835\n",
      "FOLD: 0, EPOCH: 10, train_loss: 0.018401072310233437\n",
      "FOLD: 0, EPOCH: 10, valid_loss: 0.016475519093756493\n",
      "FOLD: 0, EPOCH: 11, train_loss: 0.01807327797586048\n",
      "FOLD: 0, EPOCH: 11, valid_loss: 0.016490252903447702\n",
      "FOLD: 0, EPOCH: 12, train_loss: 0.01782198408870278\n",
      "FOLD: 0, EPOCH: 12, valid_loss: 0.0165862524165557\n",
      "FOLD: 0, EPOCH: 13, train_loss: 0.0173588638269418\n",
      "FOLD: 0, EPOCH: 13, valid_loss: 0.016561460896180227\n",
      "FOLD: 0, EPOCH: 14, train_loss: 0.016764362468510062\n",
      "FOLD: 0, EPOCH: 14, valid_loss: 0.016789570164221983\n",
      "FOLD: 0, EPOCH: 15, train_loss: 0.016197460325988563\n",
      "FOLD: 0, EPOCH: 15, valid_loss: 0.016580133269039486\n",
      "FOLD: 0, EPOCH: 16, train_loss: 0.015304993158458052\n",
      "FOLD: 0, EPOCH: 16, valid_loss: 0.01693558033842307\n",
      "FOLD: 0, EPOCH: 17, train_loss: 0.014228543946267786\n",
      "FOLD: 0, EPOCH: 17, valid_loss: 0.017021959719176475\n",
      "FOLD: 1, EPOCH: 0, train_loss: 0.5782711892011198\n",
      "FOLD: 1, EPOCH: 0, valid_loss: 0.03603225230024411\n",
      "FOLD: 1, EPOCH: 1, train_loss: 0.02709136744709434\n",
      "FOLD: 1, EPOCH: 1, valid_loss: 0.0195567486091302\n",
      "FOLD: 1, EPOCH: 2, train_loss: 0.023357271367835032\n",
      "FOLD: 1, EPOCH: 2, valid_loss: 0.0181988411797927\n",
      "FOLD: 1, EPOCH: 3, train_loss: 0.02187776200573992\n",
      "FOLD: 1, EPOCH: 3, valid_loss: 0.017710207889859494\n",
      "FOLD: 1, EPOCH: 4, train_loss: 0.020411173938899428\n",
      "FOLD: 1, EPOCH: 4, valid_loss: 0.01687009517963116\n",
      "FOLD: 1, EPOCH: 5, train_loss: 0.019396812327810237\n",
      "FOLD: 1, EPOCH: 5, valid_loss: 0.016786878928542137\n",
      "FOLD: 1, EPOCH: 6, train_loss: 0.019626265895125027\n",
      "FOLD: 1, EPOCH: 6, valid_loss: 0.020600270193356734\n",
      "FOLD: 1, EPOCH: 7, train_loss: 0.019796784287570295\n",
      "FOLD: 1, EPOCH: 7, valid_loss: 0.016786595806479454\n",
      "FOLD: 1, EPOCH: 8, train_loss: 0.018956409163168958\n",
      "FOLD: 1, EPOCH: 8, valid_loss: 0.016728295443149712\n",
      "FOLD: 1, EPOCH: 9, train_loss: 0.018560296629328985\n",
      "FOLD: 1, EPOCH: 9, valid_loss: 0.0169470479282049\n",
      "FOLD: 1, EPOCH: 10, train_loss: 0.01853370842700069\n",
      "FOLD: 1, EPOCH: 10, valid_loss: 0.017086564778135374\n",
      "FOLD: 1, EPOCH: 11, train_loss: 0.018036549659194174\n",
      "FOLD: 1, EPOCH: 11, valid_loss: 0.016856005845161583\n",
      "FOLD: 1, EPOCH: 12, train_loss: 0.017729296827235737\n",
      "FOLD: 1, EPOCH: 12, valid_loss: 0.016711618679647263\n",
      "FOLD: 1, EPOCH: 13, train_loss: 0.017286585958523525\n",
      "FOLD: 1, EPOCH: 13, valid_loss: 0.016882596179269828\n",
      "FOLD: 1, EPOCH: 14, train_loss: 0.016859404755303183\n",
      "FOLD: 1, EPOCH: 14, valid_loss: 0.016775985391667254\n",
      "FOLD: 1, EPOCH: 15, train_loss: 0.016219830090129696\n",
      "FOLD: 1, EPOCH: 15, valid_loss: 0.01705153687642171\n",
      "FOLD: 1, EPOCH: 16, train_loss: 0.015280102329278315\n",
      "FOLD: 1, EPOCH: 16, valid_loss: 0.01704847955932984\n",
      "FOLD: 1, EPOCH: 17, train_loss: 0.014131933765334857\n",
      "FOLD: 1, EPOCH: 17, valid_loss: 0.017276126604813796\n",
      "FOLD: 1, EPOCH: 18, train_loss: 0.012927430921007652\n",
      "FOLD: 1, EPOCH: 18, valid_loss: 0.017507769310703643\n",
      "FOLD: 2, EPOCH: 0, train_loss: 0.5802208294940961\n",
      "FOLD: 2, EPOCH: 0, valid_loss: 0.06258506098618874\n",
      "FOLD: 2, EPOCH: 1, train_loss: 0.027099427389534744\n",
      "FOLD: 2, EPOCH: 1, valid_loss: 0.01933972122004399\n",
      "FOLD: 2, EPOCH: 2, train_loss: 0.023633394088294055\n",
      "FOLD: 2, EPOCH: 2, valid_loss: 0.01794943041526354\n",
      "FOLD: 2, EPOCH: 3, train_loss: 0.022022269137606427\n",
      "FOLD: 2, EPOCH: 3, valid_loss: 0.01778065814421727\n",
      "FOLD: 2, EPOCH: 4, train_loss: 0.020748683301782287\n",
      "FOLD: 2, EPOCH: 4, valid_loss: 0.017007644933003645\n",
      "FOLD: 2, EPOCH: 5, train_loss: 0.019519143863706977\n",
      "FOLD: 2, EPOCH: 5, valid_loss: 0.016684188077656124\n",
      "FOLD: 2, EPOCH: 6, train_loss: 0.019342529562276764\n",
      "FOLD: 2, EPOCH: 6, valid_loss: 0.016746294899628714\n",
      "FOLD: 2, EPOCH: 7, train_loss: 0.018854086866249908\n",
      "FOLD: 2, EPOCH: 7, valid_loss: 0.016947471608336154\n",
      "FOLD: 2, EPOCH: 8, train_loss: 0.018473514557086134\n",
      "FOLD: 2, EPOCH: 8, valid_loss: 0.016911078674288895\n",
      "FOLD: 2, EPOCH: 9, train_loss: 0.018565509543829673\n",
      "FOLD: 2, EPOCH: 9, valid_loss: 0.023094112769915506\n",
      "FOLD: 2, EPOCH: 10, train_loss: 0.01871345066339583\n",
      "FOLD: 2, EPOCH: 10, valid_loss: 0.016711483924434736\n",
      "FOLD: 2, EPOCH: 11, train_loss: 0.018013929344109586\n",
      "FOLD: 2, EPOCH: 11, valid_loss: 0.016631098750692148\n",
      "FOLD: 2, EPOCH: 12, train_loss: 0.01753638230415212\n",
      "FOLD: 2, EPOCH: 12, valid_loss: 0.01681747058263192\n",
      "FOLD: 2, EPOCH: 13, train_loss: 0.017308502420279627\n",
      "FOLD: 2, EPOCH: 13, valid_loss: 0.01689091410774451\n",
      "FOLD: 2, EPOCH: 14, train_loss: 0.01667554397135973\n",
      "FOLD: 2, EPOCH: 14, valid_loss: 0.016940842310969647\n",
      "FOLD: 2, EPOCH: 15, train_loss: 0.01592106754715378\n",
      "FOLD: 2, EPOCH: 15, valid_loss: 0.01706862893815224\n",
      "FOLD: 2, EPOCH: 16, train_loss: 0.015015619416796678\n",
      "FOLD: 2, EPOCH: 16, valid_loss: 0.01697822058430085\n",
      "FOLD: 3, EPOCH: 0, train_loss: 0.5787479794408018\n",
      "FOLD: 3, EPOCH: 0, valid_loss: 0.07422819618995373\n",
      "FOLD: 3, EPOCH: 1, train_loss: 0.02714931917049595\n",
      "FOLD: 3, EPOCH: 1, valid_loss: 0.019043517657197438\n",
      "FOLD: 3, EPOCH: 2, train_loss: 0.023483752071656084\n",
      "FOLD: 3, EPOCH: 2, valid_loss: 0.01813391653391031\n",
      "FOLD: 3, EPOCH: 3, train_loss: 0.021161340252571815\n",
      "FOLD: 3, EPOCH: 3, valid_loss: 0.017292441656956307\n",
      "FOLD: 3, EPOCH: 4, train_loss: 0.02232616115361452\n",
      "FOLD: 3, EPOCH: 4, valid_loss: 0.017598533573058937\n",
      "FOLD: 3, EPOCH: 5, train_loss: 0.02089430734112456\n",
      "FOLD: 3, EPOCH: 5, valid_loss: 0.016993776680185244\n",
      "FOLD: 3, EPOCH: 6, train_loss: 0.019800076689067726\n",
      "FOLD: 3, EPOCH: 6, valid_loss: 0.0174182690680027\n",
      "FOLD: 3, EPOCH: 7, train_loss: 0.019353320092164183\n",
      "FOLD: 3, EPOCH: 7, valid_loss: 0.01681030341065847\n",
      "FOLD: 3, EPOCH: 8, train_loss: 0.0189477977267391\n",
      "FOLD: 3, EPOCH: 8, valid_loss: 0.016806513500901368\n",
      "FOLD: 3, EPOCH: 9, train_loss: 0.01860884123960057\n",
      "FOLD: 3, EPOCH: 9, valid_loss: 0.016841754603844423\n",
      "FOLD: 3, EPOCH: 10, train_loss: 0.018424016700403112\n",
      "FOLD: 3, EPOCH: 10, valid_loss: 0.016805150259572726\n",
      "FOLD: 3, EPOCH: 11, train_loss: 0.01815664750599378\n",
      "FOLD: 3, EPOCH: 11, valid_loss: 0.016802781691344883\n",
      "FOLD: 3, EPOCH: 12, train_loss: 0.017798644968786755\n",
      "FOLD: 3, EPOCH: 12, valid_loss: 0.017294666514946863\n",
      "FOLD: 3, EPOCH: 13, train_loss: 0.017471005171033983\n",
      "FOLD: 3, EPOCH: 13, valid_loss: 0.016662494709285405\n",
      "FOLD: 3, EPOCH: 14, train_loss: 0.016943802805365744\n",
      "FOLD: 3, EPOCH: 14, valid_loss: 0.01684033455183873\n",
      "FOLD: 3, EPOCH: 15, train_loss: 0.016219391500124254\n",
      "FOLD: 3, EPOCH: 15, valid_loss: 0.01692963527658811\n",
      "FOLD: 3, EPOCH: 16, train_loss: 0.01532412733177881\n",
      "FOLD: 3, EPOCH: 16, valid_loss: 0.017551336007622573\n",
      "FOLD: 3, EPOCH: 17, train_loss: 0.014468780983038046\n",
      "FOLD: 3, EPOCH: 17, valid_loss: 0.01746696334045667\n",
      "FOLD: 3, EPOCH: 18, train_loss: 0.013112108902754011\n",
      "FOLD: 3, EPOCH: 18, valid_loss: 0.017419066566687364\n",
      "FOLD: 3, EPOCH: 19, train_loss: 0.011562007101806434\n",
      "FOLD: 3, EPOCH: 19, valid_loss: 0.01781540349698984\n",
      "FOLD: 4, EPOCH: 0, train_loss: 0.5790278087495953\n",
      "FOLD: 4, EPOCH: 0, valid_loss: 0.03922147647692607\n",
      "FOLD: 4, EPOCH: 1, train_loss: 0.027180526808306977\n",
      "FOLD: 4, EPOCH: 1, valid_loss: 0.01990254710500057\n",
      "FOLD: 4, EPOCH: 2, train_loss: 0.023086635119004828\n",
      "FOLD: 4, EPOCH: 2, valid_loss: 0.018304009277086992\n",
      "FOLD: 4, EPOCH: 3, train_loss: 0.022007190521705796\n",
      "FOLD: 4, EPOCH: 3, valid_loss: 0.018607792946008537\n",
      "FOLD: 4, EPOCH: 4, train_loss: 0.020986254931100318\n",
      "FOLD: 4, EPOCH: 4, valid_loss: 0.017123959457071927\n",
      "FOLD: 4, EPOCH: 5, train_loss: 0.019318101197682524\n",
      "FOLD: 4, EPOCH: 5, valid_loss: 0.016955002784155883\n",
      "FOLD: 4, EPOCH: 6, train_loss: 0.018953488032157358\n",
      "FOLD: 4, EPOCH: 6, valid_loss: 0.016970782182537593\n",
      "FOLD: 4, EPOCH: 7, train_loss: 0.01976087105435294\n",
      "FOLD: 4, EPOCH: 7, valid_loss: 0.01693792060877268\n",
      "FOLD: 4, EPOCH: 8, train_loss: 0.019526933823284263\n",
      "FOLD: 4, EPOCH: 8, valid_loss: 0.0169367861862366\n",
      "FOLD: 4, EPOCH: 9, train_loss: 0.018838605440750316\n",
      "FOLD: 4, EPOCH: 9, valid_loss: 0.01680242671416356\n",
      "FOLD: 4, EPOCH: 10, train_loss: 0.01822007741980456\n",
      "FOLD: 4, EPOCH: 10, valid_loss: 0.016828112948972445\n",
      "FOLD: 4, EPOCH: 11, train_loss: 0.01789561168265504\n",
      "FOLD: 4, EPOCH: 11, valid_loss: 0.016807658669467155\n",
      "FOLD: 4, EPOCH: 12, train_loss: 0.017478788523255167\n",
      "FOLD: 4, EPOCH: 12, valid_loss: 0.016991846191768464\n",
      "FOLD: 4, EPOCH: 13, train_loss: 0.017074815148638713\n",
      "FOLD: 4, EPOCH: 13, valid_loss: 0.016971020099635307\n",
      "FOLD: 4, EPOCH: 14, train_loss: 0.016531016753130668\n",
      "FOLD: 4, EPOCH: 14, valid_loss: 0.017083091374773245\n",
      "FOLD: 4, EPOCH: 15, train_loss: 0.015791938375883007\n",
      "FOLD: 4, EPOCH: 15, valid_loss: 0.01719697765432871\n",
      "FOLD: 4, EPOCH: 16, train_loss: 0.014950381440890802\n",
      "FOLD: 4, EPOCH: 16, valid_loss: 0.01725151103276473\n",
      "FOLD: 4, EPOCH: 17, train_loss: 0.013959992739900545\n",
      "FOLD: 4, EPOCH: 17, valid_loss: 0.017454789593242682\n",
      "FOLD: 5, EPOCH: 0, train_loss: 0.5786491893735286\n",
      "FOLD: 5, EPOCH: 0, valid_loss: 0.03919634079703918\n",
      "FOLD: 5, EPOCH: 1, train_loss: 0.02687645434225733\n",
      "FOLD: 5, EPOCH: 1, valid_loss: 0.019800899263757926\n",
      "FOLD: 5, EPOCH: 2, train_loss: 0.022945214188783557\n",
      "FOLD: 5, EPOCH: 2, valid_loss: 0.01797640101554302\n",
      "FOLD: 5, EPOCH: 3, train_loss: 0.021320500486605876\n",
      "FOLD: 5, EPOCH: 3, valid_loss: 0.017813391123826686\n",
      "FOLD: 5, EPOCH: 4, train_loss: 0.020184609334211092\n",
      "FOLD: 5, EPOCH: 4, valid_loss: 0.017640932248188898\n",
      "FOLD: 5, EPOCH: 5, train_loss: 0.01956258447387734\n",
      "FOLD: 5, EPOCH: 5, valid_loss: 0.01689210032614378\n",
      "FOLD: 5, EPOCH: 6, train_loss: 0.020180547911975835\n",
      "FOLD: 5, EPOCH: 6, valid_loss: 0.01945650205016136\n",
      "FOLD: 5, EPOCH: 7, train_loss: 0.02015912703968383\n",
      "FOLD: 5, EPOCH: 7, valid_loss: 0.017312070498099692\n",
      "FOLD: 5, EPOCH: 8, train_loss: 0.01924158735955889\n",
      "FOLD: 5, EPOCH: 8, valid_loss: 0.01670633851049038\n",
      "FOLD: 5, EPOCH: 9, train_loss: 0.018801738759754476\n",
      "FOLD: 5, EPOCH: 9, valid_loss: 0.016606770599117644\n",
      "FOLD: 5, EPOCH: 10, train_loss: 0.018648361762029095\n",
      "FOLD: 5, EPOCH: 10, valid_loss: 0.016749474506538648\n",
      "FOLD: 5, EPOCH: 11, train_loss: 0.01834542880690581\n",
      "FOLD: 5, EPOCH: 11, valid_loss: 0.016759566532877777\n",
      "FOLD: 5, EPOCH: 12, train_loss: 0.017979455545443942\n",
      "FOLD: 5, EPOCH: 12, valid_loss: 0.016672078806620378\n",
      "FOLD: 5, EPOCH: 13, train_loss: 0.017550814884236536\n",
      "FOLD: 5, EPOCH: 13, valid_loss: 0.016864548150736552\n",
      "FOLD: 5, EPOCH: 14, train_loss: 0.017086066003586795\n",
      "FOLD: 5, EPOCH: 14, valid_loss: 0.01692827855451749\n",
      "FOLD: 5, EPOCH: 15, train_loss: 0.01645630192817063\n",
      "FOLD: 5, EPOCH: 15, valid_loss: 0.016856720814338096\n",
      "FOLD: 5, EPOCH: 16, train_loss: 0.01570727667343375\n",
      "FOLD: 5, EPOCH: 16, valid_loss: 0.01705903108589924\n",
      "FOLD: 5, EPOCH: 17, train_loss: 0.01471616988498214\n",
      "FOLD: 5, EPOCH: 17, valid_loss: 0.01722216785240632\n",
      "FOLD: 6, EPOCH: 0, train_loss: 0.5754464429778021\n",
      "FOLD: 6, EPOCH: 0, valid_loss: 0.04431600094987796\n",
      "FOLD: 6, EPOCH: 1, train_loss: 0.02707964028357654\n",
      "FOLD: 6, EPOCH: 1, valid_loss: 0.01914407269885907\n",
      "FOLD: 6, EPOCH: 2, train_loss: 0.022990243811462377\n",
      "FOLD: 6, EPOCH: 2, valid_loss: 0.025353736888903838\n",
      "FOLD: 6, EPOCH: 3, train_loss: 0.031194264320908365\n",
      "FOLD: 6, EPOCH: 3, valid_loss: 0.01914462375526245\n",
      "FOLD: 6, EPOCH: 4, train_loss: 0.022284082162219124\n",
      "FOLD: 6, EPOCH: 4, valid_loss: 0.01831678473032438\n",
      "FOLD: 6, EPOCH: 5, train_loss: 0.021279110145327206\n",
      "FOLD: 6, EPOCH: 5, valid_loss: 0.01805299248259801\n",
      "FOLD: 6, EPOCH: 6, train_loss: 0.021750919822905515\n",
      "FOLD: 6, EPOCH: 6, valid_loss: 0.018272874160454824\n",
      "FOLD: 6, EPOCH: 7, train_loss: 0.021115935231382783\n",
      "FOLD: 6, EPOCH: 7, valid_loss: 0.017368222300249796\n",
      "FOLD: 6, EPOCH: 8, train_loss: 0.020244338474160916\n",
      "FOLD: 6, EPOCH: 8, valid_loss: 0.017109844117210463\n",
      "FOLD: 6, EPOCH: 9, train_loss: 0.019712587491281935\n",
      "FOLD: 6, EPOCH: 9, valid_loss: 0.01693823403463914\n",
      "FOLD: 6, EPOCH: 10, train_loss: 0.019318804799302203\n",
      "FOLD: 6, EPOCH: 10, valid_loss: 0.01690025871189741\n",
      "FOLD: 6, EPOCH: 11, train_loss: 0.018994905935550057\n",
      "FOLD: 6, EPOCH: 11, valid_loss: 0.016778689092741564\n",
      "FOLD: 6, EPOCH: 12, train_loss: 0.01870880666113383\n",
      "FOLD: 6, EPOCH: 12, valid_loss: 0.01662479813855428\n",
      "FOLD: 6, EPOCH: 13, train_loss: 0.01830234579943322\n",
      "FOLD: 6, EPOCH: 13, valid_loss: 0.016586300988609973\n",
      "FOLD: 6, EPOCH: 14, train_loss: 0.017847482769473177\n",
      "FOLD: 6, EPOCH: 14, valid_loss: 0.016728628856631424\n",
      "FOLD: 6, EPOCH: 15, train_loss: 0.0173996509480718\n",
      "FOLD: 6, EPOCH: 15, valid_loss: 0.01671865826042799\n",
      "FOLD: 6, EPOCH: 16, train_loss: 0.016729605031778682\n",
      "FOLD: 6, EPOCH: 16, valid_loss: 0.016908692196011543\n",
      "FOLD: 6, EPOCH: 17, train_loss: 0.01589476258015713\n",
      "FOLD: 6, EPOCH: 17, valid_loss: 0.016954906571369905\n",
      "FOLD: 6, EPOCH: 18, train_loss: 0.014641133867002823\n",
      "FOLD: 6, EPOCH: 18, valid_loss: 0.017232817526047047\n",
      "FOLD: 6, EPOCH: 19, train_loss: 0.01339787570759654\n",
      "FOLD: 6, EPOCH: 19, valid_loss: 0.017142920683209713\n",
      "FOLD: 6, EPOCH: 20, train_loss: 0.011846576804748259\n",
      "FOLD: 6, EPOCH: 20, valid_loss: 0.01749595684500841\n",
      "FOLD: 0, EPOCH: 0, train_loss: 0.5774172673354278\n",
      "FOLD: 0, EPOCH: 0, valid_loss: 0.03441148022046456\n",
      "FOLD: 0, EPOCH: 1, train_loss: 0.027224153104062017\n",
      "FOLD: 0, EPOCH: 1, valid_loss: 0.019885591302926723\n",
      "FOLD: 0, EPOCH: 2, train_loss: 0.023307643453213008\n",
      "FOLD: 0, EPOCH: 2, valid_loss: 0.01817448207965264\n",
      "FOLD: 0, EPOCH: 3, train_loss: 0.02405150018229678\n",
      "FOLD: 0, EPOCH: 3, valid_loss: 0.02550662051026638\n",
      "FOLD: 0, EPOCH: 4, train_loss: 0.022154822165297496\n",
      "FOLD: 0, EPOCH: 4, valid_loss: 0.01711419239067114\n",
      "FOLD: 0, EPOCH: 5, train_loss: 0.02017354391313888\n",
      "FOLD: 0, EPOCH: 5, valid_loss: 0.01696600177540229\n",
      "FOLD: 0, EPOCH: 6, train_loss: 0.019643954076879733\n",
      "FOLD: 0, EPOCH: 6, valid_loss: 0.016839731771212358\n",
      "FOLD: 0, EPOCH: 7, train_loss: 0.019967833961788063\n",
      "FOLD: 0, EPOCH: 7, valid_loss: 0.016881440121393938\n",
      "FOLD: 0, EPOCH: 8, train_loss: 0.01953230898927998\n",
      "FOLD: 0, EPOCH: 8, valid_loss: 0.016720539317108117\n",
      "FOLD: 0, EPOCH: 9, train_loss: 0.019002396059600083\n",
      "FOLD: 0, EPOCH: 9, valid_loss: 0.016628371981474068\n",
      "FOLD: 0, EPOCH: 10, train_loss: 0.01868551201816346\n",
      "FOLD: 0, EPOCH: 10, valid_loss: 0.016532951392806493\n",
      "FOLD: 0, EPOCH: 11, train_loss: 0.018328521249664796\n",
      "FOLD: 0, EPOCH: 11, valid_loss: 0.01650337179979453\n",
      "FOLD: 0, EPOCH: 12, train_loss: 0.01802869128516397\n",
      "FOLD: 0, EPOCH: 12, valid_loss: 0.01654239808424161\n",
      "FOLD: 0, EPOCH: 13, train_loss: 0.017550794672019577\n",
      "FOLD: 0, EPOCH: 13, valid_loss: 0.01662599166425375\n",
      "FOLD: 0, EPOCH: 14, train_loss: 0.01708611989444172\n",
      "FOLD: 0, EPOCH: 14, valid_loss: 0.016730439061155684\n",
      "FOLD: 0, EPOCH: 15, train_loss: 0.016554275540181913\n",
      "FOLD: 0, EPOCH: 15, valid_loss: 0.016931061632931232\n",
      "FOLD: 0, EPOCH: 16, train_loss: 0.015684113774851367\n",
      "FOLD: 0, EPOCH: 16, valid_loss: 0.017144068215902034\n",
      "FOLD: 0, EPOCH: 17, train_loss: 0.014593199398872015\n",
      "FOLD: 0, EPOCH: 17, valid_loss: 0.01702061488937873\n",
      "FOLD: 0, EPOCH: 18, train_loss: 0.013398384687969007\n",
      "FOLD: 0, EPOCH: 18, valid_loss: 0.017351351105249845\n",
      "FOLD: 0, EPOCH: 19, train_loss: 0.011999470232104932\n",
      "FOLD: 0, EPOCH: 19, valid_loss: 0.01738468944453276\n",
      "FOLD: 1, EPOCH: 0, train_loss: 0.5771141893960334\n",
      "FOLD: 1, EPOCH: 0, valid_loss: 0.04380436413563215\n",
      "FOLD: 1, EPOCH: 1, train_loss: 0.027087196607042004\n",
      "FOLD: 1, EPOCH: 1, valid_loss: 0.01902213477744506\n",
      "FOLD: 1, EPOCH: 2, train_loss: 0.022774107074616728\n",
      "FOLD: 1, EPOCH: 2, valid_loss: 0.018176996077482518\n",
      "FOLD: 1, EPOCH: 3, train_loss: 0.03196202548271095\n",
      "FOLD: 1, EPOCH: 3, valid_loss: 0.019649945486050386\n",
      "FOLD: 1, EPOCH: 4, train_loss: 0.0227407088402558\n",
      "FOLD: 1, EPOCH: 4, valid_loss: 0.018283744557545736\n",
      "FOLD: 1, EPOCH: 5, train_loss: 0.021380289835301606\n",
      "FOLD: 1, EPOCH: 5, valid_loss: 0.01785363557820137\n",
      "FOLD: 1, EPOCH: 6, train_loss: 0.02070483089600866\n",
      "FOLD: 1, EPOCH: 6, valid_loss: 0.017296189728837747\n",
      "FOLD: 1, EPOCH: 7, train_loss: 0.020175098517053836\n",
      "FOLD: 1, EPOCH: 7, valid_loss: 0.01720324344933033\n",
      "FOLD: 1, EPOCH: 8, train_loss: 0.01983983301230379\n",
      "FOLD: 1, EPOCH: 8, valid_loss: 0.016935753994263135\n",
      "FOLD: 1, EPOCH: 9, train_loss: 0.019392212928348296\n",
      "FOLD: 1, EPOCH: 9, valid_loss: 0.0168910283022202\n",
      "FOLD: 1, EPOCH: 10, train_loss: 0.019045475895541744\n",
      "FOLD: 1, EPOCH: 10, valid_loss: 0.016627945507375095\n",
      "FOLD: 1, EPOCH: 11, train_loss: 0.018695497583295848\n",
      "FOLD: 1, EPOCH: 11, valid_loss: 0.016706080534137212\n",
      "FOLD: 1, EPOCH: 12, train_loss: 0.018429641838412027\n",
      "FOLD: 1, EPOCH: 12, valid_loss: 0.016519267112016678\n",
      "FOLD: 1, EPOCH: 13, train_loss: 0.018053000792860985\n",
      "FOLD: 1, EPOCH: 13, valid_loss: 0.01662516250060155\n",
      "FOLD: 1, EPOCH: 14, train_loss: 0.01760685894436933\n",
      "FOLD: 1, EPOCH: 14, valid_loss: 0.01675419036585551\n",
      "FOLD: 1, EPOCH: 15, train_loss: 0.017056832253630902\n",
      "FOLD: 1, EPOCH: 15, valid_loss: 0.016779758465977814\n",
      "FOLD: 1, EPOCH: 16, train_loss: 0.01637365806193368\n",
      "FOLD: 1, EPOCH: 16, valid_loss: 0.016879352024541452\n",
      "FOLD: 1, EPOCH: 17, train_loss: 0.015365983070050543\n",
      "FOLD: 1, EPOCH: 17, valid_loss: 0.01695670674626644\n",
      "FOLD: 1, EPOCH: 18, train_loss: 0.014141829432667914\n",
      "FOLD: 1, EPOCH: 18, valid_loss: 0.017093946655782368\n",
      "FOLD: 1, EPOCH: 19, train_loss: 0.012791863932098085\n",
      "FOLD: 1, EPOCH: 19, valid_loss: 0.01723629178909155\n",
      "FOLD: 2, EPOCH: 0, train_loss: 0.5786373895165082\n",
      "FOLD: 2, EPOCH: 0, valid_loss: 0.04090360236855654\n",
      "FOLD: 2, EPOCH: 1, train_loss: 0.027316086371806828\n",
      "FOLD: 2, EPOCH: 1, valid_loss: 0.019708495300549727\n",
      "FOLD: 2, EPOCH: 2, train_loss: 0.02301974327781716\n",
      "FOLD: 2, EPOCH: 2, valid_loss: 0.017779434386354227\n",
      "FOLD: 2, EPOCH: 3, train_loss: 0.021720071197361558\n",
      "FOLD: 2, EPOCH: 3, valid_loss: 0.017529659403058197\n",
      "FOLD: 2, EPOCH: 4, train_loss: 0.02019221818930394\n",
      "FOLD: 2, EPOCH: 4, valid_loss: 0.01688787455742176\n",
      "FOLD: 2, EPOCH: 5, train_loss: 0.020972687071440992\n",
      "FOLD: 2, EPOCH: 5, valid_loss: 0.01712875426388704\n",
      "FOLD: 2, EPOCH: 6, train_loss: 0.01970579767146626\n",
      "FOLD: 2, EPOCH: 6, valid_loss: 0.016887760219665673\n",
      "FOLD: 2, EPOCH: 7, train_loss: 0.019059819723101886\n",
      "FOLD: 2, EPOCH: 7, valid_loss: 0.016862948496754352\n",
      "FOLD: 2, EPOCH: 8, train_loss: 0.0188430192553111\n",
      "FOLD: 2, EPOCH: 8, valid_loss: 0.01673261119196048\n",
      "FOLD: 2, EPOCH: 9, train_loss: 0.018589678220450878\n",
      "FOLD: 2, EPOCH: 9, valid_loss: 0.0170019708860379\n",
      "FOLD: 2, EPOCH: 10, train_loss: 0.01845086338250218\n",
      "FOLD: 2, EPOCH: 10, valid_loss: 0.016913143631357413\n",
      "FOLD: 2, EPOCH: 11, train_loss: 0.018183166211521305\n",
      "FOLD: 2, EPOCH: 11, valid_loss: 0.016975568177608345\n",
      "FOLD: 2, EPOCH: 12, train_loss: 0.017826590334644187\n",
      "FOLD: 2, EPOCH: 12, valid_loss: 0.01719115789120014\n",
      "FOLD: 2, EPOCH: 13, train_loss: 0.017574912339851662\n",
      "FOLD: 2, EPOCH: 13, valid_loss: 0.01666671811388089\n",
      "FOLD: 2, EPOCH: 14, train_loss: 0.017058612237608916\n",
      "FOLD: 2, EPOCH: 14, valid_loss: 0.016961790478000276\n",
      "FOLD: 2, EPOCH: 15, train_loss: 0.01639733444647612\n",
      "FOLD: 2, EPOCH: 15, valid_loss: 0.016997940838336945\n",
      "FOLD: 2, EPOCH: 16, train_loss: 0.015573771657875261\n",
      "FOLD: 2, EPOCH: 16, valid_loss: 0.01687930696285688\n",
      "FOLD: 2, EPOCH: 17, train_loss: 0.0145282685832196\n",
      "FOLD: 2, EPOCH: 17, valid_loss: 0.017255438634982474\n",
      "FOLD: 2, EPOCH: 18, train_loss: 0.013244065833655564\n",
      "FOLD: 2, EPOCH: 18, valid_loss: 0.017389594505612668\n",
      "FOLD: 3, EPOCH: 0, train_loss: 0.5772956133492895\n",
      "FOLD: 3, EPOCH: 0, valid_loss: 0.04106774066503231\n",
      "FOLD: 3, EPOCH: 1, train_loss: 0.02743919863290078\n",
      "FOLD: 3, EPOCH: 1, valid_loss: 0.01995957141312269\n",
      "FOLD: 3, EPOCH: 2, train_loss: 0.023781468009425176\n",
      "FOLD: 3, EPOCH: 2, valid_loss: 0.0208890915203553\n",
      "FOLD: 3, EPOCH: 3, train_loss: 0.021582214262437175\n",
      "FOLD: 3, EPOCH: 3, valid_loss: 0.017184608687575046\n",
      "FOLD: 3, EPOCH: 4, train_loss: 0.022990101444962864\n",
      "FOLD: 3, EPOCH: 4, valid_loss: 0.05246263914383375\n",
      "FOLD: 3, EPOCH: 5, train_loss: 0.023068230624335842\n",
      "FOLD: 3, EPOCH: 5, valid_loss: 0.017834516385426886\n",
      "FOLD: 3, EPOCH: 6, train_loss: 0.020908241739144195\n",
      "FOLD: 3, EPOCH: 6, valid_loss: 0.017221766165815867\n",
      "FOLD: 3, EPOCH: 7, train_loss: 0.02025008626987\n",
      "FOLD: 3, EPOCH: 7, valid_loss: 0.016912115307954643\n",
      "FOLD: 3, EPOCH: 8, train_loss: 0.019764478519760275\n",
      "FOLD: 3, EPOCH: 8, valid_loss: 0.016842644804945357\n",
      "FOLD: 3, EPOCH: 9, train_loss: 0.01940074917935842\n",
      "FOLD: 3, EPOCH: 9, valid_loss: 0.016770591242955282\n",
      "FOLD: 3, EPOCH: 10, train_loss: 0.01909545177241435\n",
      "FOLD: 3, EPOCH: 10, valid_loss: 0.016874238705405824\n",
      "FOLD: 3, EPOCH: 11, train_loss: 0.018831111113163265\n",
      "FOLD: 3, EPOCH: 11, valid_loss: 0.0167968082599915\n",
      "FOLD: 3, EPOCH: 12, train_loss: 0.018562417175318743\n",
      "FOLD: 3, EPOCH: 12, valid_loss: 0.016756561011649095\n",
      "FOLD: 3, EPOCH: 13, train_loss: 0.018276935254500526\n",
      "FOLD: 3, EPOCH: 13, valid_loss: 0.01665440438171992\n",
      "FOLD: 3, EPOCH: 14, train_loss: 0.017790775846790622\n",
      "FOLD: 3, EPOCH: 14, valid_loss: 0.016787204175041273\n",
      "FOLD: 3, EPOCH: 15, train_loss: 0.017340702747271675\n",
      "FOLD: 3, EPOCH: 15, valid_loss: 0.016665818384633616\n",
      "FOLD: 3, EPOCH: 16, train_loss: 0.016675103820759703\n",
      "FOLD: 3, EPOCH: 16, valid_loss: 0.01695658667729451\n",
      "FOLD: 3, EPOCH: 17, train_loss: 0.015736253479042568\n",
      "FOLD: 3, EPOCH: 17, valid_loss: 0.01708440869473494\n",
      "FOLD: 4, EPOCH: 0, train_loss: 0.5775113151584929\n",
      "FOLD: 4, EPOCH: 0, valid_loss: 0.03707243760044758\n",
      "FOLD: 4, EPOCH: 1, train_loss: 0.02686617072873019\n",
      "FOLD: 4, EPOCH: 1, valid_loss: 0.019265990131176434\n",
      "FOLD: 4, EPOCH: 2, train_loss: 0.023014782298658346\n",
      "FOLD: 4, EPOCH: 2, valid_loss: 0.023945611543380298\n",
      "FOLD: 4, EPOCH: 3, train_loss: 0.0224323851887036\n",
      "FOLD: 4, EPOCH: 3, valid_loss: 0.018785994929762986\n",
      "FOLD: 4, EPOCH: 4, train_loss: 0.0206784273976007\n",
      "FOLD: 4, EPOCH: 4, valid_loss: 0.01728057603423412\n",
      "FOLD: 4, EPOCH: 5, train_loss: 0.019593051659899788\n",
      "FOLD: 4, EPOCH: 5, valid_loss: 0.016893070191144943\n",
      "FOLD: 4, EPOCH: 6, train_loss: 0.019136053157617915\n",
      "FOLD: 4, EPOCH: 6, valid_loss: 0.016839756128879693\n",
      "FOLD: 4, EPOCH: 7, train_loss: 0.018843877305452887\n",
      "FOLD: 4, EPOCH: 7, valid_loss: 0.01728793176320883\n",
      "FOLD: 4, EPOCH: 8, train_loss: 0.018624623079557676\n",
      "FOLD: 4, EPOCH: 8, valid_loss: 0.016800367918152075\n",
      "FOLD: 4, EPOCH: 9, train_loss: 0.018308837067436527\n",
      "FOLD: 4, EPOCH: 9, valid_loss: 0.016920077757766612\n",
      "FOLD: 4, EPOCH: 10, train_loss: 0.01814314549335757\n",
      "FOLD: 4, EPOCH: 10, valid_loss: 0.01715754273419197\n",
      "FOLD: 4, EPOCH: 11, train_loss: 0.017960652205589657\n",
      "FOLD: 4, EPOCH: 11, valid_loss: 0.016751375049352646\n",
      "FOLD: 4, EPOCH: 12, train_loss: 0.0175518729925357\n",
      "FOLD: 4, EPOCH: 12, valid_loss: 0.016869324617660962\n",
      "FOLD: 4, EPOCH: 13, train_loss: 0.017160617117140745\n",
      "FOLD: 4, EPOCH: 13, valid_loss: 0.017049604525359776\n",
      "FOLD: 4, EPOCH: 14, train_loss: 0.016575023468986556\n",
      "FOLD: 4, EPOCH: 14, valid_loss: 0.017262011766433716\n",
      "FOLD: 4, EPOCH: 15, train_loss: 0.015946525866417465\n",
      "FOLD: 4, EPOCH: 15, valid_loss: 0.0172968885073295\n",
      "FOLD: 4, EPOCH: 16, train_loss: 0.015100872043419528\n",
      "FOLD: 4, EPOCH: 16, valid_loss: 0.017288289964199066\n",
      "FOLD: 4, EPOCH: 17, train_loss: 0.014162654334024803\n",
      "FOLD: 4, EPOCH: 17, valid_loss: 0.017523651082928363\n",
      "FOLD: 5, EPOCH: 0, train_loss: 0.5750927403065804\n",
      "FOLD: 5, EPOCH: 0, valid_loss: 0.0414030933036254\n",
      "FOLD: 5, EPOCH: 1, train_loss: 0.026779841480625642\n",
      "FOLD: 5, EPOCH: 1, valid_loss: 0.019243597984313965\n",
      "FOLD: 5, EPOCH: 2, train_loss: 0.022578527697840252\n",
      "FOLD: 5, EPOCH: 2, valid_loss: 0.018329534034889478\n",
      "FOLD: 5, EPOCH: 3, train_loss: 0.03533673077519681\n",
      "FOLD: 5, EPOCH: 3, valid_loss: 0.021090262068005707\n",
      "FOLD: 5, EPOCH: 4, train_loss: 0.023577875860438153\n",
      "FOLD: 5, EPOCH: 4, valid_loss: 0.018936116749850605\n",
      "FOLD: 5, EPOCH: 5, train_loss: 0.021931307717553666\n",
      "FOLD: 5, EPOCH: 5, valid_loss: 0.018465345438856345\n",
      "FOLD: 5, EPOCH: 6, train_loss: 0.021091288358375832\n",
      "FOLD: 5, EPOCH: 6, valid_loss: 0.01795299781056551\n",
      "FOLD: 5, EPOCH: 7, train_loss: 0.02057228433723385\n",
      "FOLD: 5, EPOCH: 7, valid_loss: 0.01759369778805054\n",
      "FOLD: 5, EPOCH: 8, train_loss: 0.019966302917817154\n",
      "FOLD: 5, EPOCH: 8, valid_loss: 0.017213469227919213\n",
      "FOLD: 5, EPOCH: 9, train_loss: 0.019596519175212126\n",
      "FOLD: 5, EPOCH: 9, valid_loss: 0.017013623379170895\n",
      "FOLD: 5, EPOCH: 10, train_loss: 0.019192235166760715\n",
      "FOLD: 5, EPOCH: 10, valid_loss: 0.016689612028690484\n",
      "FOLD: 5, EPOCH: 11, train_loss: 0.018889447221079388\n",
      "FOLD: 5, EPOCH: 11, valid_loss: 0.01678982563316822\n",
      "FOLD: 5, EPOCH: 12, train_loss: 0.018510997672942845\n",
      "FOLD: 5, EPOCH: 12, valid_loss: 0.016928127895180996\n",
      "FOLD: 5, EPOCH: 13, train_loss: 0.018023716789242382\n",
      "FOLD: 5, EPOCH: 13, valid_loss: 0.016693804699641008\n",
      "FOLD: 5, EPOCH: 14, train_loss: 0.01744049256415786\n",
      "FOLD: 5, EPOCH: 14, valid_loss: 0.016684807622088835\n",
      "FOLD: 5, EPOCH: 15, train_loss: 0.01683848211541772\n",
      "FOLD: 5, EPOCH: 15, valid_loss: 0.01671952954851664\n",
      "FOLD: 5, EPOCH: 16, train_loss: 0.016076502528645703\n",
      "FOLD: 5, EPOCH: 16, valid_loss: 0.016912312963261053\n",
      "FOLD: 5, EPOCH: 17, train_loss: 0.015174166450427996\n",
      "FOLD: 5, EPOCH: 17, valid_loss: 0.016809548896092635\n",
      "FOLD: 5, EPOCH: 18, train_loss: 0.013940850939803026\n",
      "FOLD: 5, EPOCH: 18, valid_loss: 0.017160310553243525\n",
      "FOLD: 6, EPOCH: 0, train_loss: 0.577177573901576\n",
      "FOLD: 6, EPOCH: 0, valid_loss: 0.03429469552177649\n",
      "FOLD: 6, EPOCH: 1, train_loss: 0.026976496761513723\n",
      "FOLD: 6, EPOCH: 1, valid_loss: 0.019418619716396697\n",
      "FOLD: 6, EPOCH: 2, train_loss: 0.023548881397456735\n",
      "FOLD: 6, EPOCH: 2, valid_loss: 0.01959502539382531\n",
      "FOLD: 6, EPOCH: 3, train_loss: 0.021624354091850487\n",
      "FOLD: 6, EPOCH: 3, valid_loss: 0.017774529898395904\n",
      "FOLD: 6, EPOCH: 4, train_loss: 0.020835323913677317\n",
      "FOLD: 6, EPOCH: 4, valid_loss: 0.02082692874738803\n",
      "FOLD: 6, EPOCH: 5, train_loss: 0.021549534983932972\n",
      "FOLD: 6, EPOCH: 5, valid_loss: 0.01763587831877745\n",
      "FOLD: 6, EPOCH: 6, train_loss: 0.019860047872203426\n",
      "FOLD: 6, EPOCH: 6, valid_loss: 0.017121184187439773\n",
      "FOLD: 6, EPOCH: 7, train_loss: 0.01941133924835437\n",
      "FOLD: 6, EPOCH: 7, valid_loss: 0.016897638614934225\n",
      "FOLD: 6, EPOCH: 8, train_loss: 0.019175159090475458\n",
      "FOLD: 6, EPOCH: 8, valid_loss: 0.016829385780371152\n",
      "FOLD: 6, EPOCH: 9, train_loss: 0.01900140377315315\n",
      "FOLD: 6, EPOCH: 9, valid_loss: 0.016848006643928014\n",
      "FOLD: 6, EPOCH: 10, train_loss: 0.018848993790310783\n",
      "FOLD: 6, EPOCH: 10, valid_loss: 0.01671822240146307\n",
      "FOLD: 6, EPOCH: 11, train_loss: 0.018590609618538135\n",
      "FOLD: 6, EPOCH: 11, valid_loss: 0.01690691773994611\n",
      "FOLD: 6, EPOCH: 12, train_loss: 0.01841388494279739\n",
      "FOLD: 6, EPOCH: 12, valid_loss: 0.016690554455495797\n",
      "FOLD: 6, EPOCH: 13, train_loss: 0.018084345586799288\n",
      "FOLD: 6, EPOCH: 13, valid_loss: 0.016626901996250335\n",
      "FOLD: 6, EPOCH: 14, train_loss: 0.01770597157647481\n",
      "FOLD: 6, EPOCH: 14, valid_loss: 0.016593373094040614\n",
      "FOLD: 6, EPOCH: 15, train_loss: 0.017288061538459482\n",
      "FOLD: 6, EPOCH: 15, valid_loss: 0.01663905604240986\n",
      "FOLD: 6, EPOCH: 16, train_loss: 0.016736244329729595\n",
      "FOLD: 6, EPOCH: 16, valid_loss: 0.01683146606844205\n",
      "FOLD: 6, EPOCH: 17, train_loss: 0.01584313504045477\n",
      "FOLD: 6, EPOCH: 17, valid_loss: 0.01681021235596675\n",
      "FOLD: 6, EPOCH: 18, train_loss: 0.014870354100256352\n",
      "FOLD: 6, EPOCH: 18, valid_loss: 0.017124935769690916\n",
      "FOLD: 6, EPOCH: 19, train_loss: 0.013591362276693454\n",
      "FOLD: 6, EPOCH: 19, valid_loss: 0.01716374233365059\n",
      "FOLD: 6, EPOCH: 20, train_loss: 0.012162515780309567\n",
      "FOLD: 6, EPOCH: 20, valid_loss: 0.017261796845839575\n",
      "FOLD: 0, EPOCH: 0, train_loss: 0.577810210654059\n",
      "FOLD: 0, EPOCH: 0, valid_loss: 0.050117130462939925\n",
      "FOLD: 0, EPOCH: 1, train_loss: 0.026855987119110854\n",
      "FOLD: 0, EPOCH: 1, valid_loss: 0.02006723602803854\n",
      "FOLD: 0, EPOCH: 2, train_loss: 0.023215315606747125\n",
      "FOLD: 0, EPOCH: 2, valid_loss: 0.02402276946948125\n",
      "FOLD: 0, EPOCH: 3, train_loss: 0.023915802783055884\n",
      "FOLD: 0, EPOCH: 3, valid_loss: 0.017198780694833167\n",
      "FOLD: 0, EPOCH: 4, train_loss: 0.020379860407194576\n",
      "FOLD: 0, EPOCH: 4, valid_loss: 0.0167570854178988\n",
      "FOLD: 0, EPOCH: 5, train_loss: 0.020348694452361482\n",
      "FOLD: 0, EPOCH: 5, valid_loss: 0.16990864678071096\n",
      "FOLD: 0, EPOCH: 6, train_loss: 0.02102814587084828\n",
      "FOLD: 0, EPOCH: 6, valid_loss: 0.01700977121408169\n",
      "FOLD: 0, EPOCH: 7, train_loss: 0.019774720727189166\n",
      "FOLD: 0, EPOCH: 7, valid_loss: 0.01673904011169305\n",
      "FOLD: 0, EPOCH: 8, train_loss: 0.01932497919109222\n",
      "FOLD: 0, EPOCH: 8, valid_loss: 0.016514806578365657\n",
      "FOLD: 0, EPOCH: 9, train_loss: 0.018956397936956304\n",
      "FOLD: 0, EPOCH: 9, valid_loss: 0.016362865455448627\n",
      "FOLD: 0, EPOCH: 10, train_loss: 0.018713119741831277\n",
      "FOLD: 0, EPOCH: 10, valid_loss: 0.016593821060199004\n",
      "FOLD: 0, EPOCH: 11, train_loss: 0.01841571171944206\n",
      "FOLD: 0, EPOCH: 11, valid_loss: 0.016439394380610723\n",
      "FOLD: 0, EPOCH: 12, train_loss: 0.01815802143332926\n",
      "FOLD: 0, EPOCH: 12, valid_loss: 0.016441316845325325\n",
      "FOLD: 0, EPOCH: 13, train_loss: 0.01787893521926693\n",
      "FOLD: 0, EPOCH: 13, valid_loss: 0.016514617304962415\n",
      "FOLD: 0, EPOCH: 14, train_loss: 0.017393245726723124\n",
      "FOLD: 0, EPOCH: 14, valid_loss: 0.01655855108625614\n",
      "FOLD: 0, EPOCH: 15, train_loss: 0.016741012776824268\n",
      "FOLD: 0, EPOCH: 15, valid_loss: 0.016660600399168637\n",
      "FOLD: 0, EPOCH: 16, train_loss: 0.01605310124924054\n",
      "FOLD: 0, EPOCH: 16, valid_loss: 0.016791494491581734\n",
      "FOLD: 1, EPOCH: 0, train_loss: 0.5783148739184882\n",
      "FOLD: 1, EPOCH: 0, valid_loss: 0.0393473907158925\n",
      "FOLD: 1, EPOCH: 1, train_loss: 0.02684624694489144\n",
      "FOLD: 1, EPOCH: 1, valid_loss: 0.019356670431219615\n",
      "FOLD: 1, EPOCH: 2, train_loss: 0.02316110538369095\n",
      "FOLD: 1, EPOCH: 2, valid_loss: 0.017798395540851813\n",
      "FOLD: 1, EPOCH: 3, train_loss: 0.02154733706265688\n",
      "FOLD: 1, EPOCH: 3, valid_loss: 0.017313205278836764\n",
      "FOLD: 1, EPOCH: 4, train_loss: 0.02142690378870513\n",
      "FOLD: 1, EPOCH: 4, valid_loss: 0.017052444987572156\n",
      "FOLD: 1, EPOCH: 5, train_loss: 0.01970773784292711\n",
      "FOLD: 1, EPOCH: 5, valid_loss: 0.016895107495097015\n",
      "FOLD: 1, EPOCH: 6, train_loss: 0.019166411555095297\n",
      "FOLD: 1, EPOCH: 6, valid_loss: 0.017011896062355775\n",
      "FOLD: 1, EPOCH: 7, train_loss: 0.021571401934567337\n",
      "FOLD: 1, EPOCH: 7, valid_loss: 0.0176681844660869\n",
      "FOLD: 1, EPOCH: 8, train_loss: 0.020591976800681772\n",
      "FOLD: 1, EPOCH: 8, valid_loss: 0.017240910432659663\n",
      "FOLD: 1, EPOCH: 9, train_loss: 0.01986276763617187\n",
      "FOLD: 1, EPOCH: 9, valid_loss: 0.017133341242487613\n",
      "FOLD: 1, EPOCH: 10, train_loss: 0.01942740851459471\n",
      "FOLD: 1, EPOCH: 10, valid_loss: 0.016967351620013896\n",
      "FOLD: 1, EPOCH: 11, train_loss: 0.01909085871601427\n",
      "FOLD: 1, EPOCH: 11, valid_loss: 0.016718481882260397\n",
      "FOLD: 1, EPOCH: 12, train_loss: 0.018669908740431874\n",
      "FOLD: 1, EPOCH: 12, valid_loss: 0.016620435322133396\n",
      "FOLD: 1, EPOCH: 13, train_loss: 0.01830396013384735\n",
      "FOLD: 1, EPOCH: 13, valid_loss: 0.016587707285697643\n",
      "FOLD: 1, EPOCH: 14, train_loss: 0.017958751325873105\n",
      "FOLD: 1, EPOCH: 14, valid_loss: 0.016614605601017293\n",
      "FOLD: 1, EPOCH: 15, train_loss: 0.01748248645280664\n",
      "FOLD: 1, EPOCH: 15, valid_loss: 0.0166757027260386\n",
      "FOLD: 1, EPOCH: 16, train_loss: 0.016860623290208546\n",
      "FOLD: 1, EPOCH: 16, valid_loss: 0.016662051901221275\n",
      "FOLD: 1, EPOCH: 17, train_loss: 0.016057142874578368\n",
      "FOLD: 1, EPOCH: 17, valid_loss: 0.01684882355710635\n",
      "FOLD: 1, EPOCH: 18, train_loss: 0.01498594875069889\n",
      "FOLD: 1, EPOCH: 18, valid_loss: 0.01690294249699666\n",
      "FOLD: 2, EPOCH: 0, train_loss: 0.5758963114506489\n",
      "FOLD: 2, EPOCH: 0, valid_loss: 0.03911957603234511\n",
      "FOLD: 2, EPOCH: 1, train_loss: 0.027229520089521602\n",
      "FOLD: 2, EPOCH: 1, valid_loss: 0.019989639807205934\n",
      "FOLD: 2, EPOCH: 2, train_loss: 0.02310627870060302\n",
      "FOLD: 2, EPOCH: 2, valid_loss: 0.018117999801268943\n",
      "FOLD: 2, EPOCH: 3, train_loss: 0.022333307669976273\n",
      "FOLD: 2, EPOCH: 3, valid_loss: 0.017443146270055037\n",
      "FOLD: 2, EPOCH: 4, train_loss: 0.020087454946258583\n",
      "FOLD: 2, EPOCH: 4, valid_loss: 0.0168755273692883\n",
      "FOLD: 2, EPOCH: 5, train_loss: 0.019389270704138924\n",
      "FOLD: 2, EPOCH: 5, valid_loss: 0.016926776617765427\n",
      "FOLD: 2, EPOCH: 6, train_loss: 0.018898106029106153\n",
      "FOLD: 2, EPOCH: 6, valid_loss: 0.016693218467900388\n",
      "FOLD: 2, EPOCH: 7, train_loss: 0.018632462600598466\n",
      "FOLD: 2, EPOCH: 7, valid_loss: 0.016787615962899648\n",
      "FOLD: 2, EPOCH: 8, train_loss: 0.01840905817477284\n",
      "FOLD: 2, EPOCH: 8, valid_loss: 0.01684494144641436\n",
      "FOLD: 2, EPOCH: 9, train_loss: 0.01834710594266653\n",
      "FOLD: 2, EPOCH: 9, valid_loss: 0.016642832698730323\n",
      "FOLD: 2, EPOCH: 10, train_loss: 0.018079907759218604\n",
      "FOLD: 2, EPOCH: 10, valid_loss: 0.016882936398570355\n",
      "FOLD: 2, EPOCH: 11, train_loss: 0.017744514776544797\n",
      "FOLD: 2, EPOCH: 11, valid_loss: 0.016704967460380152\n",
      "FOLD: 2, EPOCH: 12, train_loss: 0.017396528764653044\n",
      "FOLD: 2, EPOCH: 12, valid_loss: 0.016682296274946287\n",
      "FOLD: 2, EPOCH: 13, train_loss: 0.016981247208408407\n",
      "FOLD: 2, EPOCH: 13, valid_loss: 0.0170395362835664\n",
      "FOLD: 2, EPOCH: 14, train_loss: 0.01653146018853059\n",
      "FOLD: 2, EPOCH: 14, valid_loss: 0.016927297585285626\n",
      "FOLD: 2, EPOCH: 15, train_loss: 0.015793393428966\n",
      "FOLD: 2, EPOCH: 15, valid_loss: 0.016944098501251295\n",
      "FOLD: 2, EPOCH: 16, train_loss: 0.014834756522464592\n",
      "FOLD: 2, EPOCH: 16, valid_loss: 0.017225978036339466\n",
      "FOLD: 3, EPOCH: 0, train_loss: 0.5779823700117098\n",
      "FOLD: 3, EPOCH: 0, valid_loss: 0.04324904112861706\n",
      "FOLD: 3, EPOCH: 1, train_loss: 0.027490575344780006\n",
      "FOLD: 3, EPOCH: 1, valid_loss: 0.01932933310476633\n",
      "FOLD: 3, EPOCH: 2, train_loss: 0.02386349137570407\n",
      "FOLD: 3, EPOCH: 2, valid_loss: 0.018422015441151764\n",
      "FOLD: 3, EPOCH: 3, train_loss: 0.021514077922581015\n",
      "FOLD: 3, EPOCH: 3, valid_loss: 0.01763405937414903\n",
      "FOLD: 3, EPOCH: 4, train_loss: 0.02078514692147036\n",
      "FOLD: 3, EPOCH: 4, valid_loss: 0.017110691907314155\n",
      "FOLD: 3, EPOCH: 5, train_loss: 0.01955536028017869\n",
      "FOLD: 3, EPOCH: 5, valid_loss: 0.019807240854089078\n",
      "FOLD: 3, EPOCH: 6, train_loss: 0.019467235719029967\n",
      "FOLD: 3, EPOCH: 6, valid_loss: 0.01688926165493635\n",
      "FOLD: 3, EPOCH: 7, train_loss: 0.018781819808724766\n",
      "FOLD: 3, EPOCH: 7, valid_loss: 0.016875702028091136\n",
      "FOLD: 3, EPOCH: 8, train_loss: 0.018597059027367347\n",
      "FOLD: 3, EPOCH: 8, valid_loss: 0.017066370265988205\n",
      "FOLD: 3, EPOCH: 9, train_loss: 0.018417364464619675\n",
      "FOLD: 3, EPOCH: 9, valid_loss: 0.016789382466903098\n",
      "FOLD: 3, EPOCH: 10, train_loss: 0.018111211222571297\n",
      "FOLD: 3, EPOCH: 10, valid_loss: 0.017177540665635697\n",
      "FOLD: 3, EPOCH: 11, train_loss: 0.017923877964652068\n",
      "FOLD: 3, EPOCH: 11, valid_loss: 0.01701734458597807\n",
      "FOLD: 3, EPOCH: 12, train_loss: 0.017589886597282178\n",
      "FOLD: 3, EPOCH: 12, valid_loss: 0.016957729911574952\n",
      "FOLD: 3, EPOCH: 13, train_loss: 0.017045960975559177\n",
      "FOLD: 3, EPOCH: 13, valid_loss: 0.01692511384876875\n",
      "FOLD: 3, EPOCH: 14, train_loss: 0.016463733945243263\n",
      "FOLD: 3, EPOCH: 14, valid_loss: 0.016964770710239045\n",
      "FOLD: 3, EPOCH: 15, train_loss: 0.01586665310015952\n",
      "FOLD: 3, EPOCH: 15, valid_loss: 0.01720005517395643\n",
      "FOLD: 3, EPOCH: 16, train_loss: 0.014935974963009357\n",
      "FOLD: 3, EPOCH: 16, valid_loss: 0.017334380402014807\n",
      "FOLD: 3, EPOCH: 17, train_loss: 0.013810639584285987\n",
      "FOLD: 3, EPOCH: 17, valid_loss: 0.017329279190072648\n",
      "FOLD: 4, EPOCH: 0, train_loss: 0.5788917630608823\n",
      "FOLD: 4, EPOCH: 0, valid_loss: 0.05722181527660443\n",
      "FOLD: 4, EPOCH: 1, train_loss: 0.026821359564122314\n",
      "FOLD: 4, EPOCH: 1, valid_loss: 0.01926182683270711\n",
      "FOLD: 4, EPOCH: 2, train_loss: 0.022719131984017992\n",
      "FOLD: 4, EPOCH: 2, valid_loss: 0.018562299127762135\n",
      "FOLD: 4, EPOCH: 3, train_loss: 0.029337381415471837\n",
      "FOLD: 4, EPOCH: 3, valid_loss: 0.022007368648281463\n",
      "FOLD: 4, EPOCH: 4, train_loss: 0.023504580874499435\n",
      "FOLD: 4, EPOCH: 4, valid_loss: 0.01855434334048858\n",
      "FOLD: 4, EPOCH: 5, train_loss: 0.021609221459240525\n",
      "FOLD: 4, EPOCH: 5, valid_loss: 0.018092224804254677\n",
      "FOLD: 4, EPOCH: 6, train_loss: 0.0208662212952166\n",
      "FOLD: 4, EPOCH: 6, valid_loss: 0.017627086203831892\n",
      "FOLD: 4, EPOCH: 7, train_loss: 0.02041936801696146\n",
      "FOLD: 4, EPOCH: 7, valid_loss: 0.017476638062642172\n",
      "FOLD: 4, EPOCH: 8, train_loss: 0.02008411570175274\n",
      "FOLD: 4, EPOCH: 8, valid_loss: 0.017287868003432568\n",
      "FOLD: 4, EPOCH: 9, train_loss: 0.019762323464493494\n",
      "FOLD: 4, EPOCH: 9, valid_loss: 0.01728200253385764\n",
      "FOLD: 4, EPOCH: 10, train_loss: 0.019388631414118652\n",
      "FOLD: 4, EPOCH: 10, valid_loss: 0.016930921791264646\n",
      "FOLD: 4, EPOCH: 11, train_loss: 0.019069953972624766\n",
      "FOLD: 4, EPOCH: 11, valid_loss: 0.016913645685865328\n",
      "FOLD: 4, EPOCH: 12, train_loss: 0.0188175864467347\n",
      "FOLD: 4, EPOCH: 12, valid_loss: 0.016744511345258124\n",
      "FOLD: 4, EPOCH: 13, train_loss: 0.018427854982783664\n",
      "FOLD: 4, EPOCH: 13, valid_loss: 0.01674638022310459\n",
      "FOLD: 4, EPOCH: 14, train_loss: 0.018026056863065507\n",
      "FOLD: 4, EPOCH: 14, valid_loss: 0.016664052525391944\n",
      "FOLD: 4, EPOCH: 15, train_loss: 0.01750769224521276\n",
      "FOLD: 4, EPOCH: 15, valid_loss: 0.016725841981287185\n",
      "FOLD: 4, EPOCH: 16, train_loss: 0.01686215415798329\n",
      "FOLD: 4, EPOCH: 16, valid_loss: 0.01682258232568319\n",
      "FOLD: 4, EPOCH: 17, train_loss: 0.015926802153321536\n",
      "FOLD: 4, EPOCH: 17, valid_loss: 0.016920913225756243\n",
      "FOLD: 4, EPOCH: 18, train_loss: 0.014869631884770619\n",
      "FOLD: 4, EPOCH: 18, valid_loss: 0.017050514857356366\n",
      "FOLD: 4, EPOCH: 19, train_loss: 0.013623691403080482\n",
      "FOLD: 4, EPOCH: 19, valid_loss: 0.017281108177625217\n",
      "FOLD: 4, EPOCH: 20, train_loss: 0.012107209164045146\n",
      "FOLD: 4, EPOCH: 20, valid_loss: 0.01736777676985814\n",
      "FOLD: 4, EPOCH: 21, train_loss: 0.010640763425947847\n",
      "FOLD: 4, EPOCH: 21, valid_loss: 0.017690590654428188\n",
      "FOLD: 4, EPOCH: 22, train_loss: 0.009353660462373818\n",
      "FOLD: 4, EPOCH: 22, valid_loss: 0.017888191944131486\n",
      "FOLD: 5, EPOCH: 0, train_loss: 0.5785131145369362\n",
      "FOLD: 5, EPOCH: 0, valid_loss: 0.04678166714998392\n",
      "FOLD: 5, EPOCH: 1, train_loss: 0.026583279936096153\n",
      "FOLD: 5, EPOCH: 1, valid_loss: 0.019560979034465093\n",
      "FOLD: 5, EPOCH: 2, train_loss: 0.023799202178378363\n",
      "FOLD: 5, EPOCH: 2, valid_loss: 0.021719815209507942\n",
      "FOLD: 5, EPOCH: 3, train_loss: 0.021760102864858265\n",
      "FOLD: 5, EPOCH: 3, valid_loss: 0.018612381643973865\n",
      "FOLD: 5, EPOCH: 4, train_loss: 0.020335007660292292\n",
      "FOLD: 5, EPOCH: 4, valid_loss: 0.017410598480357573\n",
      "FOLD: 5, EPOCH: 5, train_loss: 0.01986503306574918\n",
      "FOLD: 5, EPOCH: 5, valid_loss: 0.016925907120681725\n",
      "FOLD: 5, EPOCH: 6, train_loss: 0.020025910054509703\n",
      "FOLD: 5, EPOCH: 6, valid_loss: 0.017093199735077527\n",
      "FOLD: 5, EPOCH: 7, train_loss: 0.019559404535873515\n",
      "FOLD: 5, EPOCH: 7, valid_loss: 0.016816114218762286\n",
      "FOLD: 5, EPOCH: 8, train_loss: 0.018845025399649464\n",
      "FOLD: 5, EPOCH: 8, valid_loss: 0.01685253559396817\n",
      "FOLD: 5, EPOCH: 9, train_loss: 0.018597368503341805\n",
      "FOLD: 5, EPOCH: 9, valid_loss: 0.016584894476601712\n",
      "FOLD: 5, EPOCH: 10, train_loss: 0.018469913057177455\n",
      "FOLD: 5, EPOCH: 10, valid_loss: 0.01704173356008071\n",
      "FOLD: 5, EPOCH: 11, train_loss: 0.018161493932475913\n",
      "FOLD: 5, EPOCH: 11, valid_loss: 0.016939227540905658\n",
      "FOLD: 5, EPOCH: 12, train_loss: 0.017834382458917192\n",
      "FOLD: 5, EPOCH: 12, valid_loss: 0.016756742332990352\n",
      "FOLD: 5, EPOCH: 13, train_loss: 0.017476563115377684\n",
      "FOLD: 5, EPOCH: 13, valid_loss: 0.01693032574481689\n",
      "FOLD: 5, EPOCH: 14, train_loss: 0.016995287147929538\n",
      "FOLD: 5, EPOCH: 14, valid_loss: 0.016921902003769692\n",
      "FOLD: 5, EPOCH: 15, train_loss: 0.016422636341303587\n",
      "FOLD: 5, EPOCH: 15, valid_loss: 0.016922845433537777\n",
      "FOLD: 5, EPOCH: 16, train_loss: 0.015607736237045075\n",
      "FOLD: 5, EPOCH: 16, valid_loss: 0.01689274709385175\n",
      "FOLD: 6, EPOCH: 0, train_loss: 0.5785373079817038\n",
      "FOLD: 6, EPOCH: 0, valid_loss: 0.04111130392322174\n",
      "FOLD: 6, EPOCH: 1, train_loss: 0.027032840141170734\n",
      "FOLD: 6, EPOCH: 1, valid_loss: 0.01896453505525222\n",
      "FOLD: 6, EPOCH: 2, train_loss: 0.0228424709088899\n",
      "FOLD: 6, EPOCH: 2, valid_loss: 0.017963142205889408\n",
      "FOLD: 6, EPOCH: 3, train_loss: 0.022370569634477835\n",
      "FOLD: 6, EPOCH: 3, valid_loss: 0.019068129217395417\n",
      "FOLD: 6, EPOCH: 4, train_loss: 0.020816644225772972\n",
      "FOLD: 6, EPOCH: 4, valid_loss: 0.017111973120616034\n",
      "FOLD: 6, EPOCH: 5, train_loss: 0.020610053067070408\n",
      "FOLD: 6, EPOCH: 5, valid_loss: 0.017140348441898823\n",
      "FOLD: 6, EPOCH: 6, train_loss: 0.020467788962697662\n",
      "FOLD: 6, EPOCH: 6, valid_loss: 0.01697649247944355\n",
      "FOLD: 6, EPOCH: 7, train_loss: 0.01940466493770883\n",
      "FOLD: 6, EPOCH: 7, valid_loss: 0.01698065413018832\n",
      "FOLD: 6, EPOCH: 8, train_loss: 0.019067081245216163\n",
      "FOLD: 6, EPOCH: 8, valid_loss: 0.016765369317279413\n",
      "FOLD: 6, EPOCH: 9, train_loss: 0.01874149724136333\n",
      "FOLD: 6, EPOCH: 9, valid_loss: 0.016752222266334754\n",
      "FOLD: 6, EPOCH: 10, train_loss: 0.018583213633580786\n",
      "FOLD: 6, EPOCH: 10, valid_loss: 0.016979603956525143\n",
      "FOLD: 6, EPOCH: 11, train_loss: 0.018258476139021082\n",
      "FOLD: 6, EPOCH: 11, valid_loss: 0.01674101773936015\n",
      "FOLD: 6, EPOCH: 12, train_loss: 0.01797598976692235\n",
      "FOLD: 6, EPOCH: 12, valid_loss: 0.016728109035354394\n",
      "FOLD: 6, EPOCH: 13, train_loss: 0.017619111172452167\n",
      "FOLD: 6, EPOCH: 13, valid_loss: 0.016819698592791192\n",
      "FOLD: 6, EPOCH: 14, train_loss: 0.01720878596392435\n",
      "FOLD: 6, EPOCH: 14, valid_loss: 0.01689614477352454\n",
      "FOLD: 6, EPOCH: 15, train_loss: 0.016654443549546035\n",
      "FOLD: 6, EPOCH: 15, valid_loss: 0.016877733457546968\n",
      "FOLD: 6, EPOCH: 16, train_loss: 0.015847932006156928\n",
      "FOLD: 6, EPOCH: 16, valid_loss: 0.01725518158995188\n",
      "FOLD: 6, EPOCH: 17, train_loss: 0.014855667470476112\n",
      "FOLD: 6, EPOCH: 17, valid_loss: 0.01724964537872718\n",
      "FOLD: 6, EPOCH: 18, train_loss: 0.013666052534874226\n",
      "FOLD: 6, EPOCH: 18, valid_loss: 0.01736990061516945\n"
     ]
    }
   ],
   "source": [
    "SEED = [0,1,2,3,4,5,6]\n",
    "# SEED = [14,16,77,76,34]\n",
    "# SEED = [34]\n",
    "oof = np.zeros((len(train), len(target_cols)))\n",
    "predictions = np.zeros((len(test), len(target_cols)))\n",
    "flag = True\n",
    "for seed in SEED: \n",
    "    oof_, predictions_ = run_k_fold(NFOLDS, seed)\n",
    "    oof += oof_ / len(SEED)\n",
    "    predictions += predictions_ / len(SEED)\n",
    "\n",
    "train[target_cols] = oof\n",
    "test[target_cols] = predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-21T00:11:05.258026Z",
     "iopub.status.busy": "2020-11-21T00:11:05.256777Z",
     "iopub.status.idle": "2020-11-21T00:11:06.547887Z",
     "shell.execute_reply": "2020-11-21T00:11:06.548353Z"
    },
    "papermill": {
     "duration": 1.964212,
     "end_time": "2020-11-21T00:11:06.548497",
     "exception": false,
     "start_time": "2020-11-21T00:11:04.584285",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CV log_loss:  0.01470840514367172\n"
     ]
    }
   ],
   "source": [
    "valid_results = train_targets_scored.drop(columns=target_cols).merge(train[['sig_id']+target_cols], on='sig_id', how='left').fillna(0)\n",
    "\n",
    "\n",
    "\n",
    "y_true = train_targets_scored[target_cols].values\n",
    "y_pred = valid_results[target_cols].values\n",
    "\n",
    "score = 0\n",
    "for i in range(len(target_cols)):\n",
    "    score_ = log_loss(y_true[:, i], y_pred[:, i])\n",
    "    score += score_ / target.shape[1]\n",
    "    \n",
    "print(\"CV log_loss: \", score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-21T00:11:08.258623Z",
     "iopub.status.busy": "2020-11-21T00:11:08.256929Z",
     "iopub.status.idle": "2020-11-21T00:11:08.259438Z",
     "shell.execute_reply": "2020-11-21T00:11:08.257903Z"
    },
    "papermill": {
     "duration": 1.051219,
     "end_time": "2020-11-21T00:11:08.259616",
     "exception": false,
     "start_time": "2020-11-21T00:11:07.208397",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# def log_loss_metric(y_true, y_pred):\n",
    "#     metrics = []\n",
    "#     for _target in train_targets_scored.columns:\n",
    "#         metrics.append(log_loss(y_true.loc[:, _target], y_pred.loc[:, _target].astype(float), labels = [0,1]))\n",
    "#     return np.mean(metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-21T00:11:09.954675Z",
     "iopub.status.busy": "2020-11-21T00:11:09.953584Z",
     "iopub.status.idle": "2020-11-21T00:11:10.064285Z",
     "shell.execute_reply": "2020-11-21T00:11:10.065508Z"
    },
    "papermill": {
     "duration": 0.772507,
     "end_time": "2020-11-21T00:11:10.065758",
     "exception": false,
     "start_time": "2020-11-21T00:11:09.293251",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv('../input/lish-moa/sample_submission.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-21T00:11:11.401121Z",
     "iopub.status.busy": "2020-11-21T00:11:11.400190Z",
     "iopub.status.idle": "2020-11-21T00:11:13.488795Z",
     "shell.execute_reply": "2020-11-21T00:11:13.489291Z"
    },
    "papermill": {
     "duration": 2.760283,
     "end_time": "2020-11-21T00:11:13.489444",
     "exception": false,
     "start_time": "2020-11-21T00:11:10.729161",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "public_id = list(df['sig_id'].values)\n",
    "test_id = list(test_features['sig_id'].values)\n",
    "private_id = list(set(test_id)-set(public_id))\n",
    "df_submit = pd.DataFrame(index = public_id+private_id, columns=target_cols)\n",
    "df_submit.index.name = 'sig_id'\n",
    "df_submit[:] = 0\n",
    "df_submit.loc[test.sig_id,:] = test[target_cols].values\n",
    "df_submit.loc[test_features[test_features.cp_type=='ctl_vehicle'].sig_id]= 0\n",
    "df_submit.to_csv('submission.csv',index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-21T00:11:14.852230Z",
     "iopub.status.busy": "2020-11-21T00:11:14.851197Z",
     "iopub.status.idle": "2020-11-21T00:11:14.856275Z",
     "shell.execute_reply": "2020-11-21T00:11:14.855748Z"
    },
    "papermill": {
     "duration": 0.695388,
     "end_time": "2020-11-21T00:11:14.856374",
     "exception": false,
     "start_time": "2020-11-21T00:11:14.160986",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>5-alpha_reductase_inhibitor</th>\n",
       "      <th>11-beta-hsd1_inhibitor</th>\n",
       "      <th>acat_inhibitor</th>\n",
       "      <th>acetylcholine_receptor_agonist</th>\n",
       "      <th>acetylcholine_receptor_antagonist</th>\n",
       "      <th>acetylcholinesterase_inhibitor</th>\n",
       "      <th>adenosine_receptor_agonist</th>\n",
       "      <th>adenosine_receptor_antagonist</th>\n",
       "      <th>adenylyl_cyclase_activator</th>\n",
       "      <th>adrenergic_receptor_agonist</th>\n",
       "      <th>...</th>\n",
       "      <th>tropomyosin_receptor_kinase_inhibitor</th>\n",
       "      <th>trpv_agonist</th>\n",
       "      <th>trpv_antagonist</th>\n",
       "      <th>tubulin_inhibitor</th>\n",
       "      <th>tyrosine_kinase_inhibitor</th>\n",
       "      <th>ubiquitin_specific_protease_inhibitor</th>\n",
       "      <th>vegfr_inhibitor</th>\n",
       "      <th>vitamin_b</th>\n",
       "      <th>vitamin_d_receptor_agonist</th>\n",
       "      <th>wnt_inhibitor</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sig_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>id_0004d9e33</th>\n",
       "      <td>0.00136516</td>\n",
       "      <td>0.00222144</td>\n",
       "      <td>0.00271388</td>\n",
       "      <td>0.0107294</td>\n",
       "      <td>0.0165974</td>\n",
       "      <td>0.00469504</td>\n",
       "      <td>0.00201674</td>\n",
       "      <td>0.00762078</td>\n",
       "      <td>0.000749796</td>\n",
       "      <td>0.0094311</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00124807</td>\n",
       "      <td>0.0024223</td>\n",
       "      <td>0.00508401</td>\n",
       "      <td>0.00135914</td>\n",
       "      <td>0.00086571</td>\n",
       "      <td>0.00127323</td>\n",
       "      <td>0.000950994</td>\n",
       "      <td>0.00198338</td>\n",
       "      <td>0.0206403</td>\n",
       "      <td>0.00202415</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id_001897cda</th>\n",
       "      <td>0.000810596</td>\n",
       "      <td>0.00146312</td>\n",
       "      <td>0.00252199</td>\n",
       "      <td>0.00218494</td>\n",
       "      <td>0.00161068</td>\n",
       "      <td>0.00221069</td>\n",
       "      <td>0.00729835</td>\n",
       "      <td>0.00820226</td>\n",
       "      <td>0.00925034</td>\n",
       "      <td>0.0110798</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00131222</td>\n",
       "      <td>0.00187813</td>\n",
       "      <td>0.00457233</td>\n",
       "      <td>0.000885836</td>\n",
       "      <td>0.0159092</td>\n",
       "      <td>0.00115297</td>\n",
       "      <td>0.0136797</td>\n",
       "      <td>0.00194034</td>\n",
       "      <td>0.00203429</td>\n",
       "      <td>0.003524</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id_002429b5b</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id_00276f245</th>\n",
       "      <td>0.00142193</td>\n",
       "      <td>0.00141465</td>\n",
       "      <td>0.00225003</td>\n",
       "      <td>0.0134241</td>\n",
       "      <td>0.0172852</td>\n",
       "      <td>0.00489947</td>\n",
       "      <td>0.00413547</td>\n",
       "      <td>0.00375934</td>\n",
       "      <td>0.00080419</td>\n",
       "      <td>0.0150897</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00112868</td>\n",
       "      <td>0.00160685</td>\n",
       "      <td>0.00320995</td>\n",
       "      <td>0.0199202</td>\n",
       "      <td>0.00480384</td>\n",
       "      <td>0.00110004</td>\n",
       "      <td>0.00214475</td>\n",
       "      <td>0.00207892</td>\n",
       "      <td>0.00135614</td>\n",
       "      <td>0.00305479</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id_0027f1083</th>\n",
       "      <td>0.00229196</td>\n",
       "      <td>0.00157413</td>\n",
       "      <td>0.00229535</td>\n",
       "      <td>0.0172839</td>\n",
       "      <td>0.0191584</td>\n",
       "      <td>0.00320013</td>\n",
       "      <td>0.00711775</td>\n",
       "      <td>0.00204866</td>\n",
       "      <td>0.00110334</td>\n",
       "      <td>0.0110381</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00148483</td>\n",
       "      <td>0.00100566</td>\n",
       "      <td>0.00344258</td>\n",
       "      <td>0.00229424</td>\n",
       "      <td>0.00205212</td>\n",
       "      <td>0.00110888</td>\n",
       "      <td>0.00195315</td>\n",
       "      <td>0.00244208</td>\n",
       "      <td>0.00054361</td>\n",
       "      <td>0.0021411</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 206 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             5-alpha_reductase_inhibitor 11-beta-hsd1_inhibitor  \\\n",
       "sig_id                                                            \n",
       "id_0004d9e33                  0.00136516             0.00222144   \n",
       "id_001897cda                 0.000810596             0.00146312   \n",
       "id_002429b5b                           0                      0   \n",
       "id_00276f245                  0.00142193             0.00141465   \n",
       "id_0027f1083                  0.00229196             0.00157413   \n",
       "\n",
       "             acat_inhibitor acetylcholine_receptor_agonist  \\\n",
       "sig_id                                                       \n",
       "id_0004d9e33     0.00271388                      0.0107294   \n",
       "id_001897cda     0.00252199                     0.00218494   \n",
       "id_002429b5b              0                              0   \n",
       "id_00276f245     0.00225003                      0.0134241   \n",
       "id_0027f1083     0.00229535                      0.0172839   \n",
       "\n",
       "             acetylcholine_receptor_antagonist acetylcholinesterase_inhibitor  \\\n",
       "sig_id                                                                          \n",
       "id_0004d9e33                         0.0165974                     0.00469504   \n",
       "id_001897cda                        0.00161068                     0.00221069   \n",
       "id_002429b5b                                 0                              0   \n",
       "id_00276f245                         0.0172852                     0.00489947   \n",
       "id_0027f1083                         0.0191584                     0.00320013   \n",
       "\n",
       "             adenosine_receptor_agonist adenosine_receptor_antagonist  \\\n",
       "sig_id                                                                  \n",
       "id_0004d9e33                 0.00201674                    0.00762078   \n",
       "id_001897cda                 0.00729835                    0.00820226   \n",
       "id_002429b5b                          0                             0   \n",
       "id_00276f245                 0.00413547                    0.00375934   \n",
       "id_0027f1083                 0.00711775                    0.00204866   \n",
       "\n",
       "             adenylyl_cyclase_activator adrenergic_receptor_agonist  ...  \\\n",
       "sig_id                                                               ...   \n",
       "id_0004d9e33                0.000749796                   0.0094311  ...   \n",
       "id_001897cda                 0.00925034                   0.0110798  ...   \n",
       "id_002429b5b                          0                           0  ...   \n",
       "id_00276f245                 0.00080419                   0.0150897  ...   \n",
       "id_0027f1083                 0.00110334                   0.0110381  ...   \n",
       "\n",
       "             tropomyosin_receptor_kinase_inhibitor trpv_agonist  \\\n",
       "sig_id                                                            \n",
       "id_0004d9e33                            0.00124807    0.0024223   \n",
       "id_001897cda                            0.00131222   0.00187813   \n",
       "id_002429b5b                                     0            0   \n",
       "id_00276f245                            0.00112868   0.00160685   \n",
       "id_0027f1083                            0.00148483   0.00100566   \n",
       "\n",
       "             trpv_antagonist tubulin_inhibitor tyrosine_kinase_inhibitor  \\\n",
       "sig_id                                                                     \n",
       "id_0004d9e33      0.00508401        0.00135914                0.00086571   \n",
       "id_001897cda      0.00457233       0.000885836                 0.0159092   \n",
       "id_002429b5b               0                 0                         0   \n",
       "id_00276f245      0.00320995         0.0199202                0.00480384   \n",
       "id_0027f1083      0.00344258        0.00229424                0.00205212   \n",
       "\n",
       "             ubiquitin_specific_protease_inhibitor vegfr_inhibitor  \\\n",
       "sig_id                                                               \n",
       "id_0004d9e33                            0.00127323     0.000950994   \n",
       "id_001897cda                            0.00115297       0.0136797   \n",
       "id_002429b5b                                     0               0   \n",
       "id_00276f245                            0.00110004      0.00214475   \n",
       "id_0027f1083                            0.00110888      0.00195315   \n",
       "\n",
       "               vitamin_b vitamin_d_receptor_agonist wnt_inhibitor  \n",
       "sig_id                                                             \n",
       "id_0004d9e33  0.00198338                  0.0206403    0.00202415  \n",
       "id_001897cda  0.00194034                 0.00203429      0.003524  \n",
       "id_002429b5b           0                          0             0  \n",
       "id_00276f245  0.00207892                 0.00135614    0.00305479  \n",
       "id_0027f1083  0.00244208                 0.00054361     0.0021411  \n",
       "\n",
       "[5 rows x 206 columns]"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_submit.head()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "papermill": {
   "duration": 2776.443035,
   "end_time": "2020-11-21T00:11:16.025796",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2020-11-20T23:24:59.582761",
   "version": "2.1.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
